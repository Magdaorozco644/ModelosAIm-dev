{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tabgan==1.3.3\n",
      "  Downloading tabgan-1.3.3-py2.py3-none-any.whl.metadata (10.0 kB)\n",
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tabgan==1.3.3) (2.2.1)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tabgan==1.3.3) (1.22.4)\n",
      "Collecting category-encoders (from tabgan==1.3.3)\n",
      "  Downloading category_encoders-2.6.3-py2.py3-none-any.whl.metadata (8.0 kB)\n",
      "Collecting torch>=1.0 (from tabgan==1.3.3)\n",
      "  Downloading torch-2.2.1-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\n",
      "Requirement already satisfied: lightgbm>=2.2.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tabgan==1.3.3) (4.3.0)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tabgan==1.3.3) (1.4.0)\n",
      "Collecting torchvision (from tabgan==1.3.3)\n",
      "  Downloading torchvision-0.17.1-cp310-cp310-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: python-dateutil in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tabgan==1.3.3) (2.8.2)\n",
      "Requirement already satisfied: tqdm in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tabgan==1.3.3) (4.66.1)\n",
      "Requirement already satisfied: scipy in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from lightgbm>=2.2.3->tabgan==1.3.3) (1.11.4)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from scikit-learn>=1.0.2->tabgan==1.3.3) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from scikit-learn>=1.0.2->tabgan==1.3.3) (3.2.0)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch>=1.0->tabgan==1.3.3) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch>=1.0->tabgan==1.3.3) (4.9.0)\n",
      "Requirement already satisfied: sympy in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch>=1.0->tabgan==1.3.3) (1.12)\n",
      "Requirement already satisfied: networkx in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch>=1.0->tabgan==1.3.3) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch>=1.0->tabgan==1.3.3) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch>=1.0->tabgan==1.3.3) (2023.12.2)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.0->tabgan==1.3.3)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.0->tabgan==1.3.3)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.0->tabgan==1.3.3)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.0->tabgan==1.3.3)\n",
      "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.0->tabgan==1.3.3)\n",
      "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.0->tabgan==1.3.3)\n",
      "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.0->tabgan==1.3.3)\n",
      "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.0->tabgan==1.3.3)\n",
      "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.0->tabgan==1.3.3)\n",
      "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nccl-cu12==2.19.3 (from torch>=1.0->tabgan==1.3.3)\n",
      "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.0->tabgan==1.3.3)\n",
      "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting triton==2.2.0 (from torch>=1.0->tabgan==1.3.3)\n",
      "  Downloading triton-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
      "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.0->tabgan==1.3.3)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.99-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: statsmodels>=0.9.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from category-encoders->tabgan==1.3.3) (0.14.1)\n",
      "Requirement already satisfied: patsy>=0.5.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from category-encoders->tabgan==1.3.3) (0.5.6)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas->tabgan==1.3.3) (2023.4)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas->tabgan==1.3.3) (2023.4)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from python-dateutil->tabgan==1.3.3) (1.16.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torchvision->tabgan==1.3.3) (10.2.0)\n",
      "Requirement already satisfied: packaging>=21.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from statsmodels>=0.9.0->category-encoders->tabgan==1.3.3) (21.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jinja2->torch>=1.0->tabgan==1.3.3) (2.1.4)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sympy->torch>=1.0->tabgan==1.3.3) (1.3.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from packaging>=21.3->statsmodels>=0.9.0->category-encoders->tabgan==1.3.3) (3.1.1)\n",
      "Downloading tabgan-1.3.3-py2.py3-none-any.whl (28 kB)\n",
      "Downloading torch-2.2.1-cp310-cp310-manylinux1_x86_64.whl (755.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.5/755.5 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m37.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m68.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading triton-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (167.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading category_encoders-2.6.3-py2.py3-none-any.whl (81 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.9/81.9 kB\u001b[0m \u001b[31m793.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading torchvision-0.17.1-cp310-cp310-manylinux1_x86_64.whl (6.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m45.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.99-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: triton, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, category-encoders, torchvision, tabgan\n",
      "Successfully installed category-encoders-2.6.3 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.99 nvidia-nvtx-cu12-12.1.105 tabgan-1.3.3 torch-2.2.1 torchvision-0.17.1 triton-2.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#pip install tabgan==1.3.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightgbm in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (4.3.0)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from lightgbm) (1.22.4)\n",
      "Requirement already satisfied: scipy in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from lightgbm) (1.11.4)\n"
     ]
    }
   ],
   "source": [
    "#!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (2.2.0)\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.2.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: dask[complete] in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (2024.1.1)\n",
      "Collecting dask[complete]\n",
      "  Downloading dask-2024.3.0-py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas) (1.22.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas) (2023.4)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas) (2023.4)\n",
      "Requirement already satisfied: click>=8.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from dask[complete]) (8.1.7)\n",
      "Requirement already satisfied: cloudpickle>=1.5.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from dask[complete]) (2.2.1)\n",
      "Requirement already satisfied: fsspec>=2021.09.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from dask[complete]) (2023.12.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from dask[complete]) (21.3)\n",
      "Requirement already satisfied: partd>=1.2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from dask[complete]) (1.4.1)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from dask[complete]) (6.0.1)\n",
      "Requirement already satisfied: toolz>=0.10.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from dask[complete]) (0.12.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.13.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from dask[complete]) (6.11.0)\n",
      "Requirement already satisfied: pyarrow>=7.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from dask[complete]) (15.0.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from dask[complete]) (0.6)\n",
      "Requirement already satisfied: lz4>=4.3.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from dask[complete]) (4.3.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from importlib-metadata>=4.13.0->dask[complete]) (3.17.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from packaging>=20.0->dask[complete]) (3.1.1)\n",
      "Requirement already satisfied: locket in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from partd>=1.2.0->dask[complete]) (1.0.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: bokeh>=2.4.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from dask[complete]) (3.3.4)\n",
      "Requirement already satisfied: jinja2>=2.10.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from dask[complete]) (3.1.3)\n",
      "Collecting dask-expr<1.1,>=1.0 (from dask[complete])\n",
      "  Downloading dask_expr-1.0.2-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting distributed==2024.3.0 (from dask[complete])\n",
      "  Downloading distributed-2024.3.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: msgpack>=1.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from distributed==2024.3.0->dask[complete]) (1.0.7)\n",
      "Requirement already satisfied: psutil>=5.7.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from distributed==2024.3.0->dask[complete]) (5.9.8)\n",
      "Requirement already satisfied: sortedcontainers>=2.0.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from distributed==2024.3.0->dask[complete]) (2.4.0)\n",
      "Requirement already satisfied: tblib>=1.6.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from distributed==2024.3.0->dask[complete]) (2.0.0)\n",
      "Requirement already satisfied: tornado>=6.0.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from distributed==2024.3.0->dask[complete]) (6.3.3)\n",
      "Requirement already satisfied: urllib3>=1.24.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from distributed==2024.3.0->dask[complete]) (1.26.18)\n",
      "Requirement already satisfied: zict>=3.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from distributed==2024.3.0->dask[complete]) (3.0.0)\n",
      "Requirement already satisfied: contourpy>=1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from bokeh>=2.4.2->dask[complete]) (1.2.0)\n",
      "Requirement already satisfied: pillow>=7.1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from bokeh>=2.4.2->dask[complete]) (10.2.0)\n",
      "Requirement already satisfied: xyzservices>=2021.09.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from bokeh>=2.4.2->dask[complete]) (2023.10.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jinja2>=2.10.3->dask[complete]) (2.1.4)\n",
      "Downloading pandas-2.2.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m57.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading dask-2024.3.0-py3-none-any.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading distributed-2024.3.0-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading dask_expr-1.0.2-py3-none-any.whl (179 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m180.0/180.0 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pandas, dask, distributed, dask-expr\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 2.2.0\n",
      "    Uninstalling pandas-2.2.0:\n",
      "      Successfully uninstalled pandas-2.2.0\n",
      "  Attempting uninstall: dask\n",
      "    Found existing installation: dask 2024.1.1\n",
      "    Uninstalling dask-2024.1.1:\n",
      "      Successfully uninstalled dask-2024.1.1\n",
      "  Attempting uninstall: distributed\n",
      "    Found existing installation: distributed 2024.1.1\n",
      "    Uninstalling distributed-2024.1.1:\n",
      "      Successfully uninstalled distributed-2024.1.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "autovizwidget 0.21.0 requires pandas<2.0.0,>=0.20.1, but you have pandas 2.2.1 which is incompatible.\n",
      "hdijupyterutils 0.21.0 requires pandas<2.0.0,>=0.17.1, but you have pandas 2.2.1 which is incompatible.\n",
      "sparkmagic 0.21.0 requires pandas<2.0.0,>=0.17.1, but you have pandas 2.2.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed dask-2024.3.0 dask-expr-1.0.2 distributed-2024.3.0 pandas-2.2.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#pip install --upgrade pandas \"dask[complete]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "567b8871-992b-48f1-9709-847d1f6529ec",
     "showTitle": false,
     "title": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## librerias requeridas\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import calendar\n",
    "import re\n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.metrics import classification_report \n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "#from scikitplot.metrics import plot_roc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "#from scikitplot.metrics import plot_lift_curve\n",
    "#from scikitplot.helpers import binary_ks_curve \n",
    "#from scikitplot.metrics import plot_ks_statistic\n",
    "#from scikitplot.helpers import cumulative_gain_curve\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from lightgbm import LGBMClassifier\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6ebc0e87-d9be-4b2c-b870-c00cbea0ad90",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 500)\n",
    "#pd.set_option('display.max_rows', 500)\n",
    "#pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.memory_usage', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9a5f32c1-8445-4154-9406-921f6dc072e2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "s3_url = f\"viamericas-datalake-dev-us-east-1-283731589572-raw/FraudModel/Train\"\n",
    "    \n",
    "df1 = pd.read_parquet(f\"s3://{s3_url}/Preproc_Fr_202301.parquet\")\n",
    "df2 = pd.read_parquet(f\"s3://{s3_url}/Preproc_Fr_202302.parquet\")\n",
    "df3 = pd.read_parquet(f\"s3://{s3_url}/Preproc_Fr_202303.parquet\")\n",
    "df4 = pd.read_parquet(f\"s3://{s3_url}/Preproc_Fr_202304.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d5d5ca41-2ed5-486d-9938-5588bd98bb0d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "## TARGETS\n",
    "\n",
    "#target 1\n",
    "tg1 = df1['target_fraudes']\n",
    "#target 1\n",
    "tg2 = df2['target_fraudes']\n",
    "#target 1\n",
    "tg3 = df3['target_fraudes']\n",
    "#target 1\n",
    "tg4 = df4['target_fraudes']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "785b968d-5f8e-43f5-bc18-492a9591a309",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "## unir las cuatro cosechas\n",
    "\n",
    "dfs = [df1, df2, df3, df4]\n",
    "\n",
    "df = pd.concat( [df1, df2, df3, df4], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "15f394a4-c693-4f36-aa55-776532dc22b7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "## unir los cuatro targets\n",
    "\n",
    "tgs = [tg1, tg2, tg3, tg4]\n",
    "\n",
    "tg = pd.concat([tg1, tg2, tg3, tg4], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3b0247e4-0839-427c-b652-87ee2a94e232",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def limpiar_nombres_columnas(dataframe):\n",
    "    \"\"\"\n",
    "    Limpia y estandariza los nombres de las columnas en un DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - dataframe: DataFrame de pandas.\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame con nombres de columnas limpios.\n",
    "    \"\"\"\n",
    "    dataframe = dataframe.rename(columns=lambda x: re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "    return dataframe\n",
    "    \n",
    "df = limpiar_nombres_columnas(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "191cdfbb-d0be-46f8-9a90-aea4e8211272",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombres de columnas: ['01_receiver_transaction_count', '01_sender_sending_days', '01_branch_working_days', '01_net_amount_receiver', '01_sender_minutes_since_last_transaction_2days', '01_sender_minutes_since_last_transaction_1day', '01_sender_days_to_last_transaction_365', 'target_fraudes']\n"
     ]
    }
   ],
   "source": [
    "#listar las columnas del dataframe\n",
    "\n",
    "def nombres_de_columnas(dataframe):\n",
    "    return dataframe.columns.tolist()\n",
    "\n",
    "# Supongamos que tu DataFrame se llama 'df'\n",
    "# Puedes ajustar el nombre según el que hayas utilizado\n",
    "\n",
    "nombres_columnas = nombres_de_columnas(df)\n",
    "\n",
    "# Imprimir los nombres de las columnas\n",
    "print(f'Nombres de columnas: {nombres_columnas}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3918f177-7b8e-48dd-b4d8-bee08870e4d1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7880523, 8)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "00b45ce3-0e0c-4a02-b9ea-e39d5307115d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "##lista de variables de input\n",
    "X = df.loc[:, df.columns != 'target_fraudes']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "013a0689-6082-4ffc-a26c-22eb20e87cd8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "Y = df[['target_fraudes']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b55cb26d-4d58-4906-9a8c-9ab7be44df3b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0030074146094110758"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calcular_porcentaje_valor_1(columna):\n",
    "    \"\"\"\n",
    "    Calcula el porcentaje de ocurrencia del valor 1 en una columna dicotómica.\n",
    "\n",
    "    Parameters:\n",
    "    - columna: Columna con valores binarios (0 o 1).\n",
    "\n",
    "    Returns:\n",
    "    - Porcentaje de ocurrencia del valor 1.\n",
    "    \"\"\"\n",
    "\n",
    "    total_registros = len(columna)\n",
    "    ocurrencias_valor_1 = columna.sum()\n",
    "\n",
    "    porcentaje_valor_1 = (ocurrencias_valor_1 / total_registros) * 100\n",
    "\n",
    "    return porcentaje_valor_1\n",
    "porcentaje_1 = calcular_porcentaje_valor_1(Y['target_fraudes'])\n",
    "porcentaje_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9612dbfc-6d13-4319-a1a4-713b5142d0b4",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## ENTRENAMIENTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c5b13dbe-2dbc-4cf6-8288-e8d8eade6fb6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Dividir el conjunto de datos en conjuntos de entrenamiento (80%) y prueba (20%)\n",
    "# X_train: características de entrenamiento, X_test: características de prueba\n",
    "# y_train: etiquetas de entrenamiento, y_test: etiquetas de prueba\n",
    "# Se utiliza un 20% de los datos para prueba, y se fija la semilla aleatoria en 88 para reproducibilidad.\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2, random_state = 88) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4ffb2573-b439-4e55-8d72-d3080e43a6b3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "fit_parameters = {\n",
    "    #\"early_stopping_rounds\": 30,           # Número de rondas para detener el entrenamiento si no hay mejoras\n",
    "    \"eval_metric\": 'logloss',              # Métrica de evaluación a utilizar (en este caso, logloss)\n",
    "    \"eval_set\": [(X_test, y_test)],        # Conjunto de datos de prueba para la evaluación durante el entrenamiento\n",
    "    'eval_names': ['valid'],               # Nombre asignado al conjunto de evaluación\n",
    "    #'verbose': 100,                        # Nivel de detalle en la salida durante el entrenamiento\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "419b3f45-3007-4e2a-9695-bfafa06d672c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Parámetros para la búsqueda aleatoria de hiperparámetros\n",
    "param_testeo = {\n",
    "    \"n_estimators\": [5, 10, 15, 20, 25, 30, 35, 50, 100, 150, 300, 400, 500, 510, 520],\n",
    "    # Número de estimadores (árboles) a probar\n",
    "\n",
    "    \"num_leaves\": [2, 3, 4, 6, 10, 20, 25, 28, 30, 31, 32, 33, 35, 40, 45],\n",
    "    # Número máximo de nodos hoja en un árbol\n",
    "\n",
    "    \"max_depth\": [10, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 30, 35, 100, 125, 150, 170, 200, 250, 300, 400],\n",
    "    # Profundidad máxima de un árbol\n",
    "\n",
    "    \"colsample_bytree\": [0.50, 0.55, 0.6, 0.65, 0.68, 0.70, 0.71, 0.80, 0.81, 0.84, 0.85, 0.86, 0.9],\n",
    "    # Fracción de características a considerar en cada árbol\n",
    "\n",
    "    \"min_child_weight\": [0.001, 0.002, 0.0025, 0.0026, 0.0027, 0.003, 0.004, 0.005, 0.007, 0.008, 0.009],\n",
    "    # Peso mínimo necesario para crear un nuevo nodo en el árbol\n",
    "\n",
    "    \"learning_rate\": [0.1, 0.02, 0.03, 0.04, 0.07, 0.005, 0.003, 0.001],\n",
    "    # Tasa de aprendizaje del modelo\n",
    "\n",
    "    'subsample': [1],\n",
    "    # Fracción de muestras a utilizar para el entrenamiento de cada árbol\n",
    "\n",
    "    \"objective\": ['binary'],\n",
    "    # Tipo de problema a resolver (clasificación binaria en este caso)\n",
    "\n",
    "    \"importance_type\": [\"gini\", \"entropy\"],\n",
    "    # Tipo de importancia de las características\n",
    "\n",
    "    \"boosting_type\": [\"dart\", \"goss\", \"rf\", \"gbdt\"],\n",
    "    # Tipo de boosting a probar\n",
    "    \n",
    "    #\"is_unbalance\": ['True'],\n",
    "\n",
    "    \"scale_pos_weight\" : [0.002, 0.00002] ,}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4f395c07-c0d3-41f5-abb4-e795e5ec160a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Parámetros para la búsqueda aleatoria de hiperparámetros\n",
    "param_testeo = {\n",
    "    \"n_estimators\": [5, 10, 15, 20, 25, 30, 35, 50],\n",
    "    # Número de estimadores (árboles) a probar\n",
    "\n",
    "    \"num_leaves\": [ 28, 29, 30, 31, 32, 33],\n",
    "    # Número máximo de nodos hoja en un árbol\n",
    "\n",
    "    \"max_depth\": [ 16, 17, 18, 19, 20, 21, 22, 23, 24],\n",
    "    # Profundidad máxima de un árbol\n",
    "\n",
    "    \"colsample_bytree\": [ 0.58, 0.6, 0.62, 0.68],\n",
    "    # Fracción de características a considerar en cada árbol\n",
    "\n",
    "    \"min_child_weight\": [ 0.008, 0.0085 ,0.009, 0.0095],\n",
    "    # Peso mínimo necesario para crear un nuevo nodo en el árbol\n",
    "\n",
    "    \"learning_rate\": [0.1, 0.02, 0.04, 0.05,0.06, 0.07, 0.005, 0.001],\n",
    "    # Tasa de aprendizaje del modelo\n",
    "\n",
    "    'subsample': [1],\n",
    "    # Fracción de muestras a utilizar para el entrenamiento de cada árbol\n",
    "\n",
    "    \"objective\": ['binary'],\n",
    "    # Tipo de problema a resolver (clasificación binaria en este caso)\n",
    "\n",
    "    \"importance_type\": [\"gini\", \"entropy\"],\n",
    "    # Tipo de importancia de las características\n",
    "\n",
    "    \"boosting_type\": [\"dart\", \"goss\", \"rf\", \"gbdt\"],\n",
    "    # Tipo de boosting a probar\n",
    "    \n",
    "    \"is_unbalance\": ['True'],\n",
    "\n",
    "    \"scale_pos_weight\" : [0.002, 0.00002] ,}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d58842c3-f42c-402f-bae6-08030d6e91bb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# \"scale_pos_weight\": [2, 5, 10, 20, 24],\n",
    "# \"is_unbalance\": ['True']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "28b5e1a0-8b10-4d1d-8d27-9e0915578d16",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Número de combinaciones de hiperparámetros a probar durante la búsqueda aleatoria\n",
    "n_HP_points_to_test = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dbb03a6e-bd9c-4bd7-bf0e-981e82c3e2b5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def entrenar_modelo_con_busqueda_aleatoria(X, Y, fit_parameters, param_testeo, n_HP_points_to_test=100, random_state=87):\n",
    "    \"\"\"\n",
    "    Entrena un modelo utilizando LightGBM con búsqueda aleatoria de hiperparámetros.\n",
    "\n",
    "    Parameters:\n",
    "    - X: Características del conjunto de datos.\n",
    "    - Y: Etiquetas del conjunto de datos.\n",
    "    - fit_parameters: Parámetros para el entrenamiento y evaluación del modelo.\n",
    "    - param_testeo: Parámetros para la búsqueda aleatoria de hiperparámetros.\n",
    "    - n_HP_points_to_test: Número de combinaciones de hiperparámetros a probar (predeterminado: 100).\n",
    "    - random_state: Semilla aleatoria para reproducibilidad (predeterminado: 87).\n",
    "\n",
    "    Returns:\n",
    "    - Objeto de resultados de RandomizedSearchCV.\n",
    "    \"\"\"\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=random_state)\n",
    "\n",
    "    # Limpiar y estandarizar los nombres de las columnas (llamando a la función anterior)\n",
    "    X_train = limpiar_nombres_columnas(X_train)\n",
    "    X_test = limpiar_nombres_columnas(X_test)\n",
    "\n",
    "    # Crear un clasificador LightGBM y realizar una búsqueda aleatoria de hiperparámetros\n",
    "    lgbm = LGBMClassifier(random_state=random_state)\n",
    "    result_trainRandom = RandomizedSearchCV(\n",
    "                        estimator=lgbm, \n",
    "                        param_distributions=param_testeo, \n",
    "                        n_iter=n_HP_points_to_test,\n",
    "                        scoring='f1_micro',\n",
    "                        cv=3,\n",
    "                        refit=True,\n",
    "                        random_state=random_state,\n",
    "                        verbose=True)\n",
    "\n",
    "    # Entrenar el modelo utilizando los datos de entrenamiento y los parámetros de ajuste\n",
    "    result_trainRandom.fit(X_train, y_train, **fit_parameters)\n",
    "\n",
    "    return result_trainRandom\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4ebf1652-f079-404e-92fb-1b6cb5fd1805",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 122, number of negative: 4202823\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013616 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1781\n",
      "[LightGBM] [Info] Number of data points in the train set: 4202945, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000029 -> initscore=-10.447246\n",
      "[LightGBM] [Info] Start training from score -10.447246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 122, number of negative: 4202823\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017665 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1780\n",
      "[LightGBM] [Info] Number of data points in the train set: 4202945, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000029 -> initscore=-10.447246\n",
      "[LightGBM] [Info] Start training from score -10.447246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 122, number of negative: 4202824\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014133 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1781\n",
      "[LightGBM] [Info] Number of data points in the train set: 4202946, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000029 -> initscore=-10.447246\n",
      "[LightGBM] [Info] Start training from score -10.447246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 122, number of negative: 4202823\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018070 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1781\n",
      "[LightGBM] [Info] Number of data points in the train set: 4202945, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000029 -> initscore=-10.447246\n",
      "[LightGBM] [Info] Start training from score -10.447246\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 122, number of negative: 4202823\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019332 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1780\n",
      "[LightGBM] [Info] Number of data points in the train set: 4202945, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000029 -> initscore=-10.447246\n",
      "[LightGBM] [Info] Start training from score -10.447246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 122, number of negative: 4202824\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021812 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1781\n",
      "[LightGBM] [Info] Number of data points in the train set: 4202946, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000029 -> initscore=-10.447246\n",
      "[LightGBM] [Info] Start training from score -10.447246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 122, number of negative: 4202823\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017554 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1781\n",
      "[LightGBM] [Info] Number of data points in the train set: 4202945, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000029 -> initscore=-10.447246\n",
      "[LightGBM] [Info] Start training from score -10.447246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 122, number of negative: 4202823\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011712 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1780\n",
      "[LightGBM] [Info] Number of data points in the train set: 4202945, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000029 -> initscore=-10.447246\n",
      "[LightGBM] [Info] Start training from score -10.447246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 122, number of negative: 4202824\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015570 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1781\n",
      "[LightGBM] [Info] Number of data points in the train set: 4202946, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000029 -> initscore=-10.447246\n",
      "[LightGBM] [Info] Start training from score -10.447246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 122, number of negative: 4202823\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021760 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1781\n",
      "[LightGBM] [Info] Number of data points in the train set: 4202945, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000029 -> initscore=-10.447246\n",
      "[LightGBM] [Info] Start training from score -10.447246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 122, number of negative: 4202823\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019247 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1780\n",
      "[LightGBM] [Info] Number of data points in the train set: 4202945, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000029 -> initscore=-10.447246\n",
      "[LightGBM] [Info] Start training from score -10.447246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 122, number of negative: 4202824\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015124 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1781\n",
      "[LightGBM] [Info] Number of data points in the train set: 4202946, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000029 -> initscore=-10.447246\n",
      "[LightGBM] [Info] Start training from score -10.447246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 122, number of negative: 4202823\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019096 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1781\n",
      "[LightGBM] [Info] Number of data points in the train set: 4202945, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000029 -> initscore=-10.447246\n",
      "[LightGBM] [Info] Start training from score -10.447246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 122, number of negative: 4202823\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020313 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1780\n",
      "[LightGBM] [Info] Number of data points in the train set: 4202945, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000029 -> initscore=-10.447246\n",
      "[LightGBM] [Info] Start training from score -10.447246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 122, number of negative: 4202824\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023033 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1781\n",
      "[LightGBM] [Info] Number of data points in the train set: 4202946, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000029 -> initscore=-10.447246\n",
      "[LightGBM] [Info] Start training from score -10.447246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 122, number of negative: 4202823\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020224 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1781\n",
      "[LightGBM] [Info] Number of data points in the train set: 4202945, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000029 -> initscore=-10.447246\n",
      "[LightGBM] [Info] Start training from score -10.447246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 122, number of negative: 4202823\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021110 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1780\n",
      "[LightGBM] [Info] Number of data points in the train set: 4202945, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000029 -> initscore=-10.447246\n",
      "[LightGBM] [Info] Start training from score -10.447246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 122, number of negative: 4202824\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015623 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1781\n",
      "[LightGBM] [Info] Number of data points in the train set: 4202946, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000029 -> initscore=-10.447246\n",
      "[LightGBM] [Info] Start training from score -10.447246\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 122, number of negative: 4202823\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020770 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1781\n",
      "[LightGBM] [Info] Number of data points in the train set: 4202945, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000029 -> initscore=-10.447246\n",
      "[LightGBM] [Info] Start training from score -10.447246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 122, number of negative: 4202823\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019981 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1780\n",
      "[LightGBM] [Info] Number of data points in the train set: 4202945, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000029 -> initscore=-10.447246\n",
      "[LightGBM] [Info] Start training from score -10.447246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 122, number of negative: 4202824\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021936 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1781\n",
      "[LightGBM] [Info] Number of data points in the train set: 4202946, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000029 -> initscore=-10.447246\n",
      "[LightGBM] [Info] Start training from score -10.447246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 122, number of negative: 4202823\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019523 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1781\n",
      "[LightGBM] [Info] Number of data points in the train set: 4202945, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000029 -> initscore=-10.447246\n",
      "[LightGBM] [Info] Start training from score -10.447246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 122, number of negative: 4202823\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018697 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1780\n",
      "[LightGBM] [Info] Number of data points in the train set: 4202945, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000029 -> initscore=-10.447246\n",
      "[LightGBM] [Info] Start training from score -10.447246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 122, number of negative: 4202824\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021000 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1781\n",
      "[LightGBM] [Info] Number of data points in the train set: 4202946, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000029 -> initscore=-10.447246\n",
      "[LightGBM] [Info] Start training from score -10.447246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 122, number of negative: 4202823\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020160 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1781\n",
      "[LightGBM] [Info] Number of data points in the train set: 4202945, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000029 -> initscore=-10.447246\n",
      "[LightGBM] [Info] Start training from score -10.447246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 122, number of negative: 4202823\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017740 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1780\n",
      "[LightGBM] [Info] Number of data points in the train set: 4202945, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000029 -> initscore=-10.447246\n",
      "[LightGBM] [Info] Start training from score -10.447246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 122, number of negative: 4202824\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022041 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1781\n",
      "[LightGBM] [Info] Number of data points in the train set: 4202946, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000029 -> initscore=-10.447246\n",
      "[LightGBM] [Info] Start training from score -10.447246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 122, number of negative: 4202823\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018038 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1781\n",
      "[LightGBM] [Info] Number of data points in the train set: 4202945, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000029 -> initscore=-10.447246\n",
      "[LightGBM] [Info] Start training from score -10.447246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 122, number of negative: 4202823\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019290 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1780\n",
      "[LightGBM] [Info] Number of data points in the train set: 4202945, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000029 -> initscore=-10.447246\n",
      "[LightGBM] [Info] Start training from score -10.447246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 122, number of negative: 4202824\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012723 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1781\n",
      "[LightGBM] [Info] Number of data points in the train set: 4202946, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000029 -> initscore=-10.447246\n",
      "[LightGBM] [Info] Start training from score -10.447246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 122, number of negative: 4202823\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017797 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1781\n",
      "[LightGBM] [Info] Number of data points in the train set: 4202945, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000029 -> initscore=-10.447246\n",
      "[LightGBM] [Info] Start training from score -10.447246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 122, number of negative: 4202823\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017356 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1780\n",
      "[LightGBM] [Info] Number of data points in the train set: 4202945, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000029 -> initscore=-10.447246\n",
      "[LightGBM] [Info] Start training from score -10.447246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 122, number of negative: 4202824\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014889 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1781\n",
      "[LightGBM] [Info] Number of data points in the train set: 4202946, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000029 -> initscore=-10.447246\n",
      "[LightGBM] [Info] Start training from score -10.447246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 122, number of negative: 4202823\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021778 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1781\n",
      "[LightGBM] [Info] Number of data points in the train set: 4202945, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000029 -> initscore=-10.447246\n",
      "[LightGBM] [Info] Start training from score -10.447246\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 122, number of negative: 4202823\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021663 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1780\n",
      "[LightGBM] [Info] Number of data points in the train set: 4202945, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000029 -> initscore=-10.447246\n",
      "[LightGBM] [Info] Start training from score -10.447246\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 122, number of negative: 4202824\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013194 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1781\n",
      "[LightGBM] [Info] Number of data points in the train set: 4202946, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000029 -> initscore=-10.447246\n",
      "[LightGBM] [Info] Start training from score -10.447246\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 122, number of negative: 4202823\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021803 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1781\n",
      "[LightGBM] [Info] Number of data points in the train set: 4202945, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000029 -> initscore=-10.447246\n",
      "[LightGBM] [Info] Start training from score -10.447246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 122, number of negative: 4202823\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018345 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1780\n",
      "[LightGBM] [Info] Number of data points in the train set: 4202945, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000029 -> initscore=-10.447246\n",
      "[LightGBM] [Info] Start training from score -10.447246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 122, number of negative: 4202824\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014765 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1781\n",
      "[LightGBM] [Info] Number of data points in the train set: 4202946, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000029 -> initscore=-10.447246\n",
      "[LightGBM] [Info] Start training from score -10.447246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 122, number of negative: 4202823\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019661 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1781\n",
      "[LightGBM] [Info] Number of data points in the train set: 4202945, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000029 -> initscore=-10.447246\n",
      "[LightGBM] [Info] Start training from score -10.447246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 122, number of negative: 4202823\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018197 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1780\n",
      "[LightGBM] [Info] Number of data points in the train set: 4202945, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000029 -> initscore=-10.447246\n",
      "[LightGBM] [Info] Start training from score -10.447246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 122, number of negative: 4202824\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020698 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1781\n",
      "[LightGBM] [Info] Number of data points in the train set: 4202946, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000029 -> initscore=-10.447246\n",
      "[LightGBM] [Info] Start training from score -10.447246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 122, number of negative: 4202823\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019301 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1781\n",
      "[LightGBM] [Info] Number of data points in the train set: 4202945, number of used features: 7\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000029 -> initscore=-10.447246\n",
      "[LightGBM] [Info] Start training from score -10.447246\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 122, number of negative: 4202823\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017973 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1780\n",
      "[LightGBM] [Info] Number of data points in the train set: 4202945, number of used features: 7\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000029 -> initscore=-10.447246\n",
      "[LightGBM] [Info] Start training from score -10.447246\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 122, number of negative: 4202824\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020594 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1781\n",
      "[LightGBM] [Info] Number of data points in the train set: 4202946, number of used features: 7\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000029 -> initscore=-10.447246\n",
      "[LightGBM] [Info] Start training from score -10.447246\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 122, number of negative: 4202823\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021490 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1781\n",
      "[LightGBM] [Info] Number of data points in the train set: 4202945, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000029 -> initscore=-10.447246\n",
      "[LightGBM] [Info] Start training from score -10.447246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 122, number of negative: 4202823\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021382 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1780\n",
      "[LightGBM] [Info] Number of data points in the train set: 4202945, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000029 -> initscore=-10.447246\n",
      "[LightGBM] [Info] Start training from score -10.447246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 122, number of negative: 4202824\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013473 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1781\n",
      "[LightGBM] [Info] Number of data points in the train set: 4202946, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000029 -> initscore=-10.447246\n",
      "[LightGBM] [Info] Start training from score -10.447246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 122, number of negative: 4202823\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019858 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1781\n",
      "[LightGBM] [Info] Number of data points in the train set: 4202945, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000029 -> initscore=-10.447246\n",
      "[LightGBM] [Info] Start training from score -10.447246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 122, number of negative: 4202823\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022612 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1780\n",
      "[LightGBM] [Info] Number of data points in the train set: 4202945, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000029 -> initscore=-10.447246\n",
      "[LightGBM] [Info] Start training from score -10.447246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 122, number of negative: 4202824\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020894 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1781\n",
      "[LightGBM] [Info] Number of data points in the train set: 4202946, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000029 -> initscore=-10.447246\n",
      "[LightGBM] [Info] Start training from score -10.447246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 122, number of negative: 4202823\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018196 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1781\n",
      "[LightGBM] [Info] Number of data points in the train set: 4202945, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000029 -> initscore=-10.447246\n",
      "[LightGBM] [Info] Start training from score -10.447246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 122, number of negative: 4202823\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017809 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1780\n",
      "[LightGBM] [Info] Number of data points in the train set: 4202945, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000029 -> initscore=-10.447246\n",
      "[LightGBM] [Info] Start training from score -10.447246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 122, number of negative: 4202824\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012314 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1781\n",
      "[LightGBM] [Info] Number of data points in the train set: 4202946, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000029 -> initscore=-10.447246\n",
      "[LightGBM] [Info] Start training from score -10.447246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 122, number of negative: 4202823\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021489 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1781\n",
      "[LightGBM] [Info] Number of data points in the train set: 4202945, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000029 -> initscore=-10.447246\n",
      "[LightGBM] [Info] Start training from score -10.447246\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 122, number of negative: 4202823\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019289 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1780\n",
      "[LightGBM] [Info] Number of data points in the train set: 4202945, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000029 -> initscore=-10.447246\n",
      "[LightGBM] [Info] Start training from score -10.447246\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 122, number of negative: 4202824\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015267 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1781\n",
      "[LightGBM] [Info] Number of data points in the train set: 4202946, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000029 -> initscore=-10.447246\n",
      "[LightGBM] [Info] Start training from score -10.447246\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 122, number of negative: 4202823\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021870 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1781\n",
      "[LightGBM] [Info] Number of data points in the train set: 4202945, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000029 -> initscore=-10.447246\n",
      "[LightGBM] [Info] Start training from score -10.447246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 122, number of negative: 4202823\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019838 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1780\n",
      "[LightGBM] [Info] Number of data points in the train set: 4202945, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000029 -> initscore=-10.447246\n",
      "[LightGBM] [Info] Start training from score -10.447246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 122, number of negative: 4202824\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020963 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1781\n",
      "[LightGBM] [Info] Number of data points in the train set: 4202946, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000029 -> initscore=-10.447246\n",
      "[LightGBM] [Info] Start training from score -10.447246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 122, number of negative: 4202823\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016166 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1781\n",
      "[LightGBM] [Info] Number of data points in the train set: 4202945, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000029 -> initscore=-10.447246\n",
      "[LightGBM] [Info] Start training from score -10.447246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 122, number of negative: 4202823\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018642 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1780\n",
      "[LightGBM] [Info] Number of data points in the train set: 4202945, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000029 -> initscore=-10.447246\n",
      "[LightGBM] [Info] Start training from score -10.447246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 122, number of negative: 4202824\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012785 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1781\n",
      "[LightGBM] [Info] Number of data points in the train set: 4202946, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000029 -> initscore=-10.447246\n",
      "[LightGBM] [Info] Start training from score -10.447246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 122, number of negative: 4202823\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022530 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1781\n",
      "[LightGBM] [Info] Number of data points in the train set: 4202945, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000029 -> initscore=-10.447246\n",
      "[LightGBM] [Info] Start training from score -10.447246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 122, number of negative: 4202823\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021303 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1780\n",
      "[LightGBM] [Info] Number of data points in the train set: 4202945, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000029 -> initscore=-10.447246\n",
      "[LightGBM] [Info] Start training from score -10.447246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 122, number of negative: 4202824\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022263 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1781\n",
      "[LightGBM] [Info] Number of data points in the train set: 4202946, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000029 -> initscore=-10.447246\n",
      "[LightGBM] [Info] Start training from score -10.447246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 122, number of negative: 4202823\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015560 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1781\n",
      "[LightGBM] [Info] Number of data points in the train set: 4202945, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000029 -> initscore=-10.447246\n",
      "[LightGBM] [Info] Start training from score -10.447246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 122, number of negative: 4202823\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018051 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1780\n",
      "[LightGBM] [Info] Number of data points in the train set: 4202945, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000029 -> initscore=-10.447246\n",
      "[LightGBM] [Info] Start training from score -10.447246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 122, number of negative: 4202824\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022226 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1781\n",
      "[LightGBM] [Info] Number of data points in the train set: 4202946, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000029 -> initscore=-10.447246\n",
      "[LightGBM] [Info] Start training from score -10.447246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 122, number of negative: 4202823\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015465 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1781\n",
      "[LightGBM] [Info] Number of data points in the train set: 4202945, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000029 -> initscore=-10.447246\n",
      "[LightGBM] [Info] Start training from score -10.447246\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 122, number of negative: 4202823\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019821 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1780\n",
      "[LightGBM] [Info] Number of data points in the train set: 4202945, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000029 -> initscore=-10.447246\n",
      "[LightGBM] [Info] Start training from score -10.447246\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 122, number of negative: 4202824\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012642 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1781\n",
      "[LightGBM] [Info] Number of data points in the train set: 4202946, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000029 -> initscore=-10.447246\n",
      "[LightGBM] [Info] Start training from score -10.447246\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 122, number of negative: 4202823\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020157 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1781\n",
      "[LightGBM] [Info] Number of data points in the train set: 4202945, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000029 -> initscore=-10.447246\n",
      "[LightGBM] [Info] Start training from score -10.447246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 122, number of negative: 4202823\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019170 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1780\n",
      "[LightGBM] [Info] Number of data points in the train set: 4202945, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000029 -> initscore=-10.447246\n",
      "[LightGBM] [Info] Start training from score -10.447246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 122, number of negative: 4202824\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021194 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1781\n",
      "[LightGBM] [Info] Number of data points in the train set: 4202946, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000029 -> initscore=-10.447246\n",
      "[LightGBM] [Info] Start training from score -10.447246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 122, number of negative: 4202823\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018627 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1781\n",
      "[LightGBM] [Info] Number of data points in the train set: 4202945, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000029 -> initscore=-10.447246\n",
      "[LightGBM] [Info] Start training from score -10.447246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 122, number of negative: 4202823\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018506 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1780\n",
      "[LightGBM] [Info] Number of data points in the train set: 4202945, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000029 -> initscore=-10.447246\n",
      "[LightGBM] [Info] Start training from score -10.447246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 122, number of negative: 4202824\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020386 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1781\n",
      "[LightGBM] [Info] Number of data points in the train set: 4202946, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000029 -> initscore=-10.447246\n",
      "[LightGBM] [Info] Start training from score -10.447246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 122, number of negative: 4202823\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018642 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1781\n",
      "[LightGBM] [Info] Number of data points in the train set: 4202945, number of used features: 7\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000029 -> initscore=-10.447246\n",
      "[LightGBM] [Info] Start training from score -10.447246\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 122, number of negative: 4202823\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021403 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1780\n",
      "[LightGBM] [Info] Number of data points in the train set: 4202945, number of used features: 7\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000029 -> initscore=-10.447246\n",
      "[LightGBM] [Info] Start training from score -10.447246\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 122, number of negative: 4202824\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014587 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1781\n",
      "[LightGBM] [Info] Number of data points in the train set: 4202946, number of used features: 7\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000029 -> initscore=-10.447246\n",
      "[LightGBM] [Info] Start training from score -10.447246\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 122, number of negative: 4202823\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018770 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1781\n",
      "[LightGBM] [Info] Number of data points in the train set: 4202945, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000029 -> initscore=-10.447246\n",
      "[LightGBM] [Info] Start training from score -10.447246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 122, number of negative: 4202823\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018451 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1780\n",
      "[LightGBM] [Info] Number of data points in the train set: 4202945, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000029 -> initscore=-10.447246\n",
      "[LightGBM] [Info] Start training from score -10.447246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 122, number of negative: 4202824\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015018 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1781\n",
      "[LightGBM] [Info] Number of data points in the train set: 4202946, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000029 -> initscore=-10.447246\n",
      "[LightGBM] [Info] Start training from score -10.447246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 122, number of negative: 4202823\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019069 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1781\n",
      "[LightGBM] [Info] Number of data points in the train set: 4202945, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000029 -> initscore=-10.447246\n",
      "[LightGBM] [Info] Start training from score -10.447246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 122, number of negative: 4202823\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018057 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1780\n",
      "[LightGBM] [Info] Number of data points in the train set: 4202945, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000029 -> initscore=-10.447246\n",
      "[LightGBM] [Info] Start training from score -10.447246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 122, number of negative: 4202824\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014079 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1781\n",
      "[LightGBM] [Info] Number of data points in the train set: 4202946, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000029 -> initscore=-10.447246\n",
      "[LightGBM] [Info] Start training from score -10.447246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 122, number of negative: 4202823\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021759 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1781\n",
      "[LightGBM] [Info] Number of data points in the train set: 4202945, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000029 -> initscore=-10.447246\n",
      "[LightGBM] [Info] Start training from score -10.447246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 122, number of negative: 4202823\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016503 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1780\n",
      "[LightGBM] [Info] Number of data points in the train set: 4202945, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000029 -> initscore=-10.447246\n",
      "[LightGBM] [Info] Start training from score -10.447246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 122, number of negative: 4202824\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011185 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1781\n",
      "[LightGBM] [Info] Number of data points in the train set: 4202946, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000029 -> initscore=-10.447246\n",
      "[LightGBM] [Info] Start training from score -10.447246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 122, number of negative: 4202823\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016568 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1781\n",
      "[LightGBM] [Info] Number of data points in the train set: 4202945, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000029 -> initscore=-10.447246\n",
      "[LightGBM] [Info] Start training from score -10.447246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 122, number of negative: 4202823\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015802 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1780\n",
      "[LightGBM] [Info] Number of data points in the train set: 4202945, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000029 -> initscore=-10.447246\n",
      "[LightGBM] [Info] Start training from score -10.447246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 122, number of negative: 4202824\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021656 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1781\n",
      "[LightGBM] [Info] Number of data points in the train set: 4202946, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000029 -> initscore=-10.447246\n",
      "[LightGBM] [Info] Start training from score -10.447246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 122, number of negative: 4202823\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022974 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1781\n",
      "[LightGBM] [Info] Number of data points in the train set: 4202945, number of used features: 7\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000029 -> initscore=-10.447246\n",
      "[LightGBM] [Info] Start training from score -10.447246\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 122, number of negative: 4202823\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022471 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1780\n",
      "[LightGBM] [Info] Number of data points in the train set: 4202945, number of used features: 7\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000029 -> initscore=-10.447246\n",
      "[LightGBM] [Info] Start training from score -10.447246\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 122, number of negative: 4202824\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014919 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1781\n",
      "[LightGBM] [Info] Number of data points in the train set: 4202946, number of used features: 7\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000029 -> initscore=-10.447246\n",
      "[LightGBM] [Info] Start training from score -10.447246\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 122, number of negative: 4202823\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.024961 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1781\n",
      "[LightGBM] [Info] Number of data points in the train set: 4202945, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000029 -> initscore=-10.447246\n",
      "[LightGBM] [Info] Start training from score -10.447246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 122, number of negative: 4202823\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016412 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1780\n",
      "[LightGBM] [Info] Number of data points in the train set: 4202945, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000029 -> initscore=-10.447246\n",
      "[LightGBM] [Info] Start training from score -10.447246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 122, number of negative: 4202824\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013898 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1781\n",
      "[LightGBM] [Info] Number of data points in the train set: 4202946, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000029 -> initscore=-10.447246\n",
      "[LightGBM] [Info] Start training from score -10.447246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 122, number of negative: 4202823\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022931 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1781\n",
      "[LightGBM] [Info] Number of data points in the train set: 4202945, number of used features: 7\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000029 -> initscore=-10.447246\n",
      "[LightGBM] [Info] Start training from score -10.447246\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 122, number of negative: 4202823\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022578 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1780\n",
      "[LightGBM] [Info] Number of data points in the train set: 4202945, number of used features: 7\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000029 -> initscore=-10.447246\n",
      "[LightGBM] [Info] Start training from score -10.447246\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 122, number of negative: 4202824\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015909 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1781\n",
      "[LightGBM] [Info] Number of data points in the train set: 4202946, number of used features: 7\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000029 -> initscore=-10.447246\n",
      "[LightGBM] [Info] Start training from score -10.447246\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 122, number of negative: 4202823\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020261 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1781\n",
      "[LightGBM] [Info] Number of data points in the train set: 4202945, number of used features: 7\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000029 -> initscore=-10.447246\n",
      "[LightGBM] [Info] Start training from score -10.447246\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 122, number of negative: 4202823\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020840 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1780\n",
      "[LightGBM] [Info] Number of data points in the train set: 4202945, number of used features: 7\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000029 -> initscore=-10.447246\n",
      "[LightGBM] [Info] Start training from score -10.447246\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 122, number of negative: 4202824\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019205 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1781\n",
      "[LightGBM] [Info] Number of data points in the train set: 4202946, number of used features: 7\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000029 -> initscore=-10.447246\n",
      "[LightGBM] [Info] Start training from score -10.447246\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 122, number of negative: 4202823\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022604 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1781\n",
      "[LightGBM] [Info] Number of data points in the train set: 4202945, number of used features: 7\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000029 -> initscore=-10.447246\n",
      "[LightGBM] [Info] Start training from score -10.447246\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 122, number of negative: 4202823\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017988 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1780\n",
      "[LightGBM] [Info] Number of data points in the train set: 4202945, number of used features: 7\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000029 -> initscore=-10.447246\n",
      "[LightGBM] [Info] Start training from score -10.447246\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 122, number of negative: 4202824\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020438 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1781\n",
      "[LightGBM] [Info] Number of data points in the train set: 4202946, number of used features: 7\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000029 -> initscore=-10.447246\n",
      "[LightGBM] [Info] Start training from score -10.447246\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 122, number of negative: 4202823\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021241 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1781\n",
      "[LightGBM] [Info] Number of data points in the train set: 4202945, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000029 -> initscore=-10.447246\n",
      "[LightGBM] [Info] Start training from score -10.447246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 122, number of negative: 4202823\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017305 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1780\n",
      "[LightGBM] [Info] Number of data points in the train set: 4202945, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000029 -> initscore=-10.447246\n",
      "[LightGBM] [Info] Start training from score -10.447246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 122, number of negative: 4202824\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016985 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1781\n",
      "[LightGBM] [Info] Number of data points in the train set: 4202946, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000029 -> initscore=-10.447246\n",
      "[LightGBM] [Info] Start training from score -10.447246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 122, number of negative: 4202823\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021102 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1781\n",
      "[LightGBM] [Info] Number of data points in the train set: 4202945, number of used features: 7\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000029 -> initscore=-10.447246\n",
      "[LightGBM] [Info] Start training from score -10.447246\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 122, number of negative: 4202823\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019273 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1780\n",
      "[LightGBM] [Info] Number of data points in the train set: 4202945, number of used features: 7\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000029 -> initscore=-10.447246\n",
      "[LightGBM] [Info] Start training from score -10.447246\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 122, number of negative: 4202824\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020922 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1781\n",
      "[LightGBM] [Info] Number of data points in the train set: 4202946, number of used features: 7\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000029 -> initscore=-10.447246\n",
      "[LightGBM] [Info] Start training from score -10.447246\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 122, number of negative: 4202823\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020703 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1781\n",
      "[LightGBM] [Info] Number of data points in the train set: 4202945, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000029 -> initscore=-10.447246\n",
      "[LightGBM] [Info] Start training from score -10.447246\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 122, number of negative: 4202823\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019338 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1780\n",
      "[LightGBM] [Info] Number of data points in the train set: 4202945, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000029 -> initscore=-10.447246\n",
      "[LightGBM] [Info] Start training from score -10.447246\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 122, number of negative: 4202824\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020336 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1781\n",
      "[LightGBM] [Info] Number of data points in the train set: 4202946, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000029 -> initscore=-10.447246\n",
      "[LightGBM] [Info] Start training from score -10.447246\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 122, number of negative: 4202823\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023282 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1781\n",
      "[LightGBM] [Info] Number of data points in the train set: 4202945, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000029 -> initscore=-10.447246\n",
      "[LightGBM] [Info] Start training from score -10.447246\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 122, number of negative: 4202823\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017338 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1780\n",
      "[LightGBM] [Info] Number of data points in the train set: 4202945, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000029 -> initscore=-10.447246\n",
      "[LightGBM] [Info] Start training from score -10.447246\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 122, number of negative: 4202824\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012035 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1781\n",
      "[LightGBM] [Info] Number of data points in the train set: 4202946, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000029 -> initscore=-10.447246\n",
      "[LightGBM] [Info] Start training from score -10.447246\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[50], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mentrenar_modelo_con_busqueda_aleatoria\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfit_parameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_testeo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_HP_points_to_test\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m87\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[49], line 35\u001b[0m, in \u001b[0;36mentrenar_modelo_con_busqueda_aleatoria\u001b[0;34m(X, Y, fit_parameters, param_testeo, n_HP_points_to_test, random_state)\u001b[0m\n\u001b[1;32m     24\u001b[0m result_trainRandom \u001b[38;5;241m=\u001b[39m RandomizedSearchCV(\n\u001b[1;32m     25\u001b[0m                     estimator\u001b[38;5;241m=\u001b[39mlgbm, \n\u001b[1;32m     26\u001b[0m                     param_distributions\u001b[38;5;241m=\u001b[39mparam_testeo, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     31\u001b[0m                     random_state\u001b[38;5;241m=\u001b[39mrandom_state,\n\u001b[1;32m     32\u001b[0m                     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# Entrenar el modelo utilizando los datos de entrenamiento y los parámetros de ajuste\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m \u001b[43mresult_trainRandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_parameters\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result_trainRandom\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/base.py:1351\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1344\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1346\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1347\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1348\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1349\u001b[0m     )\n\u001b[1;32m   1350\u001b[0m ):\n\u001b[0;32m-> 1351\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/model_selection/_search.py:970\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    964\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    965\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    966\u001b[0m     )\n\u001b[1;32m    968\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 970\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    973\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    974\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1914\u001b[0m, in \u001b[0;36mRandomizedSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1912\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1913\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1914\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1915\u001b[0m \u001b[43m        \u001b[49m\u001b[43mParameterSampler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1916\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_distributions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\n\u001b[1;32m   1917\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1918\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/model_selection/_search.py:916\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    909\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    910\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    911\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    912\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    913\u001b[0m         )\n\u001b[1;32m    914\u001b[0m     )\n\u001b[0;32m--> 916\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    918\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    922\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    924\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    925\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    926\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    927\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    928\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    929\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    930\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    931\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    932\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    934\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    935\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    936\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    937\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    938\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    939\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/utils/parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     66\u001b[0m )\n\u001b[0;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/joblib/parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1861\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1862\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1863\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1865\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1866\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1867\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1868\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1869\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1870\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/joblib/parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1790\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1791\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1792\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1793\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1794\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/utils/parallel.py:129\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    127\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:912\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    909\u001b[0m result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit_error\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    911\u001b[0m fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n\u001b[0;32m--> 912\u001b[0m test_scores \u001b[38;5;241m=\u001b[39m \u001b[43m_score\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    913\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscore_params_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_score\u001b[49m\n\u001b[1;32m    914\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    915\u001b[0m score_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time \u001b[38;5;241m-\u001b[39m fit_time\n\u001b[1;32m    916\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_train_score:\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:977\u001b[0m, in \u001b[0;36m_score\u001b[0;34m(estimator, X_test, y_test, scorer, score_params, error_score)\u001b[0m\n\u001b[1;32m    975\u001b[0m         scores \u001b[38;5;241m=\u001b[39m scorer(estimator, X_test, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mscore_params)\n\u001b[1;32m    976\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 977\u001b[0m         scores \u001b[38;5;241m=\u001b[39m \u001b[43mscorer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mscore_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    978\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    979\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(scorer, _MultimetricScorer):\n\u001b[1;32m    980\u001b[0m         \u001b[38;5;66;03m# If `_MultimetricScorer` raises exception, the `error_score`\u001b[39;00m\n\u001b[1;32m    981\u001b[0m         \u001b[38;5;66;03m# parameter is equal to \"raise\".\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/metrics/_scorer.py:253\u001b[0m, in \u001b[0;36m_BaseScorer.__call__\u001b[0;34m(self, estimator, X, y_true, sample_weight, **kwargs)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    251\u001b[0m     _kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msample_weight\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m sample_weight\n\u001b[0;32m--> 253\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_cached_call\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/metrics/_scorer.py:345\u001b[0m, in \u001b[0;36m_Scorer._score\u001b[0;34m(self, method_caller, estimator, X, y_true, **kwargs)\u001b[0m\n\u001b[1;32m    343\u001b[0m pos_label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m is_regressor(estimator) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_pos_label()\n\u001b[1;32m    344\u001b[0m response_method \u001b[38;5;241m=\u001b[39m _check_response_method(estimator, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_method)\n\u001b[0;32m--> 345\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmethod_caller\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    346\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_method\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos_label\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    349\u001b[0m scoring_kwargs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_kwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs}\n\u001b[1;32m    350\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sign \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_score_func(y_true, y_pred, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mscoring_kwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/metrics/_scorer.py:87\u001b[0m, in \u001b[0;36m_cached_call\u001b[0;34m(cache, estimator, response_method, *args, **kwargs)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m response_method \u001b[38;5;129;01min\u001b[39;00m cache:\n\u001b[1;32m     85\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cache[response_method]\n\u001b[0;32m---> 87\u001b[0m result, _ \u001b[38;5;241m=\u001b[39m \u001b[43m_get_response_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_method\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     92\u001b[0m     cache[response_method] \u001b[38;5;241m=\u001b[39m result\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/utils/_response.py:210\u001b[0m, in \u001b[0;36m_get_response_values\u001b[0;34m(estimator, X, response_method, pos_label, return_response_method_used)\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m pos_label \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m target_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    208\u001b[0m         pos_label \u001b[38;5;241m=\u001b[39m classes[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m--> 210\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mprediction_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prediction_method\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredict_proba\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredict_log_proba\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    213\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m _process_predict_proba(\n\u001b[1;32m    214\u001b[0m         y_pred\u001b[38;5;241m=\u001b[39my_pred,\n\u001b[1;32m    215\u001b[0m         target_type\u001b[38;5;241m=\u001b[39mtarget_type,\n\u001b[1;32m    216\u001b[0m         classes\u001b[38;5;241m=\u001b[39mclasses,\n\u001b[1;32m    217\u001b[0m         pos_label\u001b[38;5;241m=\u001b[39mpos_label,\n\u001b[1;32m    218\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/lightgbm/sklearn.py:1223\u001b[0m, in \u001b[0;36mLGBMClassifier.predict\u001b[0;34m(self, X, raw_score, start_iteration, num_iteration, pred_leaf, pred_contrib, validate_features, **kwargs)\u001b[0m\n\u001b[1;32m   1211\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\n\u001b[1;32m   1212\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1213\u001b[0m     X: _LGBM_ScikitMatrixLike,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1220\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any\n\u001b[1;32m   1221\u001b[0m ):\n\u001b[1;32m   1222\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Docstring is inherited from the LGBMModel.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1223\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1224\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1225\u001b[0m \u001b[43m        \u001b[49m\u001b[43mraw_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mraw_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1226\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstart_iteration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_iteration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1227\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_iteration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_iteration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1228\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpred_leaf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpred_leaf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1229\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpred_contrib\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpred_contrib\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1230\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidate_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1231\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m   1232\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_objective) \u001b[38;5;129;01mor\u001b[39;00m raw_score \u001b[38;5;129;01mor\u001b[39;00m pred_leaf \u001b[38;5;129;01mor\u001b[39;00m pred_contrib:\n\u001b[1;32m   1234\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/lightgbm/sklearn.py:1253\u001b[0m, in \u001b[0;36mLGBMClassifier.predict_proba\u001b[0;34m(self, X, raw_score, start_iteration, num_iteration, pred_leaf, pred_contrib, validate_features, **kwargs)\u001b[0m\n\u001b[1;32m   1241\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict_proba\u001b[39m(\n\u001b[1;32m   1242\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1243\u001b[0m     X: _LGBM_ScikitMatrixLike,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1250\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any\n\u001b[1;32m   1251\u001b[0m ):\n\u001b[1;32m   1252\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Docstring is set after definition, using a template.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1253\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1254\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1255\u001b[0m \u001b[43m        \u001b[49m\u001b[43mraw_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mraw_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1256\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstart_iteration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_iteration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1257\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_iteration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_iteration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1258\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpred_leaf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpred_leaf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1259\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpred_contrib\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpred_contrib\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1260\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidate_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1261\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m   1262\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1263\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_objective) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (raw_score \u001b[38;5;129;01mor\u001b[39;00m pred_leaf \u001b[38;5;129;01mor\u001b[39;00m pred_contrib):\n\u001b[1;32m   1264\u001b[0m         _log_warning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot compute class probabilities or labels \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1265\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdue to the usage of customized objective function.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1266\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReturning raw scores instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/lightgbm/sklearn.py:961\u001b[0m, in \u001b[0;36mLGBMModel.predict\u001b[0;34m(self, X, raw_score, start_iteration, num_iteration, pred_leaf, pred_contrib, validate_features, **kwargs)\u001b[0m\n\u001b[1;32m    958\u001b[0m predict_params \u001b[38;5;241m=\u001b[39m _choose_param_value(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_threads\u001b[39m\u001b[38;5;124m\"\u001b[39m, predict_params, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)\n\u001b[1;32m    959\u001b[0m predict_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_threads\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_n_jobs(predict_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_threads\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m--> 961\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Booster\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[union-attr]\u001b[39;49;00m\n\u001b[1;32m    962\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraw_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mraw_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_iteration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_iteration\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_iteration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_iteration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    963\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpred_leaf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpred_leaf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpred_contrib\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpred_contrib\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidate_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    964\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpredict_params\u001b[49m\n\u001b[1;32m    965\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/lightgbm/basic.py:4453\u001b[0m, in \u001b[0;36mBooster.predict\u001b[0;34m(self, data, start_iteration, num_iteration, raw_score, pred_leaf, pred_contrib, data_has_header, validate_features, **kwargs)\u001b[0m\n\u001b[1;32m   4451\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   4452\u001b[0m         num_iteration \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 4453\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpredictor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4454\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4455\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstart_iteration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_iteration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4456\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_iteration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_iteration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4457\u001b[0m \u001b[43m    \u001b[49m\u001b[43mraw_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mraw_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4458\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpred_leaf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpred_leaf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4459\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpred_contrib\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpred_contrib\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4460\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_has_header\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_has_header\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4461\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidate_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_features\u001b[49m\n\u001b[1;32m   4462\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/lightgbm/basic.py:1159\u001b[0m, in \u001b[0;36m_InnerPredictor.predict\u001b[0;34m(self, data, start_iteration, num_iteration, raw_score, pred_leaf, pred_contrib, data_has_header, validate_features)\u001b[0m\n\u001b[1;32m   1152\u001b[0m     preds, nrow \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__pred_for_csc(\n\u001b[1;32m   1153\u001b[0m         csc\u001b[38;5;241m=\u001b[39mdata,\n\u001b[1;32m   1154\u001b[0m         start_iteration\u001b[38;5;241m=\u001b[39mstart_iteration,\n\u001b[1;32m   1155\u001b[0m         num_iteration\u001b[38;5;241m=\u001b[39mnum_iteration,\n\u001b[1;32m   1156\u001b[0m         predict_type\u001b[38;5;241m=\u001b[39mpredict_type\n\u001b[1;32m   1157\u001b[0m     )\n\u001b[1;32m   1158\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[0;32m-> 1159\u001b[0m     preds, nrow \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__pred_for_np2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmat\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstart_iteration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_iteration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1162\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_iteration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_iteration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1163\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpredict_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpredict_type\u001b[49m\n\u001b[1;32m   1164\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1165\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m _is_pyarrow_table(data):\n\u001b[1;32m   1166\u001b[0m     preds, nrow \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__pred_for_pyarrow_table(\n\u001b[1;32m   1167\u001b[0m         table\u001b[38;5;241m=\u001b[39mdata,\n\u001b[1;32m   1168\u001b[0m         start_iteration\u001b[38;5;241m=\u001b[39mstart_iteration,\n\u001b[1;32m   1169\u001b[0m         num_iteration\u001b[38;5;241m=\u001b[39mnum_iteration,\n\u001b[1;32m   1170\u001b[0m         predict_type\u001b[38;5;241m=\u001b[39mpredict_type\n\u001b[1;32m   1171\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/lightgbm/basic.py:1306\u001b[0m, in \u001b[0;36m_InnerPredictor.__pred_for_np2d\u001b[0;34m(self, mat, start_iteration, num_iteration, predict_type)\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m preds, nrow\n\u001b[1;32m   1305\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1306\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__inner_predict_np2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1307\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmat\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1308\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstart_iteration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_iteration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1309\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_iteration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_iteration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1310\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpredict_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpredict_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1311\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[1;32m   1312\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/lightgbm/basic.py:1259\u001b[0m, in \u001b[0;36m_InnerPredictor.__inner_predict_np2d\u001b[0;34m(self, mat, start_iteration, num_iteration, predict_type, preds)\u001b[0m\n\u001b[1;32m   1257\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWrong length of pre-allocated predict array\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1258\u001b[0m out_num_preds \u001b[38;5;241m=\u001b[39m ctypes\u001b[38;5;241m.\u001b[39mc_int64(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m-> 1259\u001b[0m _safe_call(\u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLGBM_BoosterPredictForMat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1260\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1261\u001b[0m \u001b[43m    \u001b[49m\u001b[43mptr_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1262\u001b[0m \u001b[43m    \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtype_ptr_data\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1263\u001b[0m \u001b[43m    \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int32\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1264\u001b[0m \u001b[43m    \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int32\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1265\u001b[0m \u001b[43m    \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_C_API_IS_ROW_MAJOR\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1266\u001b[0m \u001b[43m    \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredict_type\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_iteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_iteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1269\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_c_str\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpred_parameter\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout_num_preds\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_as\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPOINTER\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_double\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1272\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_preds \u001b[38;5;241m!=\u001b[39m out_num_preds\u001b[38;5;241m.\u001b[39mvalue:\n\u001b[1;32m   1273\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWrong length for predict results\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "result = entrenar_modelo_con_busqueda_aleatoria(X, Y, fit_parameters, param_testeo, n_HP_points_to_test=100, random_state=87)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RandomizedSearchCV(cv=3, estimator=LGBMClassifier(random_state=87), n_iter=100,\n",
    "                   param_distributions={'boosting_type': ['dart', 'goss', 'rf',\n",
    "                                                          'gbdt'],\n",
    "                                        'colsample_bytree': [0.58, 0.6, 0.62,\n",
    "                                                             0.68],\n",
    "                                        'importance_type': ['gini', 'entropy'],\n",
    "                                        'is_unbalance': ['True'],\n",
    "                                        'learning_rate': [0.1, 0.02, 0.04, 0.05,\n",
    "                                                          0.06, 0.07, 0.005,\n",
    "                                                          0.001],\n",
    "                                        'max_depth': [16, 17, 18, 19, 20, 21,\n",
    "                                                      22, 23, 24],\n",
    "                                        'min_child_weight': [0.008, 0.0085,\n",
    "                                                             0.009, 0.0095],\n",
    "                                        'n_estimators': [5, 10, 15, 20, 25, 30,\n",
    "                                                         35, 50],\n",
    "                                        'num_leaves': [28, 29, 30, 31, 32, 33],\n",
    "                                        'objective': ['binary'],\n",
    "                                        'subsample': [1]},\n",
    "                   random_state=87, scoring='f1_micro', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "35e07376-5bb5-450a-bd9c-d1cdb9d7951a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#experimento 1\n",
    "lgb_classifier = LGBMClassifier(subsample= 1, objective = 'binary', num_leaves= 31, min_child_weight=0.009, max_depth= 19, learning_rate= 0.05, importance_type='entropy', colsample_bytree= 0.6 ,boosting_type='dart', is_unbalance='True', num_boost_round = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "548fc1c7-7099-46d8-b4dd-dcef9ba72d69",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=30, num_boost_round=30 will be ignored. Current value: num_iterations=30\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 194, number of negative: 6304224\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014945 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1780\n",
      "[LightGBM] [Info] Number of data points in the train set: 6304418, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000031 -> initscore=-10.388872\n",
      "[LightGBM] [Info] Start training from score -10.388872\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "train_data  = lgb.Dataset(X_train, label = y_train)\n",
    "#model = lgb.train(params, train_data, num_boost_round=5)\n",
    "\n",
    "lgb_classifier.fit(np.array(X_train), y_train)\n",
    "#lgb_classifier.fit(train_data)\n",
    "lbg_predictions_labels = lgb_classifier.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d869acd8-14e2-4297-860c-dc798e9abb94",
     "showTitle": false,
     "title": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    }
   ],
   "source": [
    "# modelo train\n",
    "data1_f_data_pred_rf= lgb_classifier.predict(X)     \n",
    "probab_rf = lgb_classifier.predict_proba(X)\n",
    "\n",
    "score_rf=np.delete(probab_rf, np.s_[0], axis=1) \n",
    "Y_c=Y.copy()\n",
    "Y_c['preds_rf'] = data1_f_data_pred_rf\n",
    "Y_c['score_rf'] = score_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "17cc26fe-d9b1-4a06-99f5-5335a5b97d49",
     "showTitle": false,
     "title": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    }
   ],
   "source": [
    "# Realizar predicciones con el modelo entrenado en el conjunto de entrenamiento\n",
    "data1_f_data_pred_rf = lgb_classifier.predict(X)\n",
    "\n",
    "# Obtener las probabilidades predichas para la clase positiva (clase 1) del modelo\n",
    "probab_rf = lgb_classifier.predict_proba(X)\n",
    "\n",
    "# Extraer las puntuaciones (probabilidades) asociadas con la clase positiva\n",
    "score_rf = np.delete(probab_rf, np.s_[0], axis=1)\n",
    "\n",
    "# Crear una copia de las etiquetas verdaderas (Y) para análisis adicional\n",
    "Y_c = Y.copy()\n",
    "\n",
    "# Agregar las predicciones y las puntuaciones del modelo a las etiquetas verdaderas\n",
    "Y_c['preds_rf'] = data1_f_data_pred_rf\n",
    "Y_c['score_rf'] = score_rf\n",
    "\n",
    "# Los datos ahora contienen etiquetas verdaderas, predicciones y puntuaciones del modelo\n",
    "# Puedes utilizar estos resultados para realizar análisis y evaluar el rendimiento del modelo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lgb.plot_importance(lgb_classifier, importance_type=\"gain\", figsize=(7,6), title=\"LightGBM Feature Importance (Gain)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot feature importance using Split\n",
    "lgb.plot_importance(lgb_classifier, importance_type=\"split\", figsize=(7,6), title=\"LightGBM Feature Importance (Split)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_fraudes</th>\n",
       "      <th>preds_rf</th>\n",
       "      <th>score_rf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7880518</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7880519</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7880520</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7880521</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7880522</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7880523 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         target_fraudes  preds_rf  score_rf\n",
       "0                 False      True       1.0\n",
       "1                 False      True       1.0\n",
       "2                 False     False       0.0\n",
       "3                 False     False       0.0\n",
       "4                 False      True       1.0\n",
       "...                 ...       ...       ...\n",
       "7880518           False     False       0.0\n",
       "7880519           False      True       1.0\n",
       "7880520           False     False       0.0\n",
       "7880521           False      True       1.0\n",
       "7880522           False     False       0.0\n",
       "\n",
       "[7880523 rows x 3 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4068528</td>\n",
       "      <td>3811758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>197</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0        1\n",
       "0  4068528  3811758\n",
       "1      197       40"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(confusion_matrix(Y_c['target_fraudes'], Y_c['preds_rf']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   No fraude       1.00      0.52      0.68   7880286\n",
      "      Fraude       0.00      0.17      0.00       237\n",
      "\n",
      "    accuracy                           0.52   7880523\n",
      "   macro avg       0.50      0.34      0.34   7880523\n",
      "weighted avg       1.00      0.52      0.68   7880523\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_names = ['No fraude', 'Fraude']\n",
    "print(classification_report(Y_c['target_fraudes'], Y_c['preds_rf'], target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FRAUD CAPTURA 30%:\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# Dividir las predicciones en deciles y calcular la captura del 30% en el conjunto de entrenamiento\n",
    "percentiles = pd.qcut(Y_c['score_rf'], q=10, duplicates='drop').astype(str)\n",
    "percentile_label = {p: l for l, p in enumerate(sorted(percentiles.unique(), reverse=True), start=1)}\n",
    "percentiles = percentiles.map(percentile_label)\n",
    "Y_c['FRAUD_DECILE'] = np.nan\n",
    "Y_c['FRAUD_DECILE'] = Y_c['FRAUD_DECILE'].astype('Int32')\n",
    "Y_c['FRAUD_DECILE'] = percentiles\n",
    "print('FRAUD CAPTURA 30%:')\n",
    "print(sum(Y_c[Y_c['FRAUD_DECILE'] < 4]['target_fraudes']) / sum(Y_c['target_fraudes']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DECILES_T = pd.crosstab(Y_c['FRAUD_DECILE'], Y_c['target_fraudes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c696761f-b1a0-4d0d-a9f1-d9fda10a7b0e",
     "showTitle": false,
     "title": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>target_fraudes</th>\n",
       "      <th>False</th>\n",
       "      <th>True</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FRAUD_DECILE</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3900069</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3980217</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "target_fraudes    False  True \n",
       "FRAUD_DECILE                  \n",
       "1               3900069     41\n",
       "2               3980217    196"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DECILES_T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "71386cf3-61f2-44f2-aec7-360594b577b2",
     "showTitle": false,
     "title": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([<Axes: title={'center': 'False'}, xlabel='FRAUD_DECILE'>,\n",
       "       <Axes: title={'center': 'True'}, xlabel='FRAUD_DECILE'>],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "DECILES_T.plot.bar(stacked=False, rot=0,subplots=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d2607d30-6393-4d6e-ba95-acb61bf350dd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Cancelled",
       "errorTraceType": "html",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calcular la curva de ganancia acumulativa y el LIFT del modelo en el conjunto de entrenamiento\n",
    "classes = np.unique(Y_c[['target']])\n",
    "percentages, gains = cumulative_gain_curve(Y_c[['target']], Y_c['score_rf'], classes[1])\n",
    "percentages = percentages[1:]\n",
    "gains = gains[1:]\n",
    "gains = gains / percentages\n",
    "indice = round(len(gains) * 0.1)\n",
    "print('LIFT INV CHURN TRAIN:')\n",
    "print(gains[indice])\n",
    "\n",
    "# Calcular el área bajo la curva ROC del modelo en el conjunto de entrenamiento\n",
    "print('ROC INV CHURN TRAIN:')\n",
    "print(roc_auc_score(Y_c[['target']], Y_c['preds_rf']))\n",
    "\n",
    "# Calcular la estadística KS del modelo en el conjunto de entrenamiento\n",
    "thresholds, pct1, pct2, ks_statistic, max_distance_at, classes = binary_ks_curve(Y_c[['target']], Y_c['score_rf'].ravel())\n",
    "print('KS INV CHURN TRAIN:')\n",
    "print(ks_statistic)\n",
    "\n",
    "# Calcular la precisión y el recall del modelo en el conjunto de entrenamiento\n",
    "precision = precision_score(Y_c[['target']], Y_c['preds_rf'])\n",
    "recall = recall_score(Y_c[['target']], Y_c['preds_rf'])\n",
    "\n",
    "print('Precision INV CHURN TRAIN:')\n",
    "print(precision)\n",
    "print('Recall INV CHURN TRAIN:')\n",
    "print(recall)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e6fcd014-a695-48a9-8af9-a121268015cb",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## TESTEO ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "42e3788f-3cd7-45f4-bc86-72637798fd75",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Cancelled",
       "errorTraceType": "html",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tes1 = pd.read_parquet('./ABT/Prepoc_MX_2023-11-19.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7c278710-0157-4b3a-9b23-dc8b2e9bcae8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Cancelled",
       "errorTraceType": "html",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tes2 = pd.read_parquet('./ABT/Prepoc_MX_2023-11-26.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f67229ed-007f-4312-a1ea-3c0130fafef0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Cancelled",
       "errorTraceType": "html",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tes3 = pd.read_parquet('./ABT/Prepoc_MX_2023-12-03.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "49aecb61-1fbc-4537-b069-a5e4d1aeb25a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Cancelled",
       "errorTraceType": "html",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tes4 = pd.read_parquet('./ABT/Prepoc_MX_2023-12-10.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4ae8fc0e-6fec-47b0-bc75-10f837fdbaf2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Cancelled",
       "errorTraceType": "html",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## unir las cuatro cosechas\n",
    "\n",
    "tes = [tes1, tes2, tes3, tes4]\n",
    "\n",
    "tes = pd.concat(tes, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b88b7157-ce0f-4a4c-bcbd-fd2307aacc68",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Cancelled",
       "errorTraceType": "html",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## TARGETS de TESTE0\n",
    "\n",
    "#target 1\n",
    "tgt1 = pd.read_parquet('./ABT/Target_MX_2023-11-19.parquet')\n",
    "#target 1\n",
    "tgt2 = pd.read_parquet('./ABT/Target_MX_2023-11-26.parquet')\n",
    "#target 1\n",
    "tgt3 = pd.read_parquet('./ABT/Target_MX_2023-12-03.parquet')\n",
    "#target 1\n",
    "tgt4 = pd.read_parquet('./ABT/Target_MX_2023-12-10.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "25ca942c-ca5a-484a-b51c-b52436e9aef3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Cancelled",
       "errorTraceType": "html",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tgt = [tgt1, tgt2, tgt3, tgt4]\n",
    "\n",
    "tgt = pd.concat(tgt, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "461b0fcc-e2a2-4b57-8739-4605e50c1f98",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Cancelled",
       "errorTraceType": "html",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tgt = tgt.drop('country_cd', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a7ec0d91-9018-47c0-9ee2-6022c78553ec",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Cancelled",
       "errorTraceType": "html",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#ordenar las bases antes de unirlas (no es obligatorio)\n",
    "tes = tes.sort_values(by=[\"cbs_reg_user_id_cd\", \"week_dt\"])\n",
    "tgt = tgt.sort_values(by=[\"cbs_reg_user_id_cd\", \"week_dt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a08ae9f0-5d1e-4675-ac5e-891ef44cecee",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Cancelled",
       "errorTraceType": "html",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "testeo = pd.merge(tes, tgt, how=\"left\", on=[\"cbs_reg_user_id_cd\", \"week_dt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b7bd1a47-7799-4579-b3b0-66207df6f13d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Cancelled",
       "errorTraceType": "html",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def limpiar_nombres_columnas(dataframe):\n",
    "    \"\"\"\n",
    "    Limpia y estandariza los nombres de las columnas en un DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - dataframe: DataFrame de pandas.\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame con nombres de columnas limpios.\n",
    "    \"\"\"\n",
    "    dataframe = dataframe.rename(columns=lambda x: re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "    return dataframe\n",
    "    \n",
    "testeo = limpiar_nombres_columnas(testeo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c3bcf455-00db-437e-9b14-40b53d895d0b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Cancelled",
       "errorTraceType": "html",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "testeo = testeo\n",
    "testeo['ID']=testeo['cbs_reg_user_id_cd']\n",
    "testeo = testeo.set_index('ID')  \n",
    "#testeo=testeo.round(2)\n",
    "\n",
    " \n",
    "print (\"Dataset Length: \", len(testeo)) \n",
    "print (\"Dataset Shape: \", testeo.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4370c873-f4d4-457f-81f8-91409645043b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Cancelled",
       "errorTraceType": "html",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "testeo['target'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c4359382-551c-4b84-938a-6261417a69c8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Cancelled",
       "errorTraceType": "html",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## ## Con 60 dias de antiguedad\n",
    "\n",
    "testeo=testeo[(testeo['tenure_day']>=60)]\n",
    "testeo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0c0fb05b-e907-4ead-87c5-ec1a40104b55",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Cancelled",
       "errorTraceType": "html",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "testeo['target'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1318a536-2a23-456f-842c-ac6d1d389126",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Cancelled",
       "errorTraceType": "html",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Variables del modelo\n",
    "X_TESTEO = testeo[['tenure_day',\n",
    "'tenure_m']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "72208179-c108-43d3-b300-69ffbdf680c3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Cancelled",
       "errorTraceType": "html",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Extrayendo la columna 'target' del DataFrame 'testeo' y creando un nuevo DataFrame 'Y_TESTEO'\n",
    "Y_TESTEO = testeo[['target']]\n",
    "\n",
    "# Prediciendo la variable objetivo para el conjunto de datos de prueba 'X_TESTEO' utilizando el clasificador LightGBM\n",
    "testeo_data_pred_rf = lgb_classifier.predict(X_TESTEO)\n",
    "\n",
    "# Prediciendo las probabilidades de clase para cada observación en 'X_TESTEO' utilizando el clasificador LightGBM\n",
    "probab_rf = lgb_classifier.predict_proba(X_TESTEO)\n",
    "\n",
    "# Eliminando la primera columna (se asume que son las probabilidades de la clase negativa) de las probabilidades predichas\n",
    "# Se asume que la segunda columna contiene las probabilidades para la clase positiva\n",
    "score_rf = np.delete(probab_rf, np.s_[0], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9b5268e2-53ec-4de6-b411-6a2bfbbf737d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Cancelled",
       "errorTraceType": "html",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Creando una copia del DataFrame 'Y_TESTEO' para preservar los datos originales\n",
    "Y_TESTEO_c = Y_TESTEO.copy()\n",
    "\n",
    "# Agregando una nueva columna 'preds_rf' al DataFrame copiado con las predicciones del clasificador LightGBM\n",
    "Y_TESTEO_c['preds_rf'] = testeo_data_pred_rf\n",
    "\n",
    "# Agregando una nueva columna 'score_rf' al DataFrame copiado con las probabilidades de la clase positiva\n",
    "Y_TESTEO_c['score_rf'] = score_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "54a0c0f2-120c-47e0-9447-85aeb5b4de2d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Cancelled",
       "errorTraceType": "html",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calcular la curva de ganancia acumulativa y el LIFT del modelo en el conjunto de entrenamiento\n",
    "classes = np.unique(Y_TESTEO_c[['target']])\n",
    "percentages, gains = cumulative_gain_curve(Y_TESTEO_c[['target']], Y_TESTEO_c['score_rf'], classes[1])\n",
    "percentages = percentages[1:]\n",
    "gains = gains[1:]\n",
    "gains = gains / percentages\n",
    "indice = round(len(gains) * 0.1)\n",
    "print('LIFT INV CHURN TESTEO:')\n",
    "print(gains[indice])\n",
    "\n",
    "# Calcular el área bajo la curva ROC del modelo en el conjunto de entrenamiento\n",
    "print('ROC INV CHURN TESTEO:')\n",
    "print(roc_auc_score(Y_TESTEO_c[['target']], Y_TESTEO_c['preds_rf']))\n",
    "\n",
    "# Calcular la estadística KS del modelo en el conjunto de entrenamiento\n",
    "thresholds, pct1, pct2, ks_statistic, max_distance_at, classes = binary_ks_curve(Y_TESTEO_c[['target']], Y_TESTEO_c['score_rf'].ravel())\n",
    "print('KS INV CHURN TESTEO:')\n",
    "print(ks_statistic)\n",
    "\n",
    "# Calcular la precisión y el recall del modelo en el conjunto de entrenamiento\n",
    "precision = precision_score(Y_TESTEO_c[['target']], Y_TESTEO_c['preds_rf'])\n",
    "recall = recall_score(Y_TESTEO_c[['target']], Y_TESTEO_c['preds_rf'])\n",
    "print('Precision INV CHURN TESTEO:')\n",
    "print(precision)\n",
    "print('Recall INV CHURN TESTEO:')\n",
    "print(recall)\n",
    "\n",
    "# Dividir las predicciones en deciles y calcular la captura del 30% en el conjunto de entrenamiento\n",
    "percentiles = pd.qcut(Y_TESTEO_c['score_rf'], q=10, duplicates='drop').astype(str)\n",
    "percentile_label = {p: l for l, p in enumerate(sorted(percentiles.unique(), reverse=True), start=1)}\n",
    "percentiles = percentiles.map(percentile_label)\n",
    "Y_TESTEO_c['CHURNINV_DECILE'] = np.nan\n",
    "Y_TESTEO_c['CHURNINV_DECILE'] = Y_TESTEO_c['CHURNINV_DECILE'].astype('Int32')\n",
    "Y_TESTEO_c['CHURNINV_DECILE'] = percentiles\n",
    "print('INV CHURN CAPTURA 30%:')\n",
    "print(sum(Y_TESTEO_c[Y_TESTEO_c['CHURNINV_DECILE'] < 4]['target']) / sum(Y_TESTEO_c['target']))\n",
    "#Y_TESTEO_c.to_csv(r'./SCORES/primera_prueba.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5e384a20-995d-454d-a88c-8d7acca12cca",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Cancelled",
       "errorTraceType": "html",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "DECILES = pd.crosstab(Y_TESTEO_c['CHURNINV_DECILE'], Y_TESTEO_c['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6a22fdbf-71db-47c3-86e7-dcfea4708f07",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Cancelled",
       "errorTraceType": "html",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "DECILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a0acf01d-13b6-4a07-9fb1-93c341c272bc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Cancelled",
       "errorTraceType": "html",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "DECILES.plot.bar(stacked=False, rot=0,subplots=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b1f8cea5-bbb6-4676-81f0-8ed2e7a9333d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Cancelled",
       "errorTraceType": "html",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Guardando las importancias de las características (feature importance) en un archivo de texto\n",
    "# La importancia se mide en términos de ganancia ('gain') según el clasificador LightGBM\n",
    "# Se utiliza la función 'np.savetxt' para escribir en un archivo de texto\n",
    "# El archivo se guarda en la ruta './SCORES/importance_1.txt'\n",
    "# Se utiliza 'lgb_classifier.booster_.feature_importance' para obtener las importancias de las características\n",
    "# Se especifica el formato de los datos en el archivo como números de punto flotante ('%f')\n",
    "\n",
    "np.savetxt('./SCORES/importance_78.txt', lgb_classifier.booster_.feature_importance(importance_type='gain'),fmt='%f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1d562291-b328-449f-886a-c1a2fdda3e2d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##TESTEAR TODA LA BASE (sin restricciones de tenure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2cac4510-6199-471b-97b1-1081bb4a25c3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Cancelled",
       "errorTraceType": "html",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tes1 = pd.read_parquet('./ABT/Prepoc_MX_2023-11-19.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "68e0ce50-eb2d-4f2c-9222-eb4a4b01d025",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Cancelled",
       "errorTraceType": "html",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tes2 = pd.read_parquet('./ABT/Prepoc_MX_2023-11-26.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "73678c47-79a2-40a1-8d25-f5615a3fd8b8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Cancelled",
       "errorTraceType": "html",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tes3 = pd.read_parquet('./ABT/Prepoc_MX_2023-12-03.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "33e57000-a4f4-4dbb-bc81-bcaaa7018529",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Cancelled",
       "errorTraceType": "html",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tes4 = pd.read_parquet('./ABT/Prepoc_MX_2023-12-10.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "24ef412c-dec1-4dad-aad5-f467792e59ad",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Cancelled",
       "errorTraceType": "html",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## unir las cuatro cosechas\n",
    "\n",
    "tes = [tes1, tes2, tes3, tes4]\n",
    "\n",
    "tes = pd.concat(tes, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "44ea7e7a-ff47-455a-9009-48c0ed0781c5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Cancelled",
       "errorTraceType": "html",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## TARGETS de TESTE0\n",
    "\n",
    "#target 1\n",
    "tgt1 = pd.read_parquet('./ABT/Target_MX_2023-11-19.parquet')\n",
    "#target 1\n",
    "tgt2 = pd.read_parquet('./ABT/Target_MX_2023-11-26.parquet')\n",
    "#target 1\n",
    "tgt3 = pd.read_parquet('./ABT/Target_MX_2023-12-03.parquet')\n",
    "#target 1\n",
    "tgt4 = pd.read_parquet('./ABT/Target_MX_2023-12-10.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c2e65078-0d83-4163-a575-6cd735f4623c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Cancelled",
       "errorTraceType": "html",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tgt = [tgt1, tgt2, tgt3, tgt4]\n",
    "\n",
    "tgt = pd.concat(tgt, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b1caf971-d634-43bb-a3d9-1e5cf05fdf27",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Cancelled",
       "errorTraceType": "html",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tgt = tgt.drop('country_cd', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7bf27f96-27b4-499d-8cc3-9e43bf8d4999",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Cancelled",
       "errorTraceType": "html",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#ordenar las bases antes de unirlas (no es obligatorio)\n",
    "tes = tes.sort_values(by=[\"cbs_reg_user_id_cd\", \"week_dt\"])\n",
    "tgt = tgt.sort_values(by=[\"cbs_reg_user_id_cd\", \"week_dt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c71354a6-11c6-49c6-938b-b25f50160330",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Cancelled",
       "errorTraceType": "html",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tgt['target'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5ba5627c-d7e2-41ac-a013-7c2024c84950",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "testeo_f = pd.merge(tes1, tgt1, how=\"left\", on=[\"cbs_reg_user_id_cd\", \"week_dt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3dc69b00-3988-4e2a-9e55-b841a24880fb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def limpiar_nombres_columnas(dataframe):\n",
    "    \"\"\"\n",
    "    Limpia y estandariza los nombres de las columnas en un DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - dataframe: DataFrame de pandas.\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame con nombres de columnas limpios.\n",
    "    \"\"\"\n",
    "    dataframe = dataframe.rename(columns=lambda x: re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "    return dataframe\n",
    "    \n",
    "testeo_f = limpiar_nombres_columnas(testeo_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f550a28a-dbcf-4546-8ff8-f9d447ce8185",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "testeo_f['cbs_reg_user_id_cd'] = testeo_f['cbs_reg_user_id_cd'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fa059faf-cded-4ebb-85c3-196722a8697a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Length:  84947\n",
      "Dataset Shape:  (84947, 561)\n"
     ]
    }
   ],
   "source": [
    "testeo_f = testeo_f\n",
    "testeo_f['ID']=testeo_f['cbs_reg_user_id_cd']\n",
    "testeo_f = testeo_f.set_index('ID')  \n",
    "#testeo=testeo.round(2)\n",
    "\n",
    " \n",
    "print (\"Dataset Length: \", len(testeo_f)) \n",
    "print (\"Dataset Shape: \", testeo_f.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "014cf86b-9d2a-4607-b344-fce85143ddfb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    82154\n",
       "1     2793\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testeo_f['target'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5caa3b71-ebb9-4f06-9c4a-f12dee6fac63",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "X_TESTEO_f = testeo_f[['tenure_day',\n",
    "'tenure_m']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2b4408b6-b6e8-4bcb-8604-d66dc468d8cc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Extrayendo la columna 'target' del DataFrame 'testeo' y creando un nuevo DataFrame 'Y_TESTEO'\n",
    "Y_TESTEO_f = testeo_f[['target']]\n",
    "\n",
    "# Prediciendo la variable objetivo para el conjunto de datos de prueba 'X_TESTEO' utilizando el clasificador LightGBM\n",
    "testeo_data_pred_rf = lgb_classifier.predict(X_TESTEO_f)\n",
    "\n",
    "# Prediciendo las probabilidades de clase para cada observación en 'X_TESTEO' utilizando el clasificador LightGBM\n",
    "probab_rf = lgb_classifier.predict_proba(X_TESTEO_f)\n",
    "\n",
    "# Eliminando la primera columna (se asume que son las probabilidades de la clase negativa) de las probabilidades predichas\n",
    "# Se asume que la segunda columna contiene las probabilidades para la clase positiva\n",
    "score_rf = np.delete(probab_rf, np.s_[0], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "de1f9ea9-b9ee-4657-9c97-0f6b6f2597a9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Creando una copia del DataFrame 'Y_TESTEO' para preservar los datos originales\n",
    "Y_TESTEO_c = Y_TESTEO_f.copy()\n",
    "\n",
    "# Agregando una nueva columna 'preds_rf' al DataFrame copiado con las predicciones del clasificador LightGBM\n",
    "Y_TESTEO_c['preds_rf'] = testeo_data_pred_rf\n",
    "\n",
    "# Agregando una nueva columna 'score_rf' al DataFrame copiado con las probabilidades de la clase positiva\n",
    "Y_TESTEO_c['score_rf'] = score_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9fc1fe91-cb9a-4308-bd5a-23ab1b623f88",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LIFT INV CHURN TESTEO:\n",
      "5.924621422064712\n",
      "ROC INV CHURN TESTEO:\n",
      "0.7788750674518938\n",
      "KS INV CHURN TESTEO:\n",
      "0.6690402446529624\n",
      "Precision INV CHURN TESTEO:\n",
      "0.1703156358328772\n",
      "Recall INV CHURN TESTEO:\n",
      "0.6684568564267812\n",
      "INV CHURN CAPTURA 30%:\n",
      "0.9280343716433942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/databricks/python/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:115: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# Calcular la curva de ganancia acumulativa y el LIFT del modelo en el conjunto de entrenamiento\n",
    "classes = np.unique(Y_TESTEO_c[['target']])\n",
    "percentages, gains = cumulative_gain_curve(Y_TESTEO_c[['target']], Y_TESTEO_c['score_rf'], classes[1])\n",
    "percentages = percentages[1:]\n",
    "gains = gains[1:]\n",
    "gains = gains / percentages\n",
    "indice = round(len(gains) * 0.1)\n",
    "print('LIFT INV CHURN TESTEO:')\n",
    "print(gains[indice])\n",
    "\n",
    "# Calcular el área bajo la curva ROC del modelo en el conjunto de entrenamiento\n",
    "print('ROC INV CHURN TESTEO:')\n",
    "print(roc_auc_score(Y_TESTEO_c[['target']], Y_TESTEO_c['preds_rf']))\n",
    "\n",
    "# Calcular la estadística KS del modelo en el conjunto de entrenamiento\n",
    "thresholds, pct1, pct2, ks_statistic, max_distance_at, classes = binary_ks_curve(Y_TESTEO_c[['target']], Y_TESTEO_c['score_rf'].ravel())\n",
    "print('KS INV CHURN TESTEO:')\n",
    "print(ks_statistic)\n",
    "\n",
    "# Calcular la precisión y el recall del modelo en el conjunto de entrenamiento\n",
    "precision = precision_score(Y_TESTEO_c[['target']], Y_TESTEO_c['preds_rf'])\n",
    "recall = recall_score(Y_TESTEO_c[['target']], Y_TESTEO_c['preds_rf'])\n",
    "print('Precision INV CHURN TESTEO:')\n",
    "print(precision)\n",
    "print('Recall INV CHURN TESTEO:')\n",
    "print(recall)\n",
    "\n",
    "# Dividir las predicciones en deciles y calcular la captura del 30% en el conjunto de entrenamiento\n",
    "percentiles = pd.qcut(Y_TESTEO_c['score_rf'], q=10, duplicates='drop').astype(str)\n",
    "percentile_label = {p: l for l, p in enumerate(sorted(percentiles.unique(), reverse=True), start=1)}\n",
    "percentiles = percentiles.map(percentile_label)\n",
    "Y_TESTEO_c['CHURNINV_DECILE'] = np.nan\n",
    "Y_TESTEO_c['CHURNINV_DECILE'] = Y_TESTEO_c['CHURNINV_DECILE'].astype('Int32')\n",
    "Y_TESTEO_c['CHURNINV_DECILE'] = percentiles\n",
    "print('INV CHURN CAPTURA 30%:')\n",
    "print(sum(Y_TESTEO_c[Y_TESTEO_c['CHURNINV_DECILE'] < 4]['target']) / sum(Y_TESTEO_c['target']))\n",
    "#Y_TESTEO_c.to_csv(r'./SCORES/primera_prueba.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bc3c7d0d-4795-4b19-adab-2bf54e6a2646",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "DECILES = pd.crosstab(Y_TESTEO_c['CHURNINV_DECILE'], Y_TESTEO_c['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "154fc078-d694-4310-8bcb-1f776c821a63",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>target</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHURNINV_DECILE</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6840</td>\n",
       "      <td>1655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7936</td>\n",
       "      <td>558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8114</td>\n",
       "      <td>379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8248</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8557</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8406</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8423</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8620</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8325</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>8685</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "target              0     1\n",
       "CHURNINV_DECILE            \n",
       "1                6840  1655\n",
       "2                7936   558\n",
       "3                8114   379\n",
       "4                8248   158\n",
       "5                8557    28\n",
       "6                8406     8\n",
       "7                8423     3\n",
       "8                8620     1\n",
       "9                8325     1\n",
       "10               8685     2"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DECILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "770a00a6-4d80-439a-8bb0-3a1ac2bc6b1e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([<AxesSubplot:title={'center':'0'}, xlabel='CHURNINV_DECILE'>,\n",
       "       <AxesSubplot:title={'center':'1'}, xlabel='CHURNINV_DECILE'>],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "DECILES.plot.bar(stacked=False, rot=0,subplots=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "146deb8d-b353-431c-b32b-c32e8cfcdd55",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>preds_rf</th>\n",
       "      <th>score_rf</th>\n",
       "      <th>CHURNINV_DECILE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25473450</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.021569</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47048254</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.142731</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50617237</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.022059</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59198106</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.254423</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38690563</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.024852</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          target  preds_rf  score_rf  CHURNINV_DECILE\n",
       "ID                                                   \n",
       "25473450       0         0  0.021569                8\n",
       "47048254       0         0  0.142731                4\n",
       "50617237       0         0  0.022059                8\n",
       "59198106       0         0  0.254423                4\n",
       "38690563       0         0  0.024852                7"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_TESTEO_c.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d074c2fd-20a4-411e-8475-11bb3b101594",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target               int64\n",
       "preds_rf             int64\n",
       "score_rf           float64\n",
       "CHURNINV_DECILE      int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_TESTEO_c.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e13a5fcc-062c-4f07-8805-14e7c12fb045",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "testeo_f2= testeo_f[['cbs_reg_user_id_cd', 'tenure_day', 'tenure_m','days_last_paid','week_dt']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6d320fa5-adcf-4a5c-8b1c-2e5c828f47f5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "testeo_f2 = testeo_f2.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2bdc34bd-3bfb-4f08-9b1c-96470d7900b8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>cbs_reg_user_id_cd</th>\n",
       "      <th>tenure_day</th>\n",
       "      <th>tenure_m</th>\n",
       "      <th>days_last_paid</th>\n",
       "      <th>week_dt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25473450</td>\n",
       "      <td>25473450</td>\n",
       "      <td>678</td>\n",
       "      <td>23</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2023-12-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>47048254</td>\n",
       "      <td>47048254</td>\n",
       "      <td>210</td>\n",
       "      <td>7</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2023-12-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50617237</td>\n",
       "      <td>50617237</td>\n",
       "      <td>294</td>\n",
       "      <td>10</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2023-12-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>59198106</td>\n",
       "      <td>59198106</td>\n",
       "      <td>184</td>\n",
       "      <td>6</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2023-12-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>38690563</td>\n",
       "      <td>38690563</td>\n",
       "      <td>442</td>\n",
       "      <td>15</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2023-12-10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID  cbs_reg_user_id_cd  tenure_day  tenure_m  days_last_paid  \\\n",
       "0  25473450            25473450         678        23             3.0   \n",
       "1  47048254            47048254         210         7            19.0   \n",
       "2  50617237            50617237         294        10            14.0   \n",
       "3  59198106            59198106         184         6            24.0   \n",
       "4  38690563            38690563         442        15             8.0   \n",
       "\n",
       "      week_dt  \n",
       "0  2023-12-10  \n",
       "1  2023-12-10  \n",
       "2  2023-12-10  \n",
       "3  2023-12-10  \n",
       "4  2023-12-10  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testeo_f2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ea7fd300-33da-48b3-80eb-2194ccd3cc7a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                     object\n",
       "cbs_reg_user_id_cd     object\n",
       "tenure_day              int64\n",
       "tenure_m                int64\n",
       "days_last_paid        float64\n",
       "week_dt                object\n",
       "dtype: object"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testeo_f2.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "83a9829a-380c-44e4-9f60-3224ab295cb7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
       "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)\n",
       "File \u001b[0;32m/databricks/python/lib/python3.10/site-packages/pandas/core/indexes/base.py:3629\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n",
       "\u001b[1;32m   3628\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
       "\u001b[0;32m-> 3629\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n",
       "\u001b[1;32m   3630\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
       "\n",
       "File \u001b[0;32m/databricks/python/lib/python3.10/site-packages/pandas/_libs/index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
       "\n",
       "File \u001b[0;32m/databricks/python/lib/python3.10/site-packages/pandas/_libs/index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
       "\n",
       "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
       "\n",
       "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
       "\n",
       "\u001b[0;31mKeyError\u001b[0m: 'ID'\n",
       "\n",
       "The above exception was the direct cause of the following exception:\n",
       "\n",
       "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)\n",
       "File \u001b[0;32m<command-1398124266569282>, line 1\u001b[0m\n",
       "\u001b[0;32m----> 1\u001b[0m Y_TESTEO_c[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mID\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mY_TESTEO_c\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mID\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n",
       "\n",
       "File \u001b[0;32m/databricks/python/lib/python3.10/site-packages/pandas/core/frame.py:3505\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n",
       "\u001b[1;32m   3503\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
       "\u001b[1;32m   3504\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n",
       "\u001b[0;32m-> 3505\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
       "\u001b[1;32m   3506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n",
       "\u001b[1;32m   3507\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
       "\n",
       "File \u001b[0;32m/databricks/python/lib/python3.10/site-packages/pandas/core/indexes/base.py:3631\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n",
       "\u001b[1;32m   3629\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n",
       "\u001b[1;32m   3630\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
       "\u001b[0;32m-> 3631\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n",
       "\u001b[1;32m   3632\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n",
       "\u001b[1;32m   3633\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n",
       "\u001b[1;32m   3634\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n",
       "\u001b[1;32m   3635\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n",
       "\u001b[1;32m   3636\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
       "\n",
       "\u001b[0;31mKeyError\u001b[0m: 'ID'"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)\nFile \u001b[0;32m/databricks/python/lib/python3.10/site-packages/pandas/core/indexes/base.py:3629\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3628\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3629\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3630\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\nFile \u001b[0;32m/databricks/python/lib/python3.10/site-packages/pandas/_libs/index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n\nFile \u001b[0;32m/databricks/python/lib/python3.10/site-packages/pandas/_libs/index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n\nFile \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n\nFile \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n\n\u001b[0;31mKeyError\u001b[0m: 'ID'\n\nThe above exception was the direct cause of the following exception:\n\n\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)\nFile \u001b[0;32m<command-1398124266569282>, line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m Y_TESTEO_c[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mID\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mY_TESTEO_c\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mID\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n\nFile \u001b[0;32m/databricks/python/lib/python3.10/site-packages/pandas/core/frame.py:3505\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3503\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3504\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3505\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3507\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n\nFile \u001b[0;32m/databricks/python/lib/python3.10/site-packages/pandas/core/indexes/base.py:3631\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3629\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3630\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3631\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3632\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3633\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3634\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3635\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3636\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n\n\u001b[0;31mKeyError\u001b[0m: 'ID'",
       "errorSummary": "<span class='ansi-red-fg'>KeyError</span>: 'ID'",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Y_TESTEO_c['ID'] = Y_TESTEO_c['ID'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5e0e1ef2-fad8-45a9-8a38-709a3b0bfadb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "testeo_f2['ID'] = testeo_f2['ID'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "817bfbc3-1bd6-495a-b697-dae922195f5e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "testeo_all10dec2023 = pd.merge(testeo_f2, Y_TESTEO_c, how=\"left\", on=[\"ID\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0a5e88f4-33b8-4f89-9bd3-6b46a79d5c70",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>cbs_reg_user_id_cd</th>\n",
       "      <th>tenure_day</th>\n",
       "      <th>tenure_m</th>\n",
       "      <th>days_last_paid</th>\n",
       "      <th>week_dt</th>\n",
       "      <th>target</th>\n",
       "      <th>preds_rf</th>\n",
       "      <th>score_rf</th>\n",
       "      <th>CHURNINV_DECILE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25473450</td>\n",
       "      <td>25473450</td>\n",
       "      <td>678</td>\n",
       "      <td>23</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2023-12-10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.021569</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>47048254</td>\n",
       "      <td>47048254</td>\n",
       "      <td>210</td>\n",
       "      <td>7</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2023-12-10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.142731</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50617237</td>\n",
       "      <td>50617237</td>\n",
       "      <td>294</td>\n",
       "      <td>10</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2023-12-10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.022059</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>59198106</td>\n",
       "      <td>59198106</td>\n",
       "      <td>184</td>\n",
       "      <td>6</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2023-12-10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.254423</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>38690563</td>\n",
       "      <td>38690563</td>\n",
       "      <td>442</td>\n",
       "      <td>15</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2023-12-10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.024852</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID  cbs_reg_user_id_cd  tenure_day  tenure_m  days_last_paid  \\\n",
       "0  25473450            25473450         678        23             3.0   \n",
       "1  47048254            47048254         210         7            19.0   \n",
       "2  50617237            50617237         294        10            14.0   \n",
       "3  59198106            59198106         184         6            24.0   \n",
       "4  38690563            38690563         442        15             8.0   \n",
       "\n",
       "      week_dt  target  preds_rf  score_rf  CHURNINV_DECILE  \n",
       "0  2023-12-10       0         0  0.021569                8  \n",
       "1  2023-12-10       0         0  0.142731                4  \n",
       "2  2023-12-10       0         0  0.022059                8  \n",
       "3  2023-12-10       0         0  0.254423                4  \n",
       "4  2023-12-10       0         0  0.024852                7  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testeo_all10dec2023.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b4dc1ee5-2f2f-49bf-b802-b5a6ba57327c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "testeo_all10dec2023= testeo_all10dec2023[['cbs_reg_user_id_cd', 'target','preds_rf','score_rf','CHURNINV_DECILE','tenure_m']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f7f3428a-922f-422d-9395-e73732c39644",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "testeo_all10dec2023.to_csv('testeo_60Mx10dec2023.csv')"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "03.3-Train MX U_60T(lgbm)",
   "widgets": {}
  },
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.m5.large",
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
