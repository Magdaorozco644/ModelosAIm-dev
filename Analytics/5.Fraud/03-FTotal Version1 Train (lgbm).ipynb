{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tabgan==1.3.3\n",
      "  Downloading tabgan-1.3.3-py2.py3-none-any.whl.metadata (10.0 kB)\n",
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tabgan==1.3.3) (2.2.0)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tabgan==1.3.3) (1.22.4)\n",
      "Collecting category-encoders (from tabgan==1.3.3)\n",
      "  Downloading category_encoders-2.6.3-py2.py3-none-any.whl.metadata (8.0 kB)\n",
      "Collecting torch>=1.0 (from tabgan==1.3.3)\n",
      "  Downloading torch-2.2.1-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\n",
      "Collecting lightgbm>=2.2.3 (from tabgan==1.3.3)\n",
      "  Downloading lightgbm-4.3.0.tar.gz (1.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: scikit-learn>=1.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tabgan==1.3.3) (1.4.0)\n",
      "Collecting torchvision (from tabgan==1.3.3)\n",
      "  Downloading torchvision-0.17.1-cp310-cp310-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: python-dateutil in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tabgan==1.3.3) (2.8.2)\n",
      "Requirement already satisfied: tqdm in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tabgan==1.3.3) (4.66.1)\n",
      "Requirement already satisfied: scipy in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from lightgbm>=2.2.3->tabgan==1.3.3) (1.12.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from scikit-learn>=1.0.2->tabgan==1.3.3) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from scikit-learn>=1.0.2->tabgan==1.3.3) (3.2.0)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch>=1.0->tabgan==1.3.3) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch>=1.0->tabgan==1.3.3) (4.9.0)\n",
      "Requirement already satisfied: sympy in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch>=1.0->tabgan==1.3.3) (1.12)\n",
      "Requirement already satisfied: networkx in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch>=1.0->tabgan==1.3.3) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch>=1.0->tabgan==1.3.3) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch>=1.0->tabgan==1.3.3) (2023.12.2)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.0->tabgan==1.3.3)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.0->tabgan==1.3.3)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.0->tabgan==1.3.3)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.0->tabgan==1.3.3)\n",
      "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.0->tabgan==1.3.3)\n",
      "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.0->tabgan==1.3.3)\n",
      "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.0->tabgan==1.3.3)\n",
      "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.0->tabgan==1.3.3)\n",
      "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.0->tabgan==1.3.3)\n",
      "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nccl-cu12==2.19.3 (from torch>=1.0->tabgan==1.3.3)\n",
      "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.0->tabgan==1.3.3)\n",
      "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting triton==2.2.0 (from torch>=1.0->tabgan==1.3.3)\n",
      "  Downloading triton-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
      "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.0->tabgan==1.3.3)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.99-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: statsmodels>=0.9.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from category-encoders->tabgan==1.3.3) (0.14.1)\n",
      "Requirement already satisfied: patsy>=0.5.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from category-encoders->tabgan==1.3.3) (0.5.6)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas->tabgan==1.3.3) (2023.4)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas->tabgan==1.3.3) (2023.4)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from python-dateutil->tabgan==1.3.3) (1.16.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torchvision->tabgan==1.3.3) (10.2.0)\n",
      "Requirement already satisfied: packaging>=21.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from statsmodels>=0.9.0->category-encoders->tabgan==1.3.3) (21.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jinja2->torch>=1.0->tabgan==1.3.3) (2.1.4)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sympy->torch>=1.0->tabgan==1.3.3) (1.3.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from packaging>=21.3->statsmodels>=0.9.0->category-encoders->tabgan==1.3.3) (3.1.1)\n",
      "Downloading tabgan-1.3.3-py2.py3-none-any.whl (28 kB)\n",
      "Downloading torch-2.2.1-cp310-cp310-manylinux1_x86_64.whl (755.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.5/755.5 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m136.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m90.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading triton-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (167.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading category_encoders-2.6.3-py2.py3-none-any.whl (81 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.9/81.9 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torchvision-0.17.1-cp310-cp310-manylinux1_x86_64.whl (6.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m38.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.99-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: lightgbm\n",
      "  Building wheel for lightgbm (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for lightgbm: filename=lightgbm-4.3.0-py3-none-manylinux_2_26_x86_64.whl size=2461523 sha256=b008a395475b2eb3b46e4a3f713c1a3034e491adf21c56fd9e4159ad616e1441\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/6b/92/ab/b7b5df76502b64443c1a830e5f7ec3cb66741313ddebb682aa\n",
      "Successfully built lightgbm\n",
      "Installing collected packages: triton, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, lightgbm, nvidia-cusolver-cu12, torch, category-encoders, torchvision, tabgan\n",
      "Successfully installed category-encoders-2.6.3 lightgbm-4.3.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.99 nvidia-nvtx-cu12-12.1.105 tabgan-1.3.3 torch-2.2.1 torchvision-0.17.1 triton-2.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tabgan==1.3.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightgbm in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (4.3.0)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from lightgbm) (1.22.4)\n",
      "Requirement already satisfied: scipy in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from lightgbm) (1.12.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (2.2.0)\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.2.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: dask[complete] in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (2024.1.1)\n",
      "Collecting dask[complete]\n",
      "  Downloading dask-2024.3.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas) (1.22.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas) (2023.4)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas) (2023.4)\n",
      "Requirement already satisfied: click>=8.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from dask[complete]) (8.1.7)\n",
      "Requirement already satisfied: cloudpickle>=1.5.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from dask[complete]) (2.2.1)\n",
      "Requirement already satisfied: fsspec>=2021.09.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from dask[complete]) (2023.12.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from dask[complete]) (21.3)\n",
      "Requirement already satisfied: partd>=1.2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from dask[complete]) (1.4.1)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from dask[complete]) (6.0.1)\n",
      "Requirement already satisfied: toolz>=0.10.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from dask[complete]) (0.12.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.13.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from dask[complete]) (6.11.0)\n",
      "Requirement already satisfied: pyarrow>=7.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from dask[complete]) (15.0.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from dask[complete]) (0.6)\n",
      "Requirement already satisfied: lz4>=4.3.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from dask[complete]) (4.3.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from importlib-metadata>=4.13.0->dask[complete]) (3.17.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from packaging>=20.0->dask[complete]) (3.1.1)\n",
      "Requirement already satisfied: locket in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from partd>=1.2.0->dask[complete]) (1.0.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Collecting dask-expr<1.1,>=1.0 (from dask[complete])\n",
      "  Downloading dask_expr-1.0.5-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: bokeh>=2.4.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from dask[complete]) (3.3.4)\n",
      "Requirement already satisfied: jinja2>=2.10.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from dask[complete]) (3.1.3)\n",
      "Collecting distributed==2024.3.1 (from dask[complete])\n",
      "  Downloading distributed-2024.3.1-py3-none-any.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: msgpack>=1.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from distributed==2024.3.1->dask[complete]) (1.0.7)\n",
      "Requirement already satisfied: psutil>=5.7.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from distributed==2024.3.1->dask[complete]) (5.9.8)\n",
      "Requirement already satisfied: sortedcontainers>=2.0.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from distributed==2024.3.1->dask[complete]) (2.4.0)\n",
      "Requirement already satisfied: tblib>=1.6.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from distributed==2024.3.1->dask[complete]) (2.0.0)\n",
      "Requirement already satisfied: tornado>=6.0.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from distributed==2024.3.1->dask[complete]) (6.3.3)\n",
      "Requirement already satisfied: urllib3>=1.24.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from distributed==2024.3.1->dask[complete]) (1.26.18)\n",
      "Requirement already satisfied: zict>=3.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from distributed==2024.3.1->dask[complete]) (3.0.0)\n",
      "Requirement already satisfied: contourpy>=1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from bokeh>=2.4.2->dask[complete]) (1.2.0)\n",
      "Requirement already satisfied: pillow>=7.1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from bokeh>=2.4.2->dask[complete]) (10.2.0)\n",
      "Requirement already satisfied: xyzservices>=2021.09.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from bokeh>=2.4.2->dask[complete]) (2023.10.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jinja2>=2.10.3->dask[complete]) (2.1.4)\n",
      "Downloading pandas-2.2.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading dask-2024.3.1-py3-none-any.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m48.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading distributed-2024.3.1-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m47.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading dask_expr-1.0.5-py3-none-any.whl (183 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.6/183.6 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pandas, dask, distributed, dask-expr\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 2.2.0\n",
      "    Uninstalling pandas-2.2.0:\n",
      "      Successfully uninstalled pandas-2.2.0\n",
      "  Attempting uninstall: dask\n",
      "    Found existing installation: dask 2024.1.1\n",
      "    Uninstalling dask-2024.1.1:\n",
      "      Successfully uninstalled dask-2024.1.1\n",
      "  Attempting uninstall: distributed\n",
      "    Found existing installation: distributed 2024.1.1\n",
      "    Uninstalling distributed-2024.1.1:\n",
      "      Successfully uninstalled distributed-2024.1.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "autovizwidget 0.21.0 requires pandas<2.0.0,>=0.20.1, but you have pandas 2.2.1 which is incompatible.\n",
      "hdijupyterutils 0.21.0 requires pandas<2.0.0,>=0.17.1, but you have pandas 2.2.1 which is incompatible.\n",
      "sparkmagic 0.21.0 requires pandas<2.0.0,>=0.17.1, but you have pandas 2.2.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed dask-2024.3.1 dask-expr-1.0.5 distributed-2024.3.1 pandas-2.2.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade pandas \"dask[complete]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "567b8871-992b-48f1-9709-847d1f6529ec",
     "showTitle": false,
     "title": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## librerias requeridas\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import calendar\n",
    "import re\n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.metrics import classification_report \n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "#from scikitplot.metrics import plot_roc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "#from scikitplot.metrics import plot_lift_curve\n",
    "#from scikitplot.helpers import binary_ks_curve \n",
    "#from scikitplot.metrics import plot_ks_statistic\n",
    "#from scikitplot.helpers import cumulative_gain_curve\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from lightgbm import LGBMClassifier\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6ebc0e87-d9be-4b2c-b870-c00cbea0ad90",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 500)\n",
    "#pd.set_option('display.max_rows', 500)\n",
    "#pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.memory_usage', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'column'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_11837/527743540.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf1Train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   6292\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6293\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6294\u001b[0m         ):\n\u001b[1;32m   6295\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6296\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'column'"
     ]
    }
   ],
   "source": [
    "df1Train.column.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9a5f32c1-8445-4154-9406-921f6dc072e2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'target_fraudes'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'target_fraudes'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m s3_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mviamericas-datalake-dev-us-east-1-283731589572-raw/FraudModel/Data4Model\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      2\u001b[0m df1Train \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_parquet(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ms3://\u001b[39m\u001b[38;5;132;01m{\u001b[39;00ms3_url\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/TargetTodos/Train/Train.parquet\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m tg1Train \u001b[38;5;241m=\u001b[39m \u001b[43mdf1Train\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtarget_fraudes\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m      5\u001b[0m df1Val \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_parquet(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ms3://\u001b[39m\u001b[38;5;132;01m{\u001b[39;00ms3_url\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/TargetTodos/Validation/Validation.parquet\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m tg1Val \u001b[38;5;241m=\u001b[39m df1Val[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget_fraudes\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/pandas/core/frame.py:4090\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4088\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4089\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4090\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4092\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'target_fraudes'"
     ]
    }
   ],
   "source": [
    "s3_url = f\"viamericas-datalake-dev-us-east-1-283731589572-raw/FraudModel/Data4Model\"\n",
    "df1Train = pd.read_parquet(f\"s3://{s3_url}/TargetTodos/Train/Train.parquet\")\n",
    "tg1Train = df1Train['target_fraudes']\n",
    "\n",
    "df1Val = pd.read_parquet(f\"s3://{s3_url}/TargetTodos/Validation/Validation.parquet\")\n",
    "tg1Val = df1Val['target_fraudes']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3b0247e4-0839-427c-b652-87ee2a94e232",
     "showTitle": false,
     "title": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def limpiar_nombres_columnas(dataframe):\n",
    "    \"\"\"\n",
    "    Limpia y estandariza los nombres de las columnas en un DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - dataframe: DataFrame de pandas.\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame con nombres de columnas limpios.\n",
    "    \"\"\"\n",
    "    dataframe = dataframe.rename(columns=lambda x: re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "    return dataframe\n",
    "    \n",
    "df1Train = limpiar_nombres_columnas(df1Train)\n",
    "df2Train = limpiar_nombres_columnas(df2Train)\n",
    "df1Val = limpiar_nombres_columnas(df1Val)\n",
    "df2Val = limpiar_nombres_columnas(df2Val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "191cdfbb-d0be-46f8-9a90-aea4e8211272",
     "showTitle": false,
     "title": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#listar las columnas del dataframe\n",
    "\n",
    "def nombres_de_columnas(dataframe):\n",
    "    return dataframe.columns.tolist()\n",
    "\n",
    "# Supongamos que tu DataFrame se llama 'df'\n",
    "# Puedes ajustar el nombre según el que hayas utilizado\n",
    "\n",
    "nombres_columnas = nombres_de_columnas(df1Train)\n",
    "\n",
    "# Imprimir los nombres de las columnas\n",
    "print(f'Nombres de columnas: {nombres_columnas}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "var_input = ['01_receiver_transaction_count', '01_sender_sending_days', '01_branch_working_days', '01_net_amount_receiver', \n",
    "         '01_sender_minutes_since_last_transaction_2days', '01_sender_minutes_since_last_transaction_1day', \n",
    "         '01_sender_days_to_last_transaction_365', 'day_name_receiver_Friday', 'day_name_receiver_Monday', \n",
    "         'day_name_receiver_Saturday', 'day_name_receiver_Sunday', 'day_name_receiver_Thursday', 'day_name_receiver_Tuesday', \n",
    "         'day_name_receiver_Wednesday','id_payout_A', 'id_payout_C', 'id_payout_D', 'id_payout_M', 'id_payout_N', 'id_payout_O', \n",
    "         'id_payout_P', 'id_payout_S', 'id_payout_T', 'id_payout_X',\n",
    "         '01_isMexico','tx_brancity', 'tx_brancity_total', 'ptx_brancity','idlocation_fraud']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "00b45ce3-0e0c-4a02-b9ea-e39d5307115d",
     "showTitle": false,
     "title": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Ya lo traje dividido en conjuntos de entrenamiento (70%) y prueba (30%)\n",
    "\n",
    "X_train = df1Train[var_input]\n",
    "X_test = df1Val[var_input] \n",
    "y_train =  pd.DataFrame(df1Train['target_fraudes']) \n",
    "y_test = pd.DataFrame(df1Val['target_fraudes']) \n",
    "\n",
    "#Uni test y Val\n",
    "X = pd.concat([df1Train[var_input], df1Val[var_input]], ignore_index=True) \n",
    "Y = pd.DataFrame(pd.concat([df1Train['target_fraudes'], df1Val['target_fraudes']], ignore_index=True)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b55cb26d-4d58-4906-9a8c-9ab7be44df3b",
     "showTitle": false,
     "title": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calcular_porcentaje_valor_1(columna):\n",
    "    \"\"\"\n",
    "    Calcula el porcentaje de ocurrencia del valor 1 en una columna dicotómica.\n",
    "\n",
    "    Parameters:\n",
    "    - columna: Columna con valores binarios (0 o 1).\n",
    "\n",
    "    Returns:\n",
    "    - Porcentaje de ocurrencia del valor 1.\n",
    "    \"\"\"\n",
    "\n",
    "    total_registros = len(columna)\n",
    "    ocurrencias_valor_1 = columna.sum()\n",
    "\n",
    "    porcentaje_valor_1 = (ocurrencias_valor_1 / total_registros) * 100\n",
    "\n",
    "    return porcentaje_valor_1\n",
    "porcentaje_1 = calcular_porcentaje_valor_1(Y['target_fraudes'])\n",
    "porcentaje_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9612dbfc-6d13-4319-a1a4-713b5142d0b4",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## ENTRENAMIENTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c5b13dbe-2dbc-4cf6-8288-e8d8eade6fb6",
     "showTitle": false,
     "title": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Dividir el conjunto de datos en conjuntos de entrenamiento (80%) y prueba (20%)\n",
    "# X_train: características de entrenamiento, X_test: características de prueba\n",
    "# y_train: etiquetas de entrenamiento, y_test: etiquetas de prueba\n",
    "# Se utiliza un 20% de los datos para prueba, y se fija la semilla aleatoria en 88 para reproducibilidad.\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2, random_state = 88) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4ffb2573-b439-4e55-8d72-d3080e43a6b3",
     "showTitle": false,
     "title": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fit_parameters = {\n",
    "    #\"early_stopping_rounds\": 30,           # Número de rondas para detener el entrenamiento si no hay mejoras\n",
    "    \"eval_metric\": 'logloss',              # Métrica de evaluación a utilizar (en este caso, logloss)\n",
    "    \"eval_set\": [(X_test, y_test)],        # Conjunto de datos de prueba para la evaluación durante el entrenamiento\n",
    "    'eval_names': ['valid'],               # Nombre asignado al conjunto de evaluación\n",
    "    #'verbose': 100,                        # Nivel de detalle en la salida durante el entrenamiento\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "419b3f45-3007-4e2a-9695-bfafa06d672c",
     "showTitle": false,
     "title": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Parámetros para la búsqueda aleatoria de hiperparámetros\n",
    "param_testeo = {\n",
    "    \"n_estimators\": [5, 10, 15, 20, 25, 30, 35, 50, 100, 150, 300, 400, 500, 510, 520],\n",
    "    # Número de estimadores (árboles) a probar\n",
    "\n",
    "    \"num_leaves\": [2, 3, 4, 6, 10, 20, 25, 28, 30, 31, 32, 33, 35, 40, 45],\n",
    "    # Número máximo de nodos hoja en un árbol\n",
    "\n",
    "    \"max_depth\": [10, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 30, 35, 100, 125, 150, 170, 200, 250, 300, 400],\n",
    "    # Profundidad máxima de un árbol\n",
    "\n",
    "    \"colsample_bytree\": [0.50, 0.55, 0.6, 0.65, 0.68, 0.70, 0.71, 0.80, 0.81, 0.84, 0.85, 0.86, 0.9],\n",
    "    # Fracción de características a considerar en cada árbol\n",
    "\n",
    "    \"min_child_weight\": [0.001, 0.002, 0.0025, 0.0026, 0.0027, 0.003, 0.004, 0.005, 0.007, 0.008, 0.009],\n",
    "    # Peso mínimo necesario para crear un nuevo nodo en el árbol\n",
    "\n",
    "    \"learning_rate\": [0.1, 0.02, 0.03, 0.04, 0.07, 0.005, 0.003, 0.001],\n",
    "    # Tasa de aprendizaje del modelo\n",
    "\n",
    "    'subsample': [1],\n",
    "    # Fracción de muestras a utilizar para el entrenamiento de cada árbol\n",
    "\n",
    "    \"objective\": ['binary'],\n",
    "    # Tipo de problema a resolver (clasificación binaria en este caso)\n",
    "\n",
    "    \"importance_type\": [\"gini\", \"entropy\"],\n",
    "    # Tipo de importancia de las características\n",
    "\n",
    "    \"boosting_type\": [\"dart\", \"goss\", \"rf\", \"gbdt\"],\n",
    "    # Tipo de boosting a probar\n",
    "    \n",
    "    #\"is_unbalance\": ['True'],\n",
    "\n",
    "    \"scale_pos_weight\" : [0.002, 0.003, 0.004] ,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{'subsample': 1,\n",
    " 'scale_pos_weight': 0.002,\n",
    " 'objective': 'binary',\n",
    " 'num_leaves': 30,\n",
    " 'n_estimators': 500,\n",
    " 'min_child_weight': 0.0027,\n",
    " 'max_depth': 25,\n",
    " 'learning_rate': 0.07,\n",
    " 'importance_type': 'gini',\n",
    " 'colsample_bytree': 0.65,\n",
    " 'boosting_type': 'gbdt'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4f395c07-c0d3-41f5-abb4-e795e5ec160a",
     "showTitle": false,
     "title": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Parámetros para la búsqueda aleatoria de hiperparámetros\n",
    "param_testeoB = {\n",
    "    \"n_estimators\": [460, 480, 400,  500, 510, 520, 530],\n",
    "    # Número de estimadores (árboles) a probar\n",
    "\n",
    "    \"num_leaves\": [ 25, 26, 28, 30, 32, 34, 35],\n",
    "    # Número máximo de nodos hoja en un árbol\n",
    "\n",
    "    \"max_depth\": [ 22, 23, 24, 25, 26, 27, 28],\n",
    "    # Profundidad máxima de un árbol\n",
    "\n",
    "    \"colsample_bytree\": [ 0.6, 0.62, 0.65, 0.68],\n",
    "    # Fracción de características a considerar en cada árbol\n",
    "\n",
    "    \"min_child_weight\": [ 0.0025, 0.0026, 0.0027, 0.0031, 0.0033 ],\n",
    "    # Peso mínimo necesario para crear un nuevo nodo en el árbol\n",
    "\n",
    "    \"learning_rate\": [0.05,0.06, 0.07, 0.005, 0.001],\n",
    "    # Tasa de aprendizaje del modelo\n",
    "\n",
    "    'subsample': [1],\n",
    "    # Fracción de muestras a utilizar para el entrenamiento de cada árbol\n",
    "\n",
    "    \"objective\": ['binary'],\n",
    "    # Tipo de problema a resolver (clasificación binaria en este caso)\n",
    "\n",
    "    \"importance_type\": [\"gini\", \"entropy\"],\n",
    "    # Tipo de importancia de las características\n",
    "\n",
    "    \"boosting_type\": [\"dart\", \"goss\", \"rf\", \"gbdt\"],\n",
    "    # Tipo de boosting a probar\n",
    "    \n",
    "    #\"is_unbalance\": ['True'],\n",
    "\n",
    "    \"scale_pos_weight\" : [0.002, 0.003, 0.004] ,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d58842c3-f42c-402f-bae6-08030d6e91bb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# \"scale_pos_weight\": [2, 5, 10, 20, 24],\n",
    "# \"is_unbalance\": ['True']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "28b5e1a0-8b10-4d1d-8d27-9e0915578d16",
     "showTitle": false,
     "title": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Número de combinaciones de hiperparámetros a probar durante la búsqueda aleatoria\n",
    "n_HP_points_to_test = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dbb03a6e-bd9c-4bd7-bf0e-981e82c3e2b5",
     "showTitle": false,
     "title": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def entrenar_modelo_con_busqueda_aleatoria(X, Y, fit_parameters, param_testeo, n_HP_points_to_test=100, random_state=87):\n",
    "    \"\"\"\n",
    "    Entrena un modelo utilizando LightGBM con búsqueda aleatoria de hiperparámetros.\n",
    "\n",
    "    Parameters:\n",
    "    - X: Características del conjunto de datos.\n",
    "    - Y: Etiquetas del conjunto de datos.\n",
    "    - fit_parameters: Parámetros para el entrenamiento y evaluación del modelo.\n",
    "    - param_testeo: Parámetros para la búsqueda aleatoria de hiperparámetros.\n",
    "    - n_HP_points_to_test: Número de combinaciones de hiperparámetros a probar (predeterminado: 100).\n",
    "    - random_state: Semilla aleatoria para reproducibilidad (predeterminado: 87).\n",
    "\n",
    "    Returns:\n",
    "    - Objeto de resultados de RandomizedSearchCV.\n",
    "    \"\"\"\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=random_state)\n",
    "\n",
    "    # Limpiar y estandarizar los nombres de las columnas (llamando a la función anterior)\n",
    "    X_train = limpiar_nombres_columnas(X_train)\n",
    "    X_test = limpiar_nombres_columnas(X_test)\n",
    "\n",
    "    # Crear un clasificador LightGBM y realizar una búsqueda aleatoria de hiperparámetros\n",
    "    lgbm = LGBMClassifier(random_state=random_state)\n",
    "    result_trainRandom = RandomizedSearchCV(\n",
    "                        estimator=lgbm, \n",
    "                        param_distributions=param_testeo, \n",
    "                        n_iter=n_HP_points_to_test,\n",
    "                        scoring='f1_micro',\n",
    "                        cv=3,\n",
    "                        refit=True,\n",
    "                        random_state=random_state,\n",
    "                        verbose=True)\n",
    "\n",
    "    # Entrenar el modelo utilizando los datos de entrenamiento y los parámetros de ajuste\n",
    "    result_trainRandom.fit(X_train, y_train, **fit_parameters)\n",
    "\n",
    "    return result_trainRandom\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4ebf1652-f079-404e-92fb-1b6cb5fd1805",
     "showTitle": false,
     "title": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "result = entrenar_modelo_con_busqueda_aleatoria(X, Y, fit_parameters, param_testeo, n_HP_points_to_test=100, random_state=87)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "result.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{'subsample': 1,\n",
    " 'scale_pos_weight': 0.002,\n",
    " 'objective': 'binary',\n",
    " 'num_leaves': 30,\n",
    " 'n_estimators': 500,\n",
    " 'min_child_weight': 0.0027,\n",
    " 'max_depth': 25,\n",
    " 'learning_rate': 0.07,\n",
    " 'importance_type': 'gini',\n",
    " 'colsample_bytree': 0.65,\n",
    " 'boosting_type': 'gbdt'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lgb_classifier = LGBMClassifier(**result.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "35e07376-5bb5-450a-bd9c-d1cdb9d7951a",
     "showTitle": false,
     "title": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#experimento 1\n",
    "#lgb_classifier = LGBMClassifier(subsample= 1, objective = 'binary', num_leaves= 6, n_estimators= 520, min_child_weight=0.0026, max_depth= 23, learning_rate= 0.04, importance_type='gini', colsample_bytree= 0.68 ,boosting_type='goss', is_unbalance='True', num_boost_round = 30)\n",
    "#lgb_classifier = LGBMClassifier(subsample= 1, objective = 'binary', num_leaves= 31, min_child_weight=0.009, max_depth= 19, learning_rate= 0.05, importance_type='entropy', colsample_bytree= 0.6 ,boosting_type='dart', is_unbalance='True', num_boost_round = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "548fc1c7-7099-46d8-b4dd-dcef9ba72d69",
     "showTitle": false,
     "title": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "train_data  = lgb.Dataset(X_train, label = y_train)\n",
    "#model = lgb.train(params, train_data, num_boost_round=5)\n",
    "\n",
    "lgb_classifier.fit(np.array(X_train), y_train)\n",
    "#lgb_classifier.fit(train_data)\n",
    "lbg_predictions_labels = lgb_classifier.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d869acd8-14e2-4297-860c-dc798e9abb94",
     "showTitle": false,
     "title": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# modelo train\n",
    "data1_f_data_pred_rf= lgb_classifier.predict(X)     \n",
    "probab_rf = lgb_classifier.predict_proba(X)\n",
    "\n",
    "score_rf=np.delete(probab_rf, np.s_[0], axis=1) \n",
    "Y_c=Y.copy()\n",
    "Y_c['preds_rf'] = data1_f_data_pred_rf\n",
    "Y_c['score_rf'] = score_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "17cc26fe-d9b1-4a06-99f5-5335a5b97d49",
     "showTitle": false,
     "title": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Realizar predicciones con el modelo entrenado en el conjunto de entrenamiento\n",
    "data1_f_data_pred_rf = lgb_classifier.predict(X)\n",
    "\n",
    "# Obtener las probabilidades predichas para la clase positiva (clase 1) del modelo\n",
    "probab_rf = lgb_classifier.predict_proba(X)\n",
    "\n",
    "# Extraer las puntuaciones (probabilidades) asociadas con la clase positiva\n",
    "score_rf = np.delete(probab_rf, np.s_[0], axis=1)\n",
    "\n",
    "# Crear una copia de las etiquetas verdaderas (Y) para análisis adicional\n",
    "Y_c = Y.copy()\n",
    "\n",
    "# Agregar las predicciones y las puntuaciones del modelo a las etiquetas verdaderas\n",
    "Y_c['preds_rf'] = data1_f_data_pred_rf\n",
    "Y_c['score_rf'] = score_rf\n",
    "\n",
    "# Los datos ahora contienen etiquetas verdaderas, predicciones y puntuaciones del modelo\n",
    "# Puedes utilizar estos resultados para realizar análisis y evaluar el rendimiento del modelo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lgb.plot_importance(lgb_classifier, importance_type=\"gain\", figsize=(7,6), title=\"LightGBM Feature Importance (Gain)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot feature importance using Split\n",
    "lgb.plot_importance(lgb_classifier, importance_type=\"split\", figsize=(7,6), title=\"LightGBM Feature Importance (Split)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "# save model\n",
    "joblib.dump(lgb_classifier, 'ModeloV1Todos.pkl')\n",
    "# load model\n",
    "#gbm_pickle = joblib.load('ModeloV1T1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Y_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    " Y_c[Y_c[var_target] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(confusion_matrix(Y_c[var_target], Y_c['preds_rf']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.histplot(data = Y_c[Y_c[var_target] == True], x='score_rf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#sns.histplot(data = Y_c[Y_c[var_target] == False], x='score_rf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "target_names = ['No fraude', 'Fraude']\n",
    "print(classification_report(Y_c[var_target], Y_c['preds_rf'], target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#aux = Y_c[Y_c['FRAUD_DECILE'] < 4][var_target]\n",
    "#aux.target1.value_counts()\n",
    "Y_c[var_target].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Dividir las predicciones en deciles y calcular la captura del 30% en el conjunto de entrenamiento\n",
    "percentiles = pd.qcut(Y_c['score_rf'], q=10, duplicates='drop').astype(str)\n",
    "percentile_label = {p: l for l, p in enumerate(sorted(percentiles.unique(), reverse=True), start=1)}\n",
    "percentiles = percentiles.map(percentile_label)\n",
    "Y_c['FRAUD_DECILE'] = np.nan\n",
    "Y_c['FRAUD_DECILE'] = Y_c['FRAUD_DECILE'].astype('Int32')\n",
    "Y_c['FRAUD_DECILE'] = percentiles\n",
    "print('FRAUD CAPTURA 30%:')\n",
    "print(sum(Y_c[Y_c['FRAUD_DECILE'] < 4]['target1']) / sum(Y_c['target1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DECILES_T = pd.crosstab(Y_c['FRAUD_DECILE'], Y_c['target1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c696761f-b1a0-4d0d-a9f1-d9fda10a7b0e",
     "showTitle": false,
     "title": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DECILES_T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "71386cf3-61f2-44f2-aec7-360594b577b2",
     "showTitle": false,
     "title": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DECILES_T.plot.bar(stacked=False, rot=0,subplots=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d2607d30-6393-4d6e-ba95-acb61bf350dd",
     "showTitle": false,
     "title": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Calcular la curva de ganancia acumulativa y el LIFT del modelo en el conjunto de entrenamiento\n",
    "#classes = np.unique(Y_c[['target']])\n",
    "#percentages, gains = cumulative_gain_curve(Y_c[['target']], Y_c['score_rf'], classes[1])\n",
    "#percentages = percentages[1:]\n",
    "#gains = gains[1:]\n",
    "#gains = gains / percentages\n",
    "#indice = round(len(gains) * 0.1)\n",
    "#print('LIFT INV CHURN TRAIN:')\n",
    "#print(gains[indice])\n",
    "\n",
    "# Calcular el área bajo la curva ROC del modelo en el conjunto de entrenamiento\n",
    "#print('ROC INV CHURN TRAIN:')\n",
    "#print(roc_auc_score(Y_c[['target']], Y_c['preds_rf']))\n",
    "\n",
    "# Calcular la estadística KS del modelo en el conjunto de entrenamiento\n",
    "#thresholds, pct1, pct2, ks_statistic, max_distance_at, classes = binary_ks_curve(Y_c[['target']], Y_c['score_rf'].ravel())\n",
    "#print('KS INV CHURN TRAIN:')\n",
    "#print(ks_statistic)\n",
    "\n",
    "# Calcular la precisión y el recall del modelo en el conjunto de entrenamiento\n",
    "#precision = precision_score(Y_c[['target']], Y_c['preds_rf'])\n",
    "#recall = recall_score(Y_c[['target']], Y_c['preds_rf'])\n",
    "\n",
    "#print('Precision INV CHURN TRAIN:')\n",
    "#print(precision)\n",
    "#print('Recall INV CHURN TRAIN:')\n",
    "#print(recall)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e6fcd014-a695-48a9-8af9-a121268015cb",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## TESTEO ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "42e3788f-3cd7-45f4-bc86-72637798fd75",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "s3_url = f\"viamericas-datalake-dev-us-east-1-283731589572-raw/FraudModel/Data4Model\"\n",
    "\n",
    "tes = pd.read_parquet(f\"s3://{s3_url}/TargetTodos/Test/Test.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b88b7157-ce0f-4a4c-bcbd-fd2307aacc68",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "## TARGETS de TESTE0\n",
    "#target 1\n",
    "tgt = tes['target_fraudes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##lista de variables de input\n",
    "X = tes[var_input]\n",
    "Y = tes['target_fraudes'] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a08ae9f0-5d1e-4675-ac5e-891ef44cecee",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "testeo = tes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b7bd1a47-7799-4579-b3b0-66207df6f13d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def limpiar_nombres_columnas(dataframe):\n",
    "    \"\"\"\n",
    "    Limpia y estandariza los nombres de las columnas en un DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - dataframe: DataFrame de pandas.\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame con nombres de columnas limpios.\n",
    "    \"\"\"\n",
    "    dataframe = dataframe.rename(columns=lambda x: re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "    return dataframe\n",
    "    \n",
    "testeo = limpiar_nombres_columnas(testeo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c3bcf455-00db-437e-9b14-40b53d895d0b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "testeo = testeo\n",
    " \n",
    "print (\"Dataset Length: \", len(testeo)) \n",
    "print (\"Dataset Shape: \", testeo.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0c0fb05b-e907-4ead-87c5-ec1a40104b55",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "testeo['target_fraudes'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1318a536-2a23-456f-842c-ac6d1d389126",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "## Variables del modelo\n",
    "X_TESTEO = tes[var_input]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_TESTEO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "72208179-c108-43d3-b300-69ffbdf680c3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Extrayendo la columna 'target' del DataFrame 'testeo' y creando un nuevo DataFrame 'Y_TESTEO'\n",
    "Y_TESTEO = testeo['target_fraudes']\n",
    "\n",
    "# Prediciendo la variable objetivo para el conjunto de datos de prueba 'X_TESTEO' utilizando el clasificador LightGBM\n",
    "testeo_data_pred_rf = lgb_classifier.predict(X_TESTEO)\n",
    "\n",
    "# Prediciendo las probabilidades de clase para cada observación en 'X_TESTEO' utilizando el clasificador LightGBM\n",
    "probab_rf = lgb_classifier.predict_proba(X_TESTEO)\n",
    "\n",
    "# Eliminando la primera columna (se asume que son las probabilidades de la clase negativa) de las probabilidades predichas\n",
    "# Se asume que la segunda columna contiene las probabilidades para la clase positiva\n",
    "score_rf = np.delete(probab_rf, np.s_[0], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9b5268e2-53ec-4de6-b411-6a2bfbbf737d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Creando una copia del DataFrame 'Y_TESTEO' para preservar los datos originales\n",
    "Y_TESTEO_c = Y_TESTEO.copy()\n",
    "\n",
    "# Agregando una nueva columna 'preds_rf' al DataFrame copiado con las predicciones del clasificador LightGBM\n",
    "Y_TESTEO_c['preds_rf'] = testeo_data_pred_rf\n",
    "\n",
    "# Agregando una nueva columna 'score_rf' al DataFrame copiado con las probabilidades de la clase positiva\n",
    "Y_TESTEO_c['score_rf'] = score_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir las predicciones en deciles y calcular la captura del 30% en el conjunto de entrenamiento\n",
    "percentiles = pd.qcut(Y_TESTEO_c['score_rf'], q=10, duplicates='drop').astype(str)\n",
    "percentile_label = {p: l for l, p in enumerate(sorted(percentiles.unique(), reverse=True), start=1)}\n",
    "percentiles = percentiles.map(percentile_label)\n",
    "Y_TESTEO_c['FRAUD_DECILE'] = np.nan\n",
    "Y_TESTEO_c['FRAUD_DECILE'] = Y_TESTEO_c['FRAUD_DECILE'].astype('Int32')\n",
    "Y_TESTEO_c['FRAUD_DECILE'] = percentiles\n",
    "print('FRAUD CAPTURA 30%:')\n",
    "print(sum(Y_TESTEO_c[Y_TESTEO_c['FRAUD_DECILE'] < 4]['target_fraudes']) / sum(Y_TESTEO_c['target_fraudes']))\n",
    "#Y_TESTEO_c.to_csv(r'./SCORES/primera_prueba.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5e384a20-995d-454d-a88c-8d7acca12cca",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "DECILES = pd.crosstab(Y_TESTEO_c['FRAUD_DECILE'], Y_TESTEO_c['target_fraudes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6a22fdbf-71db-47c3-86e7-dcfea4708f07",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "DECILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a0acf01d-13b6-4a07-9fb1-93c341c272bc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "DECILES.plot.bar(stacked=False, rot=0,subplots=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "54a0c0f2-120c-47e0-9447-85aeb5b4de2d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Calcular la curva de ganancia acumulativa y el LIFT del modelo en el conjunto de entrenamiento\n",
    "classes = np.unique(Y_TESTEO_c[['target']])\n",
    "percentages, gains = cumulative_gain_curve(Y_TESTEO_c[['target_fraudes']], Y_TESTEO_c['score_rf'], classes[1])\n",
    "percentages = percentages[1:]\n",
    "gains = gains[1:]\n",
    "gains = gains / percentages\n",
    "indice = round(len(gains) * 0.1)\n",
    "print('LIFT INV CHURN TESTEO:')\n",
    "print(gains[indice])\n",
    "\n",
    "# Calcular el área bajo la curva ROC del modelo en el conjunto de entrenamiento\n",
    "print('ROC INV CHURN TESTEO:')\n",
    "print(roc_auc_score(Y_TESTEO_c[['target']], Y_TESTEO_c['preds_rf']))\n",
    "\n",
    "# Calcular la estadística KS del modelo en el conjunto de entrenamiento\n",
    "thresholds, pct1, pct2, ks_statistic, max_distance_at, classes = binary_ks_curve(Y_TESTEO_c[['target']], Y_TESTEO_c['score_rf'].ravel())\n",
    "print('KS INV CHURN TESTEO:')\n",
    "print(ks_statistic)\n",
    "\n",
    "# Calcular la precisión y el recall del modelo en el conjunto de entrenamiento\n",
    "precision = precision_score(Y_TESTEO_c[['target']], Y_TESTEO_c['preds_rf'])\n",
    "recall = recall_score(Y_TESTEO_c[['target']], Y_TESTEO_c['preds_rf'])\n",
    "print('Precision INV CHURN TESTEO:')\n",
    "print(precision)\n",
    "print('Recall INV CHURN TESTEO:')\n",
    "print(recall)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b1f8cea5-bbb6-4676-81f0-8ed2e7a9333d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Guardando las importancias de las características (feature importance) en un archivo de texto\n",
    "# La importancia se mide en términos de ganancia ('gain') según el clasificador LightGBM\n",
    "# Se utiliza la función 'np.savetxt' para escribir en un archivo de texto\n",
    "# El archivo se guarda en la ruta './SCORES/importance_1.txt'\n",
    "# Se utiliza 'lgb_classifier.booster_.feature_importance' para obtener las importancias de las características\n",
    "# Se especifica el formato de los datos en el archivo como números de punto flotante ('%f')\n",
    "\n",
    "#np.savetxt('./SCORES/importance_78.txt', lgb_classifier.booster_.feature_importance(importance_type='gain'),fmt='%f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1d562291-b328-449f-886a-c1a2fdda3e2d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##TESTEAR TODA LA BASE (sin restricciones de tenure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2cac4510-6199-471b-97b1-1081bb4a25c3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "tes1 = pd.read_parquet('./ABT/Prepoc_MX_2023-11-19.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "68e0ce50-eb2d-4f2c-9222-eb4a4b01d025",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "tes2 = pd.read_parquet('./ABT/Prepoc_MX_2023-11-26.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "73678c47-79a2-40a1-8d25-f5615a3fd8b8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "tes3 = pd.read_parquet('./ABT/Prepoc_MX_2023-12-03.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "33e57000-a4f4-4dbb-bc81-bcaaa7018529",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "tes4 = pd.read_parquet('./ABT/Prepoc_MX_2023-12-10.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "24ef412c-dec1-4dad-aad5-f467792e59ad",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "## unir las cuatro cosechas\n",
    "\n",
    "tes = [tes1, tes2, tes3, tes4]\n",
    "\n",
    "tes = pd.concat(tes, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "44ea7e7a-ff47-455a-9009-48c0ed0781c5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "## TARGETS de TESTE0\n",
    "\n",
    "#target 1\n",
    "tgt1 = pd.read_parquet('./ABT/Target_MX_2023-11-19.parquet')\n",
    "#target 1\n",
    "tgt2 = pd.read_parquet('./ABT/Target_MX_2023-11-26.parquet')\n",
    "#target 1\n",
    "tgt3 = pd.read_parquet('./ABT/Target_MX_2023-12-03.parquet')\n",
    "#target 1\n",
    "tgt4 = pd.read_parquet('./ABT/Target_MX_2023-12-10.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c2e65078-0d83-4163-a575-6cd735f4623c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "tgt = [tgt1, tgt2, tgt3, tgt4]\n",
    "\n",
    "tgt = pd.concat(tgt, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b1caf971-d634-43bb-a3d9-1e5cf05fdf27",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "tgt = tgt.drop('country_cd', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7bf27f96-27b4-499d-8cc3-9e43bf8d4999",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#ordenar las bases antes de unirlas (no es obligatorio)\n",
    "tes = tes.sort_values(by=[\"cbs_reg_user_id_cd\", \"week_dt\"])\n",
    "tgt = tgt.sort_values(by=[\"cbs_reg_user_id_cd\", \"week_dt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c71354a6-11c6-49c6-938b-b25f50160330",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "tgt['target'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5ba5627c-d7e2-41ac-a013-7c2024c84950",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "testeo_f = pd.merge(tes1, tgt1, how=\"left\", on=[\"cbs_reg_user_id_cd\", \"week_dt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3dc69b00-3988-4e2a-9e55-b841a24880fb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def limpiar_nombres_columnas(dataframe):\n",
    "    \"\"\"\n",
    "    Limpia y estandariza los nombres de las columnas en un DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - dataframe: DataFrame de pandas.\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame con nombres de columnas limpios.\n",
    "    \"\"\"\n",
    "    dataframe = dataframe.rename(columns=lambda x: re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "    return dataframe\n",
    "    \n",
    "testeo_f = limpiar_nombres_columnas(testeo_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f550a28a-dbcf-4546-8ff8-f9d447ce8185",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "testeo_f['cbs_reg_user_id_cd'] = testeo_f['cbs_reg_user_id_cd'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fa059faf-cded-4ebb-85c3-196722a8697a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "testeo_f = testeo_f\n",
    "testeo_f['ID']=testeo_f['cbs_reg_user_id_cd']\n",
    "testeo_f = testeo_f.set_index('ID')  \n",
    "#testeo=testeo.round(2)\n",
    "\n",
    " \n",
    "print (\"Dataset Length: \", len(testeo_f)) \n",
    "print (\"Dataset Shape: \", testeo_f.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "014cf86b-9d2a-4607-b344-fce85143ddfb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "testeo_f['target'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5caa3b71-ebb9-4f06-9c4a-f12dee6fac63",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "X_TESTEO_f = testeo_f[['tenure_day',\n",
    "'tenure_m']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2b4408b6-b6e8-4bcb-8604-d66dc468d8cc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Extrayendo la columna 'target' del DataFrame 'testeo' y creando un nuevo DataFrame 'Y_TESTEO'\n",
    "Y_TESTEO_f = testeo_f[['target']]\n",
    "\n",
    "# Prediciendo la variable objetivo para el conjunto de datos de prueba 'X_TESTEO' utilizando el clasificador LightGBM\n",
    "testeo_data_pred_rf = lgb_classifier.predict(X_TESTEO_f)\n",
    "\n",
    "# Prediciendo las probabilidades de clase para cada observación en 'X_TESTEO' utilizando el clasificador LightGBM\n",
    "probab_rf = lgb_classifier.predict_proba(X_TESTEO_f)\n",
    "\n",
    "# Eliminando la primera columna (se asume que son las probabilidades de la clase negativa) de las probabilidades predichas\n",
    "# Se asume que la segunda columna contiene las probabilidades para la clase positiva\n",
    "score_rf = np.delete(probab_rf, np.s_[0], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "de1f9ea9-b9ee-4657-9c97-0f6b6f2597a9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Creando una copia del DataFrame 'Y_TESTEO' para preservar los datos originales\n",
    "Y_TESTEO_c = Y_TESTEO_f.copy()\n",
    "\n",
    "# Agregando una nueva columna 'preds_rf' al DataFrame copiado con las predicciones del clasificador LightGBM\n",
    "Y_TESTEO_c['preds_rf'] = testeo_data_pred_rf\n",
    "\n",
    "# Agregando una nueva columna 'score_rf' al DataFrame copiado con las probabilidades de la clase positiva\n",
    "Y_TESTEO_c['score_rf'] = score_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9fc1fe91-cb9a-4308-bd5a-23ab1b623f88",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Calcular la curva de ganancia acumulativa y el LIFT del modelo en el conjunto de entrenamiento\n",
    "classes = np.unique(Y_TESTEO_c[['target']])\n",
    "percentages, gains = cumulative_gain_curve(Y_TESTEO_c[['target']], Y_TESTEO_c['score_rf'], classes[1])\n",
    "percentages = percentages[1:]\n",
    "gains = gains[1:]\n",
    "gains = gains / percentages\n",
    "indice = round(len(gains) * 0.1)\n",
    "print('LIFT INV CHURN TESTEO:')\n",
    "print(gains[indice])\n",
    "\n",
    "# Calcular el área bajo la curva ROC del modelo en el conjunto de entrenamiento\n",
    "print('ROC INV CHURN TESTEO:')\n",
    "print(roc_auc_score(Y_TESTEO_c[['target']], Y_TESTEO_c['preds_rf']))\n",
    "\n",
    "# Calcular la estadística KS del modelo en el conjunto de entrenamiento\n",
    "thresholds, pct1, pct2, ks_statistic, max_distance_at, classes = binary_ks_curve(Y_TESTEO_c[['target']], Y_TESTEO_c['score_rf'].ravel())\n",
    "print('KS INV CHURN TESTEO:')\n",
    "print(ks_statistic)\n",
    "\n",
    "# Calcular la precisión y el recall del modelo en el conjunto de entrenamiento\n",
    "precision = precision_score(Y_TESTEO_c[['target']], Y_TESTEO_c['preds_rf'])\n",
    "recall = recall_score(Y_TESTEO_c[['target']], Y_TESTEO_c['preds_rf'])\n",
    "print('Precision INV CHURN TESTEO:')\n",
    "print(precision)\n",
    "print('Recall INV CHURN TESTEO:')\n",
    "print(recall)\n",
    "\n",
    "# Dividir las predicciones en deciles y calcular la captura del 30% en el conjunto de entrenamiento\n",
    "percentiles = pd.qcut(Y_TESTEO_c['score_rf'], q=10, duplicates='drop').astype(str)\n",
    "percentile_label = {p: l for l, p in enumerate(sorted(percentiles.unique(), reverse=True), start=1)}\n",
    "percentiles = percentiles.map(percentile_label)\n",
    "Y_TESTEO_c['CHURNINV_DECILE'] = np.nan\n",
    "Y_TESTEO_c['CHURNINV_DECILE'] = Y_TESTEO_c['CHURNINV_DECILE'].astype('Int32')\n",
    "Y_TESTEO_c['CHURNINV_DECILE'] = percentiles\n",
    "print('INV CHURN CAPTURA 30%:')\n",
    "print(sum(Y_TESTEO_c[Y_TESTEO_c['CHURNINV_DECILE'] < 4]['target']) / sum(Y_TESTEO_c['target']))\n",
    "#Y_TESTEO_c.to_csv(r'./SCORES/primera_prueba.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bc3c7d0d-4795-4b19-adab-2bf54e6a2646",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "DECILES = pd.crosstab(Y_TESTEO_c['CHURNINV_DECILE'], Y_TESTEO_c['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "154fc078-d694-4310-8bcb-1f776c821a63",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "DECILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "770a00a6-4d80-439a-8bb0-3a1ac2bc6b1e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "DECILES.plot.bar(stacked=False, rot=0,subplots=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "146deb8d-b353-431c-b32b-c32e8cfcdd55",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "Y_TESTEO_c.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d074c2fd-20a4-411e-8475-11bb3b101594",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "Y_TESTEO_c.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e13a5fcc-062c-4f07-8805-14e7c12fb045",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "testeo_f2= testeo_f[['cbs_reg_user_id_cd', 'tenure_day', 'tenure_m','days_last_paid','week_dt']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6d320fa5-adcf-4a5c-8b1c-2e5c828f47f5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "testeo_f2 = testeo_f2.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2bdc34bd-3bfb-4f08-9b1c-96470d7900b8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "testeo_f2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ea7fd300-33da-48b3-80eb-2194ccd3cc7a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "testeo_f2.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "83a9829a-380c-44e4-9f60-3224ab295cb7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "Y_TESTEO_c['ID'] = Y_TESTEO_c['ID'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5e0e1ef2-fad8-45a9-8a38-709a3b0bfadb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "testeo_f2['ID'] = testeo_f2['ID'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "817bfbc3-1bd6-495a-b697-dae922195f5e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "testeo_all10dec2023 = pd.merge(testeo_f2, Y_TESTEO_c, how=\"left\", on=[\"ID\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0a5e88f4-33b8-4f89-9bd3-6b46a79d5c70",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "testeo_all10dec2023.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b4dc1ee5-2f2f-49bf-b802-b5a6ba57327c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "testeo_all10dec2023= testeo_all10dec2023[['cbs_reg_user_id_cd', 'target','preds_rf','score_rf','CHURNINV_DECILE','tenure_m']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f7f3428a-922f-422d-9395-e73732c39644",
     "showTitle": false,
     "title": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "testeo_all10dec2023.to_csv('testeo_60Mx10dec2023.csv')"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "03.3-Train MX U_60T(lgbm)",
   "widgets": {}
  },
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.m5.large",
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
