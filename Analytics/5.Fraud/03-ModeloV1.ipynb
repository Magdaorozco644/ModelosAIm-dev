{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a73bdbc-db0f-4a2f-9526-891933b5e778",
   "metadata": {},
   "source": [
    "## LightGBM de SageMaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8092eb17-5fed-41ef-ad0b-308665032e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import image_uris, model_uris, script_uris\n",
    "\n",
    "train_model_id, train_model_version, train_scope = \"lightgbm-classification-model\", \"*\", \"training\"\n",
    "training_instance_type = \"ml.m5.12xlarge\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f856557c-dfad-4d44-a6ad-1a254e089d74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using model 'lightgbm-classification-model' with wildcard version identifier '*'. You can pin to version '2.1.0' for more stable results. Note that models may have different input/output signatures after a major version upgrade.\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the docker image\n",
    "train_image_uri = image_uris.retrieve(\n",
    "    region=None,\n",
    "    framework=None,\n",
    "    model_id=train_model_id,\n",
    "    model_version=train_model_version,\n",
    "    image_scope=train_scope,\n",
    "    instance_type=training_instance_type\n",
    ")\n",
    "\n",
    "# Retrieve the training script\n",
    "train_source_uri = script_uris.retrieve(\n",
    "    model_id=train_model_id, model_version=train_model_version, script_scope=train_scope\n",
    ")\n",
    "\n",
    "train_model_uri = model_uris.retrieve(\n",
    "    model_id=train_model_id, model_version=train_model_version, model_scope=train_scope\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ab18e0bb-e9fb-4679-9d0e-279a80c466e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buckets para Train data y Output\n",
    "training_data_bucket = f\"viamericas-datalake-dev-us-east-1-283731589572-raw/FraudModel/Data4Model\"\n",
    "#training_data_prefix = \"training-datasets/tabular_multiclass/\"\n",
    "\n",
    "training_dataset_s3_path = f\"s3://{training_data_bucket}/Train\" #/exp1.parquet \n",
    "validation_dataset_s3_path = f\"s3://{training_data_bucket}/Validation\" #/exp1.parquet \n",
    "\n",
    "output_bucket = f\"viamericas-datalake-dev-us-east-1-283731589572-analytics\"\n",
    "output_prefix = \"FraudModel\"\n",
    "\n",
    "s3_output_location = f\"s3://{output_bucket}/{output_prefix}/output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d6b2af9e-c5f0-4a7e-aa96-a5676d046fcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_boost_round': '500', 'early_stopping_rounds': '30', 'metric': 'auto', 'learning_rate': '0.009', 'num_leaves': '67', 'feature_fraction': '0.74', 'bagging_fraction': '0.53', 'bagging_freq': '5', 'max_depth': '11', 'min_data_in_leaf': '26', 'max_delta_step': '0.0', 'lambda_l1': '0.0', 'lambda_l2': '0.0', 'boosting': 'gbdt', 'min_gain_to_split': '0.0', 'scale_pos_weight': '1.0', 'tree_learner': 'serial', 'feature_fraction_bynode': '1.0', 'is_unbalance': 'False', 'max_bin': '255', 'num_threads': '0', 'verbosity': '1', 'use_dask': 'False'}\n"
     ]
    }
   ],
   "source": [
    "# Defino hiperparametros\n",
    "from sagemaker import hyperparameters\n",
    "\n",
    "# Retrieve the default hyperparameters for training the model\n",
    "hyperparameters = hyperparameters.retrieve_default(\n",
    "    model_id=train_model_id, model_version=train_model_version\n",
    ")\n",
    "\n",
    "# [Optional] Override default hyperparameters with custom values\n",
    "hyperparameters[\n",
    "    \"num_boost_round\"\n",
    "] = \"500\"\n",
    "print(hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "215664a2-8b59-4a0b-9cf4-cc01c2fd17ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker.utils import name_from_base\n",
    "\n",
    "training_job_name = name_from_base(f\"built-in-algo-{train_model_id}-training2\")\n",
    "\n",
    "# Create SageMaker Estimator instance\n",
    "tabular_estimator = Estimator(\n",
    "    role=\"arn:aws:iam::283731589572:role/service-role/AmazonSageMaker-ExecutionRole-20231127T122316\",\n",
    "    image_uri=train_image_uri,\n",
    "    source_dir=train_source_uri,\n",
    "    model_uri=train_model_uri,\n",
    "    entry_point=\"transfer_learning.py\",\n",
    "    instance_count=1, # for distributed training, specify an instance_count greater than 1\n",
    "    instance_type=training_instance_type,\n",
    "    max_run=360000,\n",
    "    hyperparameters=hyperparameters,\n",
    "    output_path=s3_output_location\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178ff55b-fce6-4ac5-9e14-98b94c47bb16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: built-in-algo-lightgbm-classification-m-2024-03-12-14-56-09-133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-12 14:56:12 Starting - Starting the training job...\n",
      "2024-03-12 14:56:28 Starting - Preparing the instances for training...\n",
      "2024-03-12 14:57:01 Downloading - Downloading input data...\n",
      "2024-03-12 14:57:31 Training - Training image download completed. Training in progress....\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2024-03-12 14:57:58,907 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2024-03-12 14:57:58,908 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2024-03-12 14:57:58,917 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2024-03-12 14:57:58,919 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2024-03-12 14:57:59,439 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.8 -m pip install -r requirements.txt\u001b[0m\n",
      "\u001b[34mProcessing ./lib/dask/dask-2022.12.1-py3-none-any.whl\u001b[0m\n",
      "\u001b[34mProcessing ./lib/distributed/distributed-2022.12.1-py3-none-any.whl\u001b[0m\n",
      "\u001b[34mProcessing ./lib/graphviz/graphviz-0.17-py3-none-any.whl\u001b[0m\n",
      "\u001b[34mProcessing ./lib/HeapDict/HeapDict-1.0.1-py3-none-any.whl\u001b[0m\n",
      "\u001b[34mProcessing ./lib/lightgbm/lightgbm-3.3.3-py3-none-manylinux1_x86_64.whl\u001b[0m\n",
      "\u001b[34mProcessing ./lib/locket/locket-1.0.0-py2.py3-none-any.whl\u001b[0m\n",
      "\u001b[34mProcessing ./lib/msgpack/msgpack-1.0.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\u001b[0m\n",
      "\u001b[34mProcessing ./lib/partd/partd-1.3.0-py3-none-any.whl\u001b[0m\n",
      "\u001b[34mProcessing ./lib/sortedcontainers/sortedcontainers-2.4.0-py2.py3-none-any.whl\u001b[0m\n",
      "\u001b[34mProcessing ./lib/tblib/tblib-1.7.0-py2.py3-none-any.whl\u001b[0m\n",
      "\u001b[34mProcessing ./lib/toolz/toolz-0.12.0-py3-none-any.whl\u001b[0m\n",
      "\u001b[34mProcessing ./lib/zict/zict-2.2.0-py2.py3-none-any.whl\u001b[0m\n",
      "\u001b[34mProcessing ./lib/sagemaker_jumpstart_tabular_script_utilities/sagemaker_jumpstart_tabular_script_utilities-1.0.0-py2.py3-none-any.whl\u001b[0m\n",
      "\u001b[34mProcessing ./lib/sagemaker_jumpstart_prepack_script_utilities/sagemaker_jumpstart_prepack_script_utilities-1.0.0-py2.py3-none-any.whl\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.8/site-packages (from dask==2022.12.1->-r requirements.txt (line 1)) (21.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: cloudpickle>=1.1.1 in /opt/conda/lib/python3.8/site-packages (from dask==2022.12.1->-r requirements.txt (line 1)) (2.0.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: click>=7.0 in /opt/conda/lib/python3.8/site-packages (from dask==2022.12.1->-r requirements.txt (line 1)) (8.0.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyyaml>=5.3.1 in /opt/conda/lib/python3.8/site-packages (from dask==2022.12.1->-r requirements.txt (line 1)) (5.4.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: fsspec>=0.6.0 in /opt/conda/lib/python3.8/site-packages (from dask==2022.12.1->-r requirements.txt (line 1)) (2021.10.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tornado>=6.0.3 in /opt/conda/lib/python3.8/site-packages (from distributed==2022.12.1->-r requirements.txt (line 2)) (6.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: jinja2 in /opt/conda/lib/python3.8/site-packages (from distributed==2022.12.1->-r requirements.txt (line 2)) (3.0.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: urllib3 in /opt/conda/lib/python3.8/site-packages (from distributed==2022.12.1->-r requirements.txt (line 2)) (1.26.7)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: psutil>=5.0 in /opt/conda/lib/python3.8/site-packages (from distributed==2022.12.1->-r requirements.txt (line 2)) (5.6.7)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scikit-learn!=0.22.0 in /opt/conda/lib/python3.8/site-packages (from lightgbm==3.3.3->-r requirements.txt (line 5)) (0.24.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy in /opt/conda/lib/python3.8/site-packages (from lightgbm==3.3.3->-r requirements.txt (line 5)) (1.19.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scipy in /opt/conda/lib/python3.8/site-packages (from lightgbm==3.3.3->-r requirements.txt (line 5)) (1.7.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: wheel in /opt/conda/lib/python3.8/site-packages (from lightgbm==3.3.3->-r requirements.txt (line 5)) (0.37.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging>=20.0->dask==2022.12.1->-r requirements.txt (line 1)) (2.4.7)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from scikit-learn!=0.22.0->lightgbm==3.3.3->-r requirements.txt (line 5)) (2.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.8/site-packages (from scikit-learn!=0.22.0->lightgbm==3.3.3->-r requirements.txt (line 5)) (1.0.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.8/site-packages (from jinja2->distributed==2022.12.1->-r requirements.txt (line 2)) (2.0.1)\u001b[0m\n",
      "\u001b[34mInstalling collected packages: toolz, locket, partd, HeapDict, zict, tblib, sortedcontainers, msgpack, dask, sagemaker-jumpstart-tabular-script-utilities, sagemaker-jumpstart-prepack-script-utilities, lightgbm, graphviz, distributed\u001b[0m\n",
      "\u001b[34mSuccessfully installed HeapDict-1.0.1 dask-2022.12.1 distributed-2022.12.1 graphviz-0.17 lightgbm-3.3.3 locket-1.0.0 msgpack-1.0.4 partd-1.3.0 sagemaker-jumpstart-prepack-script-utilities-1.0.0 sagemaker-jumpstart-tabular-script-utilities-1.0.0 sortedcontainers-2.4.0 tblib-1.7.0 toolz-0.12.0 zict-2.2.0\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m2024-03-12 14:58:02,199 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2024-03-12 14:58:02,211 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2024-03-12 14:58:02,221 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2024-03-12 14:58:02,229 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"model\": \"/opt/ml/input/data/model\",\n",
      "        \"train\": \"/opt/ml/input/data/train\",\n",
      "        \"validation\": \"/opt/ml/input/data/validation\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"bagging_fraction\": \"0.53\",\n",
      "        \"bagging_freq\": \"5\",\n",
      "        \"boosting\": \"gbdt\",\n",
      "        \"early_stopping_rounds\": \"30\",\n",
      "        \"feature_fraction\": \"0.74\",\n",
      "        \"feature_fraction_bynode\": \"1.0\",\n",
      "        \"is_unbalance\": \"False\",\n",
      "        \"lambda_l1\": \"0.0\",\n",
      "        \"lambda_l2\": \"0.0\",\n",
      "        \"learning_rate\": \"0.009\",\n",
      "        \"max_bin\": \"255\",\n",
      "        \"max_delta_step\": \"0.0\",\n",
      "        \"max_depth\": \"11\",\n",
      "        \"metric\": \"auto\",\n",
      "        \"min_data_in_leaf\": \"26\",\n",
      "        \"min_gain_to_split\": \"0.0\",\n",
      "        \"num_boost_round\": \"500\",\n",
      "        \"num_leaves\": \"67\",\n",
      "        \"num_threads\": \"0\",\n",
      "        \"scale_pos_weight\": \"1.0\",\n",
      "        \"tree_learner\": \"serial\",\n",
      "        \"use_dask\": \"False\",\n",
      "        \"verbosity\": \"1\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"model\": {\n",
      "            \"ContentType\": \"application/x-sagemaker-model\",\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"ContentType\": \"application/x-parquet\",\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"validation\": {\n",
      "            \"ContentType\": \"application/x-parquet\",\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"built-in-algo-lightgbm-classification-m-2024-03-12-14-56-09-133\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://jumpstart-cache-prod-us-east-1/source-directory-tarballs/lightgbm/transfer_learning/classification/prepack/v1.1.1/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"transfer_learning\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 48,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.m5.12xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.m5.12xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"transfer_learning.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"bagging_fraction\":\"0.53\",\"bagging_freq\":\"5\",\"boosting\":\"gbdt\",\"early_stopping_rounds\":\"30\",\"feature_fraction\":\"0.74\",\"feature_fraction_bynode\":\"1.0\",\"is_unbalance\":\"False\",\"lambda_l1\":\"0.0\",\"lambda_l2\":\"0.0\",\"learning_rate\":\"0.009\",\"max_bin\":\"255\",\"max_delta_step\":\"0.0\",\"max_depth\":\"11\",\"metric\":\"auto\",\"min_data_in_leaf\":\"26\",\"min_gain_to_split\":\"0.0\",\"num_boost_round\":\"500\",\"num_leaves\":\"67\",\"num_threads\":\"0\",\"scale_pos_weight\":\"1.0\",\"tree_learner\":\"serial\",\"use_dask\":\"False\",\"verbosity\":\"1\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=transfer_learning.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m5.12xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.12xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"model\":{\"ContentType\":\"application/x-sagemaker-model\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"ContentType\":\"application/x-parquet\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"validation\":{\"ContentType\":\"application/x-parquet\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"model\",\"train\",\"validation\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=transfer_learning\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=48\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://jumpstart-cache-prod-us-east-1/source-directory-tarballs/lightgbm/transfer_learning/classification/prepack/v1.1.1/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"model\":\"/opt/ml/input/data/model\",\"train\":\"/opt/ml/input/data/train\",\"validation\":\"/opt/ml/input/data/validation\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"bagging_fraction\":\"0.53\",\"bagging_freq\":\"5\",\"boosting\":\"gbdt\",\"early_stopping_rounds\":\"30\",\"feature_fraction\":\"0.74\",\"feature_fraction_bynode\":\"1.0\",\"is_unbalance\":\"False\",\"lambda_l1\":\"0.0\",\"lambda_l2\":\"0.0\",\"learning_rate\":\"0.009\",\"max_bin\":\"255\",\"max_delta_step\":\"0.0\",\"max_depth\":\"11\",\"metric\":\"auto\",\"min_data_in_leaf\":\"26\",\"min_gain_to_split\":\"0.0\",\"num_boost_round\":\"500\",\"num_leaves\":\"67\",\"num_threads\":\"0\",\"scale_pos_weight\":\"1.0\",\"tree_learner\":\"serial\",\"use_dask\":\"False\",\"verbosity\":\"1\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"model\":{\"ContentType\":\"application/x-sagemaker-model\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"ContentType\":\"application/x-parquet\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"validation\":{\"ContentType\":\"application/x-parquet\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"built-in-algo-lightgbm-classification-m-2024-03-12-14-56-09-133\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://jumpstart-cache-prod-us-east-1/source-directory-tarballs/lightgbm/transfer_learning/classification/prepack/v1.1.1/sourcedir.tar.gz\",\"module_name\":\"transfer_learning\",\"network_interface_name\":\"eth0\",\"num_cpus\":48,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m5.12xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.12xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"transfer_learning.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--bagging_fraction\",\"0.53\",\"--bagging_freq\",\"5\",\"--boosting\",\"gbdt\",\"--early_stopping_rounds\",\"30\",\"--feature_fraction\",\"0.74\",\"--feature_fraction_bynode\",\"1.0\",\"--is_unbalance\",\"False\",\"--lambda_l1\",\"0.0\",\"--lambda_l2\",\"0.0\",\"--learning_rate\",\"0.009\",\"--max_bin\",\"255\",\"--max_delta_step\",\"0.0\",\"--max_depth\",\"11\",\"--metric\",\"auto\",\"--min_data_in_leaf\",\"26\",\"--min_gain_to_split\",\"0.0\",\"--num_boost_round\",\"500\",\"--num_leaves\",\"67\",\"--num_threads\",\"0\",\"--scale_pos_weight\",\"1.0\",\"--tree_learner\",\"serial\",\"--use_dask\",\"False\",\"--verbosity\",\"1\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_MODEL=/opt/ml/input/data/model\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_VALIDATION=/opt/ml/input/data/validation\u001b[0m\n",
      "\u001b[34mSM_HP_BAGGING_FRACTION=0.53\u001b[0m\n",
      "\u001b[34mSM_HP_BAGGING_FREQ=5\u001b[0m\n",
      "\u001b[34mSM_HP_BOOSTING=gbdt\u001b[0m\n",
      "\u001b[34mSM_HP_EARLY_STOPPING_ROUNDS=30\u001b[0m\n",
      "\u001b[34mSM_HP_FEATURE_FRACTION=0.74\u001b[0m\n",
      "\u001b[34mSM_HP_FEATURE_FRACTION_BYNODE=1.0\u001b[0m\n",
      "\u001b[34mSM_HP_IS_UNBALANCE=False\u001b[0m\n",
      "\u001b[34mSM_HP_LAMBDA_L1=0.0\u001b[0m\n",
      "\u001b[34mSM_HP_LAMBDA_L2=0.0\u001b[0m\n",
      "\u001b[34mSM_HP_LEARNING_RATE=0.009\u001b[0m\n",
      "\u001b[34mSM_HP_MAX_BIN=255\u001b[0m\n",
      "\u001b[34mSM_HP_MAX_DELTA_STEP=0.0\u001b[0m\n",
      "\u001b[34mSM_HP_MAX_DEPTH=11\u001b[0m\n",
      "\u001b[34mSM_HP_METRIC=auto\u001b[0m\n",
      "\u001b[34mSM_HP_MIN_DATA_IN_LEAF=26\u001b[0m\n",
      "\u001b[34mSM_HP_MIN_GAIN_TO_SPLIT=0.0\u001b[0m\n",
      "\u001b[34mSM_HP_NUM_BOOST_ROUND=500\u001b[0m\n",
      "\u001b[34mSM_HP_NUM_LEAVES=67\u001b[0m\n",
      "\u001b[34mSM_HP_NUM_THREADS=0\u001b[0m\n",
      "\u001b[34mSM_HP_SCALE_POS_WEIGHT=1.0\u001b[0m\n",
      "\u001b[34mSM_HP_TREE_LEARNER=serial\u001b[0m\n",
      "\u001b[34mSM_HP_USE_DASK=False\u001b[0m\n",
      "\u001b[34mSM_HP_VERBOSITY=1\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python38.zip:/opt/conda/lib/python3.8:/opt/conda/lib/python3.8/lib-dynload:/opt/conda/lib/python3.8/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.8 transfer_learning.py --bagging_fraction 0.53 --bagging_freq 5 --boosting gbdt --early_stopping_rounds 30 --feature_fraction 0.74 --feature_fraction_bynode 1.0 --is_unbalance False --lambda_l1 0.0 --lambda_l2 0.0 --learning_rate 0.009 --max_bin 255 --max_delta_step 0.0 --max_depth 11 --metric auto --min_data_in_leaf 26 --min_gain_to_split 0.0 --num_boost_round 500 --num_leaves 67 --num_threads 0 --scale_pos_weight 1.0 --tree_learner serial --use_dask False --verbosity 1\u001b[0m\n",
      "\u001b[34mINFO:root:Loading data\u001b[0m\n",
      "\u001b[34mINFO:root:Found data in the validation channel. Reading the train and validation data from the training and validation channel, respectively.\u001b[0m\n",
      "\u001b[34mINFO:root:'_input_model_extracted/__models_info__.json' file could not be found.\u001b[0m\n",
      "\u001b[34mINFO:root:Beginning training\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\u001b[0m\n",
      "\u001b[34m[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\u001b[0m\n",
      "\u001b[34m[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\u001b[0m\n",
      "\u001b[34m[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.035365 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_row_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34mAnd if memory is not enough, you can set `force_col_wise=true`.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1530\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 10420811, number of used features: 7\u001b[0m\n",
      "\u001b[34m[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.010257\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -4.584937\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -34.538776\u001b[0m\n",
      "\u001b[34m[1]#011train's multi_logloss: 0.0564317#011val's multi_logloss: 0.0564053\u001b[0m\n",
      "\u001b[34mTraining until validation scores don't improve for 30 rounds\u001b[0m\n",
      "\u001b[34m[2]#011train's multi_logloss: 0.0559501#011val's multi_logloss: 0.0559252\u001b[0m\n",
      "\u001b[34m[3]#011train's multi_logloss: 0.055194#011val's multi_logloss: 0.0551737\u001b[0m\n",
      "\u001b[34m[4]#011train's multi_logloss: 0.0546716#011val's multi_logloss: 0.0546549\u001b[0m\n",
      "\u001b[34m[5]#011train's multi_logloss: 0.0539122#011val's multi_logloss: 0.0539025\u001b[0m\n",
      "\u001b[34m[6]#011train's multi_logloss: 0.0532424#011val's multi_logloss: 0.0532397\u001b[0m\n",
      "\u001b[34m[7]#011train's multi_logloss: 0.0526395#011val's multi_logloss: 0.0526425\u001b[0m\n",
      "\u001b[34m[8]#011train's multi_logloss: 0.0522343#011val's multi_logloss: 0.0522407\u001b[0m\n",
      "\u001b[34m[9]#011train's multi_logloss: 0.0517995#011val's multi_logloss: 0.0518095\u001b[0m\n",
      "\u001b[34m[10]#011train's multi_logloss: 0.051274#011val's multi_logloss: 0.0512892\u001b[0m\n",
      "\u001b[34m[11]#011train's multi_logloss: 0.0508349#011val's multi_logloss: 0.050855\u001b[0m\n",
      "\u001b[34m[12]#011train's multi_logloss: 0.050386#011val's multi_logloss: 0.0504106\u001b[0m\n",
      "\u001b[34m[13]#011train's multi_logloss: 0.0499745#011val's multi_logloss: 0.0500032\u001b[0m\n",
      "\u001b[34m[14]#011train's multi_logloss: 0.0496802#011val's multi_logloss: 0.0497106\u001b[0m\n",
      "\u001b[34m[15]#011train's multi_logloss: 0.0493289#011val's multi_logloss: 0.0493612\u001b[0m\n",
      "\u001b[34m[16]#011train's multi_logloss: 0.049073#011val's multi_logloss: 0.0491071\u001b[0m\n",
      "\u001b[34m[17]#011train's multi_logloss: 0.0488007#011val's multi_logloss: 0.0488367\u001b[0m\n",
      "\u001b[34m[18]#011train's multi_logloss: 0.0485476#011val's multi_logloss: 0.0485858\u001b[0m\n",
      "\u001b[34m[19]#011train's multi_logloss: 0.0483173#011val's multi_logloss: 0.0483569\u001b[0m\n",
      "\u001b[34m[20]#011train's multi_logloss: 0.0481023#011val's multi_logloss: 0.0481436\u001b[0m\n",
      "\u001b[34m[21]#011train's multi_logloss: 0.0478846#011val's multi_logloss: 0.0479274\u001b[0m\n",
      "\u001b[34m[22]#011train's multi_logloss: 0.0476849#011val's multi_logloss: 0.0477295\u001b[0m\n",
      "\u001b[34m[23]#011train's multi_logloss: 0.0474839#011val's multi_logloss: 0.0475297\u001b[0m\n",
      "\u001b[34m[24]#011train's multi_logloss: 0.0472323#011val's multi_logloss: 0.047281\u001b[0m\n",
      "\u001b[34m[25]#011train's multi_logloss: 0.0470533#011val's multi_logloss: 0.0471038\u001b[0m\n",
      "\u001b[34m[26]#011train's multi_logloss: 0.0468345#011val's multi_logloss: 0.0468866\u001b[0m\n",
      "\u001b[34m[27]#011train's multi_logloss: 0.0466293#011val's multi_logloss: 0.0466833\u001b[0m\n",
      "\u001b[34m[28]#011train's multi_logloss: 0.0464952#011val's multi_logloss: 0.0465499\u001b[0m\n",
      "\u001b[34m[29]#011train's multi_logloss: 0.0463129#011val's multi_logloss: 0.046369\u001b[0m\n",
      "\u001b[34m[30]#011train's multi_logloss: 0.0461242#011val's multi_logloss: 0.0461819\u001b[0m\n",
      "\u001b[34m[31]#011train's multi_logloss: 0.0459641#011val's multi_logloss: 0.0460231\u001b[0m\n",
      "\u001b[34m[32]#011train's multi_logloss: 0.0457875#011val's multi_logloss: 0.0458479\u001b[0m\n",
      "\u001b[34m[33]#011train's multi_logloss: 0.0456181#011val's multi_logloss: 0.0456795\u001b[0m\n",
      "\u001b[34m[34]#011train's multi_logloss: 0.0454549#011val's multi_logloss: 0.0455174\u001b[0m\n",
      "\u001b[34m[35]#011train's multi_logloss: 0.0453248#011val's multi_logloss: 0.0453883\u001b[0m\n",
      "\u001b[34m[36]#011train's multi_logloss: 0.0451662#011val's multi_logloss: 0.0452318\u001b[0m\n",
      "\u001b[34m[37]#011train's multi_logloss: 0.0450165#011val's multi_logloss: 0.0450831\u001b[0m\n",
      "\u001b[34m[38]#011train's multi_logloss: 0.0449102#011val's multi_logloss: 0.0449775\u001b[0m\n",
      "\u001b[34m[39]#011train's multi_logloss: 0.0447699#011val's multi_logloss: 0.0448383\u001b[0m\n",
      "\u001b[34m[40]#011train's multi_logloss: 0.044627#011val's multi_logloss: 0.0446971\u001b[0m\n",
      "\u001b[34m[41]#011train's multi_logloss: 0.0444978#011val's multi_logloss: 0.0445693\u001b[0m\n",
      "\u001b[34m[42]#011train's multi_logloss: 0.0443778#011val's multi_logloss: 0.0444503\u001b[0m\n",
      "\u001b[34m[43]#011train's multi_logloss: 0.0442891#011val's multi_logloss: 0.0443624\u001b[0m\n",
      "\u001b[34m[44]#011train's multi_logloss: 0.0441709#011val's multi_logloss: 0.0442454\u001b[0m\n",
      "\u001b[34m[45]#011train's multi_logloss: 0.0440554#011val's multi_logloss: 0.0441311\u001b[0m\n",
      "\u001b[34m[46]#011train's multi_logloss: 0.043943#011val's multi_logloss: 0.0440199\u001b[0m\n",
      "\u001b[34m[47]#011train's multi_logloss: 0.0438664#011val's multi_logloss: 0.0439441\u001b[0m\n",
      "\u001b[34m[48]#011train's multi_logloss: 0.0437585#011val's multi_logloss: 0.043837\u001b[0m\n",
      "\u001b[34m[49]#011train's multi_logloss: 0.0436519#011val's multi_logloss: 0.0437312\u001b[0m\n",
      "\u001b[34m[50]#011train's multi_logloss: 0.0435662#011val's multi_logloss: 0.0436461\u001b[0m\n",
      "\u001b[34m[51]#011train's multi_logloss: 0.0434602#011val's multi_logloss: 0.0435415\u001b[0m\n",
      "\u001b[34m[52]#011train's multi_logloss: 0.0433755#011val's multi_logloss: 0.0434579\u001b[0m\n",
      "\u001b[34m[53]#011train's multi_logloss: 0.0432785#011val's multi_logloss: 0.043362\u001b[0m\n",
      "\u001b[34m[54]#011train's multi_logloss: 0.0432031#011val's multi_logloss: 0.043287\u001b[0m\n",
      "\u001b[34m[55]#011train's multi_logloss: 0.0431234#011val's multi_logloss: 0.0432081\u001b[0m\n",
      "\u001b[34m[56]#011train's multi_logloss: 0.0430682#011val's multi_logloss: 0.0431533\u001b[0m\n",
      "\u001b[34m[57]#011train's multi_logloss: 0.0429797#011val's multi_logloss: 0.0430655\u001b[0m\n",
      "\u001b[34m[58]#011train's multi_logloss: 0.0429177#011val's multi_logloss: 0.0430042\u001b[0m\n",
      "\u001b[34m[59]#011train's multi_logloss: 0.0428425#011val's multi_logloss: 0.0429297\u001b[0m\n",
      "\u001b[34m[60]#011train's multi_logloss: 0.0427654#011val's multi_logloss: 0.0428532\u001b[0m\n",
      "\u001b[34m[61]#011train's multi_logloss: 0.0427018#011val's multi_logloss: 0.0427903\u001b[0m\n",
      "\u001b[34m[62]#011train's multi_logloss: 0.0426383#011val's multi_logloss: 0.0427273\u001b[0m\n",
      "\u001b[34m[63]#011train's multi_logloss: 0.0425638#011val's multi_logloss: 0.0426535\u001b[0m\n",
      "\u001b[34m[64]#011train's multi_logloss: 0.0424875#011val's multi_logloss: 0.0425781\u001b[0m\n",
      "\u001b[34m[65]#011train's multi_logloss: 0.0424164#011val's multi_logloss: 0.0425083\u001b[0m\n",
      "\u001b[34m[66]#011train's multi_logloss: 0.0423461#011val's multi_logloss: 0.0424383\u001b[0m\n",
      "\u001b[34m[67]#011train's multi_logloss: 0.0422873#011val's multi_logloss: 0.0423803\u001b[0m\n",
      "\u001b[34m[68]#011train's multi_logloss: 0.0422302#011val's multi_logloss: 0.0423241\u001b[0m\n",
      "\u001b[34m[69]#011train's multi_logloss: 0.042173#011val's multi_logloss: 0.0422675\u001b[0m\n",
      "\u001b[34m[70]#011train's multi_logloss: 0.0421098#011val's multi_logloss: 0.0422045\u001b[0m\n",
      "\u001b[34m[71]#011train's multi_logloss: 0.0420658#011val's multi_logloss: 0.0421614\u001b[0m\n",
      "\u001b[34m[72]#011train's multi_logloss: 0.0420232#011val's multi_logloss: 0.0421197\u001b[0m\n",
      "\u001b[34m[73]#011train's multi_logloss: 0.0419623#011val's multi_logloss: 0.0420592\u001b[0m\n",
      "\u001b[34m[74]#011train's multi_logloss: 0.0419046#011val's multi_logloss: 0.0420027\u001b[0m\n",
      "\u001b[34m[75]#011train's multi_logloss: 0.0418437#011val's multi_logloss: 0.0419424\u001b[0m\n",
      "\u001b[34m[76]#011train's multi_logloss: 0.0417965#011val's multi_logloss: 0.0418954\u001b[0m\n",
      "\u001b[34m[77]#011train's multi_logloss: 0.041758#011val's multi_logloss: 0.0418575\u001b[0m\n",
      "\u001b[34m[78]#011train's multi_logloss: 0.0417134#011val's multi_logloss: 0.0418136\u001b[0m\n",
      "\u001b[34m[79]#011train's multi_logloss: 0.0416687#011val's multi_logloss: 0.0417696\u001b[0m\n",
      "\u001b[34m[80]#011train's multi_logloss: 0.0416359#011val's multi_logloss: 0.0417372\u001b[0m\n",
      "\u001b[34m[81]#011train's multi_logloss: 0.0415957#011val's multi_logloss: 0.041697\u001b[0m\n",
      "\u001b[34m[82]#011train's multi_logloss: 0.0415425#011val's multi_logloss: 0.0416452\u001b[0m\n",
      "\u001b[34m[83]#011train's multi_logloss: 0.0415007#011val's multi_logloss: 0.0416043\u001b[0m\n",
      "\u001b[34m[84]#011train's multi_logloss: 0.0414507#011val's multi_logloss: 0.0415555\u001b[0m\n",
      "\u001b[34m[85]#011train's multi_logloss: 0.0414043#011val's multi_logloss: 0.0415096\u001b[0m\n",
      "\u001b[34m[86]#011train's multi_logloss: 0.0413555#011val's multi_logloss: 0.0414614\u001b[0m\n",
      "\u001b[34m[87]#011train's multi_logloss: 0.0413068#011val's multi_logloss: 0.0414138\u001b[0m\n",
      "\u001b[34m[88]#011train's multi_logloss: 0.0412614#011val's multi_logloss: 0.0413694\u001b[0m\n",
      "\u001b[34m[89]#011train's multi_logloss: 0.0412276#011val's multi_logloss: 0.0413362\u001b[0m\n",
      "\u001b[34m[90]#011train's multi_logloss: 0.0411837#011val's multi_logloss: 0.0412934\u001b[0m\n",
      "\u001b[34m[91]#011train's multi_logloss: 0.0411452#011val's multi_logloss: 0.0412555\u001b[0m\n",
      "\u001b[34m[92]#011train's multi_logloss: 0.0411098#011val's multi_logloss: 0.0412212\u001b[0m\n",
      "\u001b[34m[93]#011train's multi_logloss: 0.0410776#011val's multi_logloss: 0.0411897\u001b[0m\n",
      "\u001b[34m[94]#011train's multi_logloss: 0.0410451#011val's multi_logloss: 0.041158\u001b[0m\n",
      "\u001b[34m[95]#011train's multi_logloss: 0.0410059#011val's multi_logloss: 0.0411198\u001b[0m\n",
      "\u001b[34m[96]#011train's multi_logloss: 0.0409827#011val's multi_logloss: 0.0410969\u001b[0m\n",
      "\u001b[34m[97]#011train's multi_logloss: 0.0409501#011val's multi_logloss: 0.0410647\u001b[0m\n",
      "\u001b[34m[98]#011train's multi_logloss: 0.0409136#011val's multi_logloss: 0.0410291\u001b[0m\n",
      "\u001b[34m[99]#011train's multi_logloss: 0.040886#011val's multi_logloss: 0.0410019\u001b[0m\n",
      "\u001b[34m[100]#011train's multi_logloss: 0.0408509#011val's multi_logloss: 0.0409674\u001b[0m\n",
      "\u001b[34m[101]#011train's multi_logloss: 0.0408274#011val's multi_logloss: 0.0409439\u001b[0m\n",
      "\u001b[34m[102]#011train's multi_logloss: 0.0407942#011val's multi_logloss: 0.0409111\u001b[0m\n",
      "\u001b[34m[103]#011train's multi_logloss: 0.0407648#011val's multi_logloss: 0.0408822\u001b[0m\n",
      "\u001b[34m[104]#011train's multi_logloss: 0.0407381#011val's multi_logloss: 0.0408558\u001b[0m\n",
      "\u001b[34m[105]#011train's multi_logloss: 0.0407117#011val's multi_logloss: 0.0408296\u001b[0m\n",
      "\u001b[34m[106]#011train's multi_logloss: 0.0406858#011val's multi_logloss: 0.0408041\u001b[0m\n",
      "\u001b[34m[107]#011train's multi_logloss: 0.040654#011val's multi_logloss: 0.040773\u001b[0m\n",
      "\u001b[34m[108]#011train's multi_logloss: 0.0406228#011val's multi_logloss: 0.0407428\u001b[0m\n",
      "\u001b[34m[109]#011train's multi_logloss: 0.0405938#011val's multi_logloss: 0.0407145\u001b[0m\n",
      "\u001b[34m[110]#011train's multi_logloss: 0.0405701#011val's multi_logloss: 0.0406917\u001b[0m\n",
      "\u001b[34m[111]#011train's multi_logloss: 0.0405421#011val's multi_logloss: 0.0406642\u001b[0m\n",
      "\u001b[34m[112]#011train's multi_logloss: 0.0405143#011val's multi_logloss: 0.0406371\u001b[0m\n",
      "\u001b[34m[113]#011train's multi_logloss: 0.0404871#011val's multi_logloss: 0.0406104\u001b[0m\n",
      "\u001b[34m[114]#011train's multi_logloss: 0.0404658#011val's multi_logloss: 0.0405894\u001b[0m\n",
      "\u001b[34m[115]#011train's multi_logloss: 0.0404435#011val's multi_logloss: 0.0405672\u001b[0m\n",
      "\u001b[34m[116]#011train's multi_logloss: 0.0404163#011val's multi_logloss: 0.040541\u001b[0m\n",
      "\u001b[34m[117]#011train's multi_logloss: 0.0403911#011val's multi_logloss: 0.0405166\u001b[0m\n",
      "\u001b[34m[118]#011train's multi_logloss: 0.0403641#011val's multi_logloss: 0.0404904\u001b[0m\n",
      "\u001b[34m[119]#011train's multi_logloss: 0.0403385#011val's multi_logloss: 0.0404659\u001b[0m\n",
      "\u001b[34m[120]#011train's multi_logloss: 0.0403221#011val's multi_logloss: 0.0404499\u001b[0m\n",
      "\u001b[34m[121]#011train's multi_logloss: 0.040302#011val's multi_logloss: 0.0404307\u001b[0m\n",
      "\u001b[34m[122]#011train's multi_logloss: 0.0402783#011val's multi_logloss: 0.0404084\u001b[0m\n",
      "\u001b[34m[123]#011train's multi_logloss: 0.0402542#011val's multi_logloss: 0.0403857\u001b[0m\n",
      "\u001b[34m[124]#011train's multi_logloss: 0.0402355#011val's multi_logloss: 0.0403679\u001b[0m\n",
      "\u001b[34m[125]#011train's multi_logloss: 0.0402144#011val's multi_logloss: 0.0403483\u001b[0m\n",
      "\u001b[34m[126]#011train's multi_logloss: 0.0401959#011val's multi_logloss: 0.04033\u001b[0m\n",
      "\u001b[34m[127]#011train's multi_logloss: 0.0401766#011val's multi_logloss: 0.0403111\u001b[0m\n",
      "\u001b[34m[128]#011train's multi_logloss: 0.0401591#011val's multi_logloss: 0.040294\u001b[0m\n",
      "\u001b[34m[129]#011train's multi_logloss: 0.0401442#011val's multi_logloss: 0.0402797\u001b[0m\n",
      "\u001b[34m[130]#011train's multi_logloss: 0.0401258#011val's multi_logloss: 0.0402618\u001b[0m\n",
      "\u001b[34m[131]#011train's multi_logloss: 0.0401093#011val's multi_logloss: 0.0402459\u001b[0m\n",
      "\u001b[34m[132]#011train's multi_logloss: 0.0400896#011val's multi_logloss: 0.0402272\u001b[0m\n",
      "\u001b[34m[133]#011train's multi_logloss: 0.0400702#011val's multi_logloss: 0.0402085\u001b[0m\n",
      "\u001b[34m[134]#011train's multi_logloss: 0.0400515#011val's multi_logloss: 0.0401904\u001b[0m\n",
      "\u001b[34m[135]#011train's multi_logloss: 0.0400327#011val's multi_logloss: 0.0401725\u001b[0m\n",
      "\u001b[34m[136]#011train's multi_logloss: 0.0400171#011val's multi_logloss: 0.0401573\u001b[0m\n",
      "\u001b[34m[137]#011train's multi_logloss: 0.0400012#011val's multi_logloss: 0.0401417\u001b[0m\n",
      "\u001b[34m[138]#011train's multi_logloss: 0.0399832#011val's multi_logloss: 0.0401243\u001b[0m\n",
      "\u001b[34m[139]#011train's multi_logloss: 0.0399652#011val's multi_logloss: 0.0401069\u001b[0m\n",
      "\u001b[34m[140]#011train's multi_logloss: 0.0399493#011val's multi_logloss: 0.0400912\u001b[0m\n",
      "\u001b[34m[141]#011train's multi_logloss: 0.0399376#011val's multi_logloss: 0.0400805\u001b[0m\n",
      "\u001b[34m[142]#011train's multi_logloss: 0.0399283#011val's multi_logloss: 0.0400714\u001b[0m\n",
      "\u001b[34m[143]#011train's multi_logloss: 0.0399171#011val's multi_logloss: 0.0400607\u001b[0m\n",
      "\u001b[34m[144]#011train's multi_logloss: 0.0399007#011val's multi_logloss: 0.0400449\u001b[0m\n",
      "\u001b[34m[145]#011train's multi_logloss: 0.0398883#011val's multi_logloss: 0.040033\u001b[0m\n",
      "\u001b[34m[146]#011train's multi_logloss: 0.0398774#011val's multi_logloss: 0.0400225\u001b[0m\n",
      "\u001b[34m[147]#011train's multi_logloss: 0.03986#011val's multi_logloss: 0.0400054\u001b[0m\n",
      "\u001b[34m[148]#011train's multi_logloss: 0.0398485#011val's multi_logloss: 0.0399943\u001b[0m\n",
      "\u001b[34m[149]#011train's multi_logloss: 0.0398325#011val's multi_logloss: 0.0399787\u001b[0m\n",
      "\u001b[34m[150]#011train's multi_logloss: 0.0398173#011val's multi_logloss: 0.039964\u001b[0m\n",
      "\u001b[34m[151]#011train's multi_logloss: 0.0398007#011val's multi_logloss: 0.0399481\u001b[0m\n",
      "\u001b[34m[152]#011train's multi_logloss: 0.0397893#011val's multi_logloss: 0.0399371\u001b[0m\n",
      "\u001b[34m[153]#011train's multi_logloss: 0.0397758#011val's multi_logloss: 0.0399241\u001b[0m\n",
      "\u001b[34m[154]#011train's multi_logloss: 0.0397605#011val's multi_logloss: 0.0399097\u001b[0m\n",
      "\u001b[34m[155]#011train's multi_logloss: 0.0397465#011val's multi_logloss: 0.0398963\u001b[0m\n",
      "\u001b[34m[156]#011train's multi_logloss: 0.0397348#011val's multi_logloss: 0.0398849\u001b[0m\n",
      "\u001b[34m[157]#011train's multi_logloss: 0.0397222#011val's multi_logloss: 0.039873\u001b[0m\n",
      "\u001b[34m[158]#011train's multi_logloss: 0.0397114#011val's multi_logloss: 0.0398624\u001b[0m\n",
      "\u001b[34m[159]#011train's multi_logloss: 0.0396973#011val's multi_logloss: 0.0398487\u001b[0m\n",
      "\u001b[34m[160]#011train's multi_logloss: 0.0396831#011val's multi_logloss: 0.0398349\u001b[0m\n",
      "\u001b[34m[161]#011train's multi_logloss: 0.0396691#011val's multi_logloss: 0.0398215\u001b[0m\n",
      "\u001b[34m[162]#011train's multi_logloss: 0.0396548#011val's multi_logloss: 0.0398085\u001b[0m\n",
      "\u001b[34m[163]#011train's multi_logloss: 0.039644#011val's multi_logloss: 0.0397983\u001b[0m\n",
      "\u001b[34m[164]#011train's multi_logloss: 0.039631#011val's multi_logloss: 0.0397863\u001b[0m\n",
      "\u001b[34m[165]#011train's multi_logloss: 0.0396193#011val's multi_logloss: 0.0397755\u001b[0m\n",
      "\u001b[34m[166]#011train's multi_logloss: 0.0396089#011val's multi_logloss: 0.0397657\u001b[0m\n",
      "\u001b[34m[167]#011train's multi_logloss: 0.0395991#011val's multi_logloss: 0.0397563\u001b[0m\n",
      "\u001b[34m[168]#011train's multi_logloss: 0.0395897#011val's multi_logloss: 0.0397474\u001b[0m\n",
      "\u001b[34m[169]#011train's multi_logloss: 0.0395781#011val's multi_logloss: 0.0397365\u001b[0m\n",
      "\u001b[34m[170]#011train's multi_logloss: 0.0395667#011val's multi_logloss: 0.0397254\u001b[0m\n",
      "\u001b[34m[171]#011train's multi_logloss: 0.0395559#011val's multi_logloss: 0.0397153\u001b[0m\n",
      "\u001b[34m[172]#011train's multi_logloss: 0.0395433#011val's multi_logloss: 0.0397037\u001b[0m\n",
      "\u001b[34m[173]#011train's multi_logloss: 0.0395361#011val's multi_logloss: 0.0396971\u001b[0m\n",
      "\u001b[34m[174]#011train's multi_logloss: 0.0395234#011val's multi_logloss: 0.0396855\u001b[0m\n",
      "\u001b[34m[175]#011train's multi_logloss: 0.0395122#011val's multi_logloss: 0.0396754\u001b[0m\n",
      "\u001b[34m[176]#011train's multi_logloss: 0.0395018#011val's multi_logloss: 0.0396659\u001b[0m\n",
      "\u001b[34m[177]#011train's multi_logloss: 0.0394921#011val's multi_logloss: 0.0396573\u001b[0m\n",
      "\u001b[34m[178]#011train's multi_logloss: 0.0394804#011val's multi_logloss: 0.0396466\u001b[0m\n",
      "\u001b[34m[179]#011train's multi_logloss: 0.0394719#011val's multi_logloss: 0.0396388\u001b[0m\n",
      "\u001b[34m[180]#011train's multi_logloss: 0.0394596#011val's multi_logloss: 0.0396278\u001b[0m\n",
      "\u001b[34m[181]#011train's multi_logloss: 0.0394493#011val's multi_logloss: 0.0396183\u001b[0m\n",
      "\u001b[34m[182]#011train's multi_logloss: 0.0394395#011val's multi_logloss: 0.0396091\u001b[0m\n",
      "\u001b[34m[183]#011train's multi_logloss: 0.0394326#011val's multi_logloss: 0.0396032\u001b[0m\n",
      "\u001b[34m[184]#011train's multi_logloss: 0.0394226#011val's multi_logloss: 0.039594\u001b[0m\n",
      "\u001b[34m[185]#011train's multi_logloss: 0.0394147#011val's multi_logloss: 0.0395865\u001b[0m\n",
      "\u001b[34m[186]#011train's multi_logloss: 0.0394041#011val's multi_logloss: 0.0395774\u001b[0m\n",
      "\u001b[34m[187]#011train's multi_logloss: 0.0393959#011val's multi_logloss: 0.03957\u001b[0m\n",
      "\u001b[34m[188]#011train's multi_logloss: 0.0393878#011val's multi_logloss: 0.0395629\u001b[0m\n",
      "\u001b[34m[189]#011train's multi_logloss: 0.0393811#011val's multi_logloss: 0.0395568\u001b[0m\n",
      "\u001b[34m[190]#011train's multi_logloss: 0.0393757#011val's multi_logloss: 0.0395517\u001b[0m\n",
      "\u001b[34m[191]#011train's multi_logloss: 0.0393675#011val's multi_logloss: 0.0395444\u001b[0m\n",
      "\u001b[34m[192]#011train's multi_logloss: 0.039358#011val's multi_logloss: 0.0395357\u001b[0m\n",
      "\u001b[34m[193]#011train's multi_logloss: 0.0393485#011val's multi_logloss: 0.0395267\u001b[0m\n",
      "\u001b[34m[194]#011train's multi_logloss: 0.0393407#011val's multi_logloss: 0.03952\u001b[0m\n",
      "\u001b[34m[195]#011train's multi_logloss: 0.0393341#011val's multi_logloss: 0.0395141\u001b[0m\n",
      "\u001b[34m[196]#011train's multi_logloss: 0.039326#011val's multi_logloss: 0.0395067\u001b[0m\n",
      "\u001b[34m[197]#011train's multi_logloss: 0.0393184#011val's multi_logloss: 0.0394999\u001b[0m\n",
      "\u001b[34m[198]#011train's multi_logloss: 0.0393112#011val's multi_logloss: 0.0394933\u001b[0m\n",
      "\u001b[34m[199]#011train's multi_logloss: 0.039302#011val's multi_logloss: 0.0394848\u001b[0m\n",
      "\u001b[34m[200]#011train's multi_logloss: 0.0392949#011val's multi_logloss: 0.0394784\u001b[0m\n",
      "\u001b[34m[201]#011train's multi_logloss: 0.0392863#011val's multi_logloss: 0.0394707\u001b[0m\n",
      "\u001b[34m[202]#011train's multi_logloss: 0.0392794#011val's multi_logloss: 0.0394645\u001b[0m\n",
      "\u001b[34m[203]#011train's multi_logloss: 0.039272#011val's multi_logloss: 0.0394578\u001b[0m\n",
      "\u001b[34m[204]#011train's multi_logloss: 0.0392641#011val's multi_logloss: 0.0394509\u001b[0m\n",
      "\u001b[34m[205]#011train's multi_logloss: 0.0392572#011val's multi_logloss: 0.0394448\u001b[0m\n",
      "\u001b[34m[206]#011train's multi_logloss: 0.0392485#011val's multi_logloss: 0.0394366\u001b[0m\n",
      "\u001b[34m[207]#011train's multi_logloss: 0.0392421#011val's multi_logloss: 0.039431\u001b[0m\n",
      "\u001b[34m[208]#011train's multi_logloss: 0.039236#011val's multi_logloss: 0.0394256\u001b[0m\n",
      "\u001b[34m[209]#011train's multi_logloss: 0.0392291#011val's multi_logloss: 0.0394191\u001b[0m\n",
      "\u001b[34m[210]#011train's multi_logloss: 0.0392214#011val's multi_logloss: 0.0394118\u001b[0m\n",
      "\u001b[34m[211]#011train's multi_logloss: 0.0392134#011val's multi_logloss: 0.0394053\u001b[0m\n",
      "\u001b[34m[212]#011train's multi_logloss: 0.0392059#011val's multi_logloss: 0.0393987\u001b[0m\n",
      "\u001b[34m[213]#011train's multi_logloss: 0.0392005#011val's multi_logloss: 0.0393936\u001b[0m\n",
      "\u001b[34m[214]#011train's multi_logloss: 0.0391939#011val's multi_logloss: 0.0393876\u001b[0m\n",
      "\u001b[34m[215]#011train's multi_logloss: 0.0391875#011val's multi_logloss: 0.0393819\u001b[0m\n",
      "\u001b[34m[216]#011train's multi_logloss: 0.0391814#011val's multi_logloss: 0.0393767\u001b[0m\n",
      "\u001b[34m[217]#011train's multi_logloss: 0.0391766#011val's multi_logloss: 0.0393726\u001b[0m\n",
      "\u001b[34m[218]#011train's multi_logloss: 0.0391702#011val's multi_logloss: 0.039367\u001b[0m\n",
      "\u001b[34m[219]#011train's multi_logloss: 0.0391651#011val's multi_logloss: 0.0393626\u001b[0m\n",
      "\u001b[34m[220]#011train's multi_logloss: 0.0391598#011val's multi_logloss: 0.0393579\u001b[0m\n",
      "\u001b[34m[221]#011train's multi_logloss: 0.0391529#011val's multi_logloss: 0.039352\u001b[0m\n",
      "\u001b[34m[222]#011train's multi_logloss: 0.0391456#011val's multi_logloss: 0.0393457\u001b[0m\n",
      "\u001b[34m[223]#011train's multi_logloss: 0.0391385#011val's multi_logloss: 0.0393397\u001b[0m\n",
      "\u001b[34m[224]#011train's multi_logloss: 0.0391323#011val's multi_logloss: 0.0393342\u001b[0m\n",
      "\u001b[34m[225]#011train's multi_logloss: 0.0391276#011val's multi_logloss: 0.0393305\u001b[0m\n",
      "\u001b[34m[226]#011train's multi_logloss: 0.0391194#011val's multi_logloss: 0.0393238\u001b[0m\n",
      "\u001b[34m[227]#011train's multi_logloss: 0.0391129#011val's multi_logloss: 0.0393183\u001b[0m\n",
      "\u001b[34m[228]#011train's multi_logloss: 0.0391073#011val's multi_logloss: 0.0393138\u001b[0m\n",
      "\u001b[34m[229]#011train's multi_logloss: 0.0391019#011val's multi_logloss: 0.0393093\u001b[0m\n",
      "\u001b[34m[230]#011train's multi_logloss: 0.0390956#011val's multi_logloss: 0.0393039\u001b[0m\n",
      "\u001b[34m[231]#011train's multi_logloss: 0.0390893#011val's multi_logloss: 0.0392986\u001b[0m\n",
      "\u001b[34m[232]#011train's multi_logloss: 0.0390847#011val's multi_logloss: 0.0392946\u001b[0m\n",
      "\u001b[34m[233]#011train's multi_logloss: 0.0390788#011val's multi_logloss: 0.0392896\u001b[0m\n",
      "\u001b[34m[234]#011train's multi_logloss: 0.0390745#011val's multi_logloss: 0.0392862\u001b[0m\n",
      "\u001b[34m[235]#011train's multi_logloss: 0.0390693#011val's multi_logloss: 0.0392822\u001b[0m\n",
      "\u001b[34m[236]#011train's multi_logloss: 0.0390624#011val's multi_logloss: 0.0392766\u001b[0m\n",
      "\u001b[34m[237]#011train's multi_logloss: 0.0390563#011val's multi_logloss: 0.039272\u001b[0m\n",
      "\u001b[34m[238]#011train's multi_logloss: 0.0390509#011val's multi_logloss: 0.0392674\u001b[0m\n",
      "\u001b[34m[239]#011train's multi_logloss: 0.0390457#011val's multi_logloss: 0.039263\u001b[0m\n",
      "\u001b[34m[240]#011train's multi_logloss: 0.0390412#011val's multi_logloss: 0.0392591\u001b[0m\n",
      "\u001b[34m[241]#011train's multi_logloss: 0.0390353#011val's multi_logloss: 0.0392544\u001b[0m\n",
      "\u001b[34m[242]#011train's multi_logloss: 0.0390296#011val's multi_logloss: 0.0392496\u001b[0m\n",
      "\u001b[34m[243]#011train's multi_logloss: 0.0390252#011val's multi_logloss: 0.039246\u001b[0m\n",
      "\u001b[34m[244]#011train's multi_logloss: 0.0390214#011val's multi_logloss: 0.0392427\u001b[0m\n",
      "\u001b[34m[245]#011train's multi_logloss: 0.0390169#011val's multi_logloss: 0.0392387\u001b[0m\n",
      "\u001b[34m[246]#011train's multi_logloss: 0.0390107#011val's multi_logloss: 0.0392333\u001b[0m\n",
      "\u001b[34m[247]#011train's multi_logloss: 0.0390054#011val's multi_logloss: 0.0392289\u001b[0m\n",
      "\u001b[34m[248]#011train's multi_logloss: 0.0390022#011val's multi_logloss: 0.0392264\u001b[0m\n",
      "\u001b[34m[249]#011train's multi_logloss: 0.038996#011val's multi_logloss: 0.0392214\u001b[0m\n",
      "\u001b[34m[250]#011train's multi_logloss: 0.0389911#011val's multi_logloss: 0.0392171\u001b[0m\n",
      "\u001b[34m[251]#011train's multi_logloss: 0.0389858#011val's multi_logloss: 0.0392131\u001b[0m\n",
      "\u001b[34m[252]#011train's multi_logloss: 0.0389817#011val's multi_logloss: 0.0392099\u001b[0m\n",
      "\u001b[34m[253]#011train's multi_logloss: 0.0389775#011val's multi_logloss: 0.0392064\u001b[0m\n",
      "\u001b[34m[254]#011train's multi_logloss: 0.0389728#011val's multi_logloss: 0.0392026\u001b[0m\n",
      "\u001b[34m[255]#011train's multi_logloss: 0.0389688#011val's multi_logloss: 0.0391994\u001b[0m\n",
      "\u001b[34m[256]#011train's multi_logloss: 0.0389642#011val's multi_logloss: 0.0391958\u001b[0m\n",
      "\u001b[34m[257]#011train's multi_logloss: 0.0389602#011val's multi_logloss: 0.0391933\u001b[0m\n",
      "\u001b[34m[258]#011train's multi_logloss: 0.0389565#011val's multi_logloss: 0.0391906\u001b[0m\n",
      "\u001b[34m[259]#011train's multi_logloss: 0.0389519#011val's multi_logloss: 0.0391872\u001b[0m\n",
      "\u001b[34m[260]#011train's multi_logloss: 0.0389484#011val's multi_logloss: 0.0391845\u001b[0m\n",
      "\u001b[34m[261]#011train's multi_logloss: 0.0389447#011val's multi_logloss: 0.0391817\u001b[0m\n",
      "\u001b[34m[262]#011train's multi_logloss: 0.0389409#011val's multi_logloss: 0.0391787\u001b[0m\n",
      "\u001b[34m[263]#011train's multi_logloss: 0.0389365#011val's multi_logloss: 0.0391755\u001b[0m\n",
      "\u001b[34m[264]#011train's multi_logloss: 0.0389315#011val's multi_logloss: 0.0391719\u001b[0m\n",
      "\u001b[34m[265]#011train's multi_logloss: 0.0389274#011val's multi_logloss: 0.0391687\u001b[0m\n",
      "\u001b[34m[266]#011train's multi_logloss: 0.038923#011val's multi_logloss: 0.039165\u001b[0m\n",
      "\u001b[34m[267]#011train's multi_logloss: 0.0389193#011val's multi_logloss: 0.0391626\u001b[0m\n",
      "\u001b[34m[268]#011train's multi_logloss: 0.0389158#011val's multi_logloss: 0.0391599\u001b[0m\n",
      "\u001b[34m[269]#011train's multi_logloss: 0.0389105#011val's multi_logloss: 0.0391552\u001b[0m\n",
      "\u001b[34m[270]#011train's multi_logloss: 0.0389065#011val's multi_logloss: 0.0391521\u001b[0m\n",
      "\u001b[34m[271]#011train's multi_logloss: 0.038901#011val's multi_logloss: 0.0391484\u001b[0m\n",
      "\u001b[34m[272]#011train's multi_logloss: 0.0388967#011val's multi_logloss: 0.0391455\u001b[0m\n",
      "\u001b[34m[273]#011train's multi_logloss: 0.0388929#011val's multi_logloss: 0.0391423\u001b[0m\n",
      "\u001b[34m[274]#011train's multi_logloss: 0.0388896#011val's multi_logloss: 0.0391395\u001b[0m\n",
      "\u001b[34m[275]#011train's multi_logloss: 0.0388857#011val's multi_logloss: 0.039136\u001b[0m\n",
      "\u001b[34m[276]#011train's multi_logloss: 0.0388817#011val's multi_logloss: 0.0391329\u001b[0m\n",
      "\u001b[34m[277]#011train's multi_logloss: 0.0388787#011val's multi_logloss: 0.0391307\u001b[0m\n",
      "\u001b[34m[278]#011train's multi_logloss: 0.0388742#011val's multi_logloss: 0.0391271\u001b[0m\n",
      "\u001b[34m[279]#011train's multi_logloss: 0.0388701#011val's multi_logloss: 0.0391244\u001b[0m\n",
      "\u001b[34m[280]#011train's multi_logloss: 0.0388674#011val's multi_logloss: 0.0391224\u001b[0m\n",
      "\u001b[34m[281]#011train's multi_logloss: 0.0388645#011val's multi_logloss: 0.0391199\u001b[0m\n",
      "\u001b[34m[282]#011train's multi_logloss: 0.0388617#011val's multi_logloss: 0.0391177\u001b[0m\n",
      "\u001b[34m[283]#011train's multi_logloss: 0.038857#011val's multi_logloss: 0.0391142\u001b[0m\n",
      "\u001b[34m[284]#011train's multi_logloss: 0.0388539#011val's multi_logloss: 0.0391118\u001b[0m\n",
      "\u001b[34m[285]#011train's multi_logloss: 0.0388509#011val's multi_logloss: 0.0391096\u001b[0m\n",
      "\u001b[34m[286]#011train's multi_logloss: 0.0388473#011val's multi_logloss: 0.039107\u001b[0m\n",
      "\u001b[34m[287]#011train's multi_logloss: 0.038844#011val's multi_logloss: 0.0391046\u001b[0m\n",
      "\u001b[34m[288]#011train's multi_logloss: 0.0388414#011val's multi_logloss: 0.0391028\u001b[0m\n",
      "\u001b[34m[289]#011train's multi_logloss: 0.0388388#011val's multi_logloss: 0.039101\u001b[0m\n",
      "\u001b[34m[290]#011train's multi_logloss: 0.0388365#011val's multi_logloss: 0.0390995\u001b[0m\n",
      "\u001b[34m[291]#011train's multi_logloss: 0.0388322#011val's multi_logloss: 0.0390968\u001b[0m\n",
      "\u001b[34m[292]#011train's multi_logloss: 0.0388279#011val's multi_logloss: 0.0390938\u001b[0m\n",
      "\u001b[34m[293]#011train's multi_logloss: 0.0388249#011val's multi_logloss: 0.0390914\u001b[0m\n",
      "\u001b[34m[294]#011train's multi_logloss: 0.0388209#011val's multi_logloss: 0.0390886\u001b[0m\n",
      "\u001b[34m[295]#011train's multi_logloss: 0.0388178#011val's multi_logloss: 0.0390865\u001b[0m\n",
      "\u001b[34m[296]#011train's multi_logloss: 0.0388146#011val's multi_logloss: 0.0390842\u001b[0m\n",
      "\u001b[34m[297]#011train's multi_logloss: 0.0388109#011val's multi_logloss: 0.0390819\u001b[0m\n",
      "\u001b[34m[298]#011train's multi_logloss: 0.0388072#011val's multi_logloss: 0.0390792\u001b[0m\n",
      "\u001b[34m[299]#011train's multi_logloss: 0.0388036#011val's multi_logloss: 0.0390771\u001b[0m\n",
      "\u001b[34m[300]#011train's multi_logloss: 0.0388009#011val's multi_logloss: 0.0390753\u001b[0m\n",
      "\u001b[34m[301]#011train's multi_logloss: 0.0387971#011val's multi_logloss: 0.0390723\u001b[0m\n",
      "\u001b[34m[302]#011train's multi_logloss: 0.038793#011val's multi_logloss: 0.0390689\u001b[0m\n",
      "\u001b[34m[303]#011train's multi_logloss: 0.0387899#011val's multi_logloss: 0.0390663\u001b[0m\n",
      "\u001b[34m[304]#011train's multi_logloss: 0.0387856#011val's multi_logloss: 0.0390637\u001b[0m\n",
      "\u001b[34m[305]#011train's multi_logloss: 0.0387828#011val's multi_logloss: 0.039062\u001b[0m\n",
      "\u001b[34m[306]#011train's multi_logloss: 0.0387795#011val's multi_logloss: 0.0390592\u001b[0m\n",
      "\u001b[34m[307]#011train's multi_logloss: 0.0387769#011val's multi_logloss: 0.0390573\u001b[0m\n",
      "\u001b[34m[308]#011train's multi_logloss: 0.0387733#011val's multi_logloss: 0.039055\u001b[0m\n",
      "\u001b[34m[309]#011train's multi_logloss: 0.0387709#011val's multi_logloss: 0.0390532\u001b[0m\n",
      "\u001b[34m[310]#011train's multi_logloss: 0.0387675#011val's multi_logloss: 0.0390507\u001b[0m\n",
      "\u001b[34m[311]#011train's multi_logloss: 0.0387636#011val's multi_logloss: 0.0390486\u001b[0m\n",
      "\u001b[34m[312]#011train's multi_logloss: 0.0387605#011val's multi_logloss: 0.0390468\u001b[0m\n",
      "\u001b[34m[313]#011train's multi_logloss: 0.0387578#011val's multi_logloss: 0.039045\u001b[0m\n",
      "\u001b[34m[314]#011train's multi_logloss: 0.0387548#011val's multi_logloss: 0.0390429\u001b[0m\n",
      "\u001b[34m[315]#011train's multi_logloss: 0.0387514#011val's multi_logloss: 0.0390412\u001b[0m\n",
      "\u001b[34m[316]#011train's multi_logloss: 0.0387478#011val's multi_logloss: 0.0390383\u001b[0m\n",
      "\u001b[34m[317]#011train's multi_logloss: 0.0387432#011val's multi_logloss: 0.0390352\u001b[0m\n",
      "\u001b[34m[318]#011train's multi_logloss: 0.0387398#011val's multi_logloss: 0.0390326\u001b[0m\n",
      "\u001b[34m[319]#011train's multi_logloss: 0.0387372#011val's multi_logloss: 0.0390307\u001b[0m\n",
      "\u001b[34m[320]#011train's multi_logloss: 0.0387339#011val's multi_logloss: 0.0390285\u001b[0m\n",
      "\u001b[34m[321]#011train's multi_logloss: 0.0387308#011val's multi_logloss: 0.0390262\u001b[0m\n",
      "\u001b[34m[322]#011train's multi_logloss: 0.0387279#011val's multi_logloss: 0.0390241\u001b[0m\n",
      "\u001b[34m[323]#011train's multi_logloss: 0.0387248#011val's multi_logloss: 0.0390221\u001b[0m\n",
      "\u001b[34m[324]#011train's multi_logloss: 0.0387214#011val's multi_logloss: 0.0390194\u001b[0m\n",
      "\u001b[34m[325]#011train's multi_logloss: 0.0387186#011val's multi_logloss: 0.0390177\u001b[0m\n",
      "\u001b[34m[326]#011train's multi_logloss: 0.0387156#011val's multi_logloss: 0.0390157\u001b[0m\n",
      "\u001b[34m[327]#011train's multi_logloss: 0.0387123#011val's multi_logloss: 0.039014\u001b[0m\n",
      "\u001b[34m[328]#011train's multi_logloss: 0.0387098#011val's multi_logloss: 0.0390124\u001b[0m\n",
      "\u001b[34m[329]#011train's multi_logloss: 0.0387065#011val's multi_logloss: 0.0390105\u001b[0m\n",
      "\u001b[34m[330]#011train's multi_logloss: 0.0387038#011val's multi_logloss: 0.0390087\u001b[0m\n",
      "\u001b[34m[331]#011train's multi_logloss: 0.0387011#011val's multi_logloss: 0.0390067\u001b[0m\n",
      "\u001b[34m[332]#011train's multi_logloss: 0.0386977#011val's multi_logloss: 0.0390044\u001b[0m\n",
      "\u001b[34m[333]#011train's multi_logloss: 0.0386954#011val's multi_logloss: 0.0390031\u001b[0m\n",
      "\u001b[34m[334]#011train's multi_logloss: 0.0386933#011val's multi_logloss: 0.0390016\u001b[0m\n",
      "\u001b[34m[335]#011train's multi_logloss: 0.0386908#011val's multi_logloss: 0.0390003\u001b[0m\n",
      "\u001b[34m[336]#011train's multi_logloss: 0.0386881#011val's multi_logloss: 0.0389983\u001b[0m\n",
      "\u001b[34m[337]#011train's multi_logloss: 0.0386857#011val's multi_logloss: 0.0389966\u001b[0m\n",
      "\u001b[34m[338]#011train's multi_logloss: 0.0386833#011val's multi_logloss: 0.0389948\u001b[0m\n",
      "\u001b[34m[339]#011train's multi_logloss: 0.0386796#011val's multi_logloss: 0.0389931\u001b[0m\n",
      "\u001b[34m[340]#011train's multi_logloss: 0.0386775#011val's multi_logloss: 0.0389919\u001b[0m\n",
      "\u001b[34m[341]#011train's multi_logloss: 0.0386752#011val's multi_logloss: 0.0389907\u001b[0m\n",
      "\u001b[34m[342]#011train's multi_logloss: 0.0386724#011val's multi_logloss: 0.038989\u001b[0m\n",
      "\u001b[34m[343]#011train's multi_logloss: 0.0386696#011val's multi_logloss: 0.0389877\u001b[0m\n",
      "\u001b[34m[344]#011train's multi_logloss: 0.0386665#011val's multi_logloss: 0.0389856\u001b[0m\n",
      "\u001b[34m[345]#011train's multi_logloss: 0.0386637#011val's multi_logloss: 0.038984\u001b[0m\n",
      "\u001b[34m[346]#011train's multi_logloss: 0.0386622#011val's multi_logloss: 0.0389832\u001b[0m\n",
      "\u001b[34m[347]#011train's multi_logloss: 0.0386594#011val's multi_logloss: 0.0389817\u001b[0m\n",
      "\u001b[34m[348]#011train's multi_logloss: 0.0386566#011val's multi_logloss: 0.0389802\u001b[0m\n",
      "\u001b[34m[349]#011train's multi_logloss: 0.0386536#011val's multi_logloss: 0.0389787\u001b[0m\n",
      "\u001b[34m[350]#011train's multi_logloss: 0.0386506#011val's multi_logloss: 0.0389768\u001b[0m\n",
      "\u001b[34m[351]#011train's multi_logloss: 0.0386479#011val's multi_logloss: 0.0389749\u001b[0m\n",
      "\u001b[34m[352]#011train's multi_logloss: 0.0386453#011val's multi_logloss: 0.0389733\u001b[0m\n",
      "\u001b[34m[353]#011train's multi_logloss: 0.0386427#011val's multi_logloss: 0.0389719\u001b[0m\n",
      "\u001b[34m[354]#011train's multi_logloss: 0.0386402#011val's multi_logloss: 0.0389702\u001b[0m\n",
      "\u001b[34m[355]#011train's multi_logloss: 0.038638#011val's multi_logloss: 0.0389694\u001b[0m\n",
      "\u001b[34m[356]#011train's multi_logloss: 0.0386355#011val's multi_logloss: 0.0389678\u001b[0m\n",
      "\u001b[34m[357]#011train's multi_logloss: 0.0386327#011val's multi_logloss: 0.0389659\u001b[0m\n",
      "\u001b[34m[358]#011train's multi_logloss: 0.0386301#011val's multi_logloss: 0.0389642\u001b[0m\n",
      "\u001b[34m[359]#011train's multi_logloss: 0.0386273#011val's multi_logloss: 0.0389624\u001b[0m\n",
      "\u001b[34m[360]#011train's multi_logloss: 0.0386245#011val's multi_logloss: 0.038961\u001b[0m\n",
      "\u001b[34m[361]#011train's multi_logloss: 0.0386214#011val's multi_logloss: 0.0389591\u001b[0m\n",
      "\u001b[34m[362]#011train's multi_logloss: 0.0386188#011val's multi_logloss: 0.0389581\u001b[0m\n",
      "\u001b[34m[363]#011train's multi_logloss: 0.038616#011val's multi_logloss: 0.0389565\u001b[0m\n",
      "\u001b[34m[364]#011train's multi_logloss: 0.038614#011val's multi_logloss: 0.038955\u001b[0m\n",
      "\u001b[34m[365]#011train's multi_logloss: 0.0386114#011val's multi_logloss: 0.0389539\u001b[0m\n",
      "\u001b[34m[366]#011train's multi_logloss: 0.0386084#011val's multi_logloss: 0.0389519\u001b[0m\n",
      "\u001b[34m[367]#011train's multi_logloss: 0.0386058#011val's multi_logloss: 0.0389502\u001b[0m\n",
      "\u001b[34m[368]#011train's multi_logloss: 0.0386022#011val's multi_logloss: 0.0389478\u001b[0m\n",
      "\u001b[34m[369]#011train's multi_logloss: 0.0385997#011val's multi_logloss: 0.038946\u001b[0m\n",
      "\u001b[34m[370]#011train's multi_logloss: 0.0385962#011val's multi_logloss: 0.0389432\u001b[0m\n",
      "\u001b[34m[371]#011train's multi_logloss: 0.0385933#011val's multi_logloss: 0.0389411\u001b[0m\n",
      "\u001b[34m[372]#011train's multi_logloss: 0.038591#011val's multi_logloss: 0.0389397\u001b[0m\n",
      "\u001b[34m[373]#011train's multi_logloss: 0.0385882#011val's multi_logloss: 0.0389382\u001b[0m\n",
      "\u001b[34m[374]#011train's multi_logloss: 0.0385862#011val's multi_logloss: 0.0389373\u001b[0m\n",
      "\u001b[34m[375]#011train's multi_logloss: 0.0385837#011val's multi_logloss: 0.0389355\u001b[0m\n",
      "\u001b[34m[376]#011train's multi_logloss: 0.038581#011val's multi_logloss: 0.0389341\u001b[0m\n",
      "\u001b[34m[377]#011train's multi_logloss: 0.0385785#011val's multi_logloss: 0.0389326\u001b[0m\n",
      "\u001b[34m[378]#011train's multi_logloss: 0.0385763#011val's multi_logloss: 0.0389311\u001b[0m\n",
      "\u001b[34m[379]#011train's multi_logloss: 0.0385739#011val's multi_logloss: 0.0389304\u001b[0m\n",
      "\u001b[34m[380]#011train's multi_logloss: 0.0385716#011val's multi_logloss: 0.0389288\u001b[0m\n",
      "\u001b[34m[381]#011train's multi_logloss: 0.0385692#011val's multi_logloss: 0.0389273\u001b[0m\n",
      "\u001b[34m[382]#011train's multi_logloss: 0.0385669#011val's multi_logloss: 0.0389261\u001b[0m\n",
      "\u001b[34m[383]#011train's multi_logloss: 0.0385648#011val's multi_logloss: 0.0389247\u001b[0m\n",
      "\u001b[34m[384]#011train's multi_logloss: 0.0385624#011val's multi_logloss: 0.0389237\u001b[0m\n",
      "\u001b[34m[385]#011train's multi_logloss: 0.0385599#011val's multi_logloss: 0.0389226\u001b[0m\n",
      "\u001b[34m[386]#011train's multi_logloss: 0.038558#011val's multi_logloss: 0.0389217\u001b[0m\n",
      "\u001b[34m[387]#011train's multi_logloss: 0.0385554#011val's multi_logloss: 0.0389205\u001b[0m\n",
      "\u001b[34m[388]#011train's multi_logloss: 0.0385525#011val's multi_logloss: 0.0389193\u001b[0m\n",
      "\u001b[34m[389]#011train's multi_logloss: 0.0385504#011val's multi_logloss: 0.0389183\u001b[0m\n",
      "\u001b[34m[390]#011train's multi_logloss: 0.0385481#011val's multi_logloss: 0.038917\u001b[0m\n",
      "\u001b[34m[391]#011train's multi_logloss: 0.0385449#011val's multi_logloss: 0.0389161\u001b[0m\n",
      "\u001b[34m[392]#011train's multi_logloss: 0.0385422#011val's multi_logloss: 0.0389144\u001b[0m\n",
      "\u001b[34m[393]#011train's multi_logloss: 0.0385395#011val's multi_logloss: 0.0389138\u001b[0m\n",
      "\u001b[34m[394]#011train's multi_logloss: 0.0385366#011val's multi_logloss: 0.0389125\u001b[0m\n",
      "\u001b[34m[395]#011train's multi_logloss: 0.0385342#011val's multi_logloss: 0.0389111\u001b[0m\n",
      "\u001b[34m[396]#011train's multi_logloss: 0.0385316#011val's multi_logloss: 0.0389105\u001b[0m\n",
      "\u001b[34m[397]#011train's multi_logloss: 0.0385285#011val's multi_logloss: 0.0389094\u001b[0m\n",
      "\u001b[34m[398]#011train's multi_logloss: 0.0385261#011val's multi_logloss: 0.0389087\u001b[0m\n",
      "\u001b[34m[399]#011train's multi_logloss: 0.0385242#011val's multi_logloss: 0.0389079\u001b[0m\n",
      "\u001b[34m[400]#011train's multi_logloss: 0.0385222#011val's multi_logloss: 0.0389068\u001b[0m\n",
      "\u001b[34m[401]#011train's multi_logloss: 0.0385202#011val's multi_logloss: 0.0389057\u001b[0m\n",
      "\u001b[34m[402]#011train's multi_logloss: 0.0385179#011val's multi_logloss: 0.0389045\u001b[0m\n",
      "\u001b[34m[403]#011train's multi_logloss: 0.0385154#011val's multi_logloss: 0.0389032\u001b[0m\n",
      "\u001b[34m[404]#011train's multi_logloss: 0.0385125#011val's multi_logloss: 0.0389018\u001b[0m\n",
      "\u001b[34m[405]#011train's multi_logloss: 0.0385095#011val's multi_logloss: 0.0389003\u001b[0m\n",
      "\u001b[34m[406]#011train's multi_logloss: 0.0385071#011val's multi_logloss: 0.0388991\u001b[0m\n",
      "\u001b[34m[407]#011train's multi_logloss: 0.0385048#011val's multi_logloss: 0.038898\u001b[0m\n",
      "\u001b[34m[408]#011train's multi_logloss: 0.0385024#011val's multi_logloss: 0.0388965\u001b[0m\n",
      "\u001b[34m[409]#011train's multi_logloss: 0.0385007#011val's multi_logloss: 0.0388957\u001b[0m\n",
      "\u001b[34m[410]#011train's multi_logloss: 0.0384987#011val's multi_logloss: 0.0388947\u001b[0m\n",
      "\u001b[34m[411]#011train's multi_logloss: 0.0384967#011val's multi_logloss: 0.0388937\u001b[0m\n",
      "\u001b[34m[412]#011train's multi_logloss: 0.0384946#011val's multi_logloss: 0.0388928\u001b[0m\n",
      "\u001b[34m[413]#011train's multi_logloss: 0.0384911#011val's multi_logloss: 0.0388904\u001b[0m\n",
      "\u001b[34m[414]#011train's multi_logloss: 0.0384894#011val's multi_logloss: 0.0388896\u001b[0m\n",
      "\u001b[34m[415]#011train's multi_logloss: 0.0384872#011val's multi_logloss: 0.0388885\u001b[0m\n",
      "\u001b[34m[416]#011train's multi_logloss: 0.0384853#011val's multi_logloss: 0.0388878\u001b[0m\n",
      "\u001b[34m[417]#011train's multi_logloss: 0.0384832#011val's multi_logloss: 0.0388867\u001b[0m\n",
      "\u001b[34m[418]#011train's multi_logloss: 0.0384812#011val's multi_logloss: 0.0388858\u001b[0m\n",
      "\u001b[34m[419]#011train's multi_logloss: 0.0384785#011val's multi_logloss: 0.0388851\u001b[0m\n",
      "\u001b[34m[420]#011train's multi_logloss: 0.0384764#011val's multi_logloss: 0.0388842\u001b[0m\n",
      "\u001b[34m[421]#011train's multi_logloss: 0.0384734#011val's multi_logloss: 0.0388826\u001b[0m\n",
      "\u001b[34m[422]#011train's multi_logloss: 0.0384707#011val's multi_logloss: 0.038881\u001b[0m\n",
      "\u001b[34m[423]#011train's multi_logloss: 0.038468#011val's multi_logloss: 0.0388799\u001b[0m\n",
      "\u001b[34m[424]#011train's multi_logloss: 0.0384652#011val's multi_logloss: 0.0388788\u001b[0m\n",
      "\u001b[34m[425]#011train's multi_logloss: 0.0384632#011val's multi_logloss: 0.038878\u001b[0m\n",
      "\u001b[34m[426]#011train's multi_logloss: 0.0384589#011val's multi_logloss: 0.0388768\u001b[0m\n",
      "\u001b[34m[427]#011train's multi_logloss: 0.0384564#011val's multi_logloss: 0.0388754\u001b[0m\n",
      "\u001b[34m[428]#011train's multi_logloss: 0.0384528#011val's multi_logloss: 0.0388744\u001b[0m\n",
      "\u001b[34m[429]#011train's multi_logloss: 0.0384509#011val's multi_logloss: 0.0388734\u001b[0m\n",
      "\u001b[34m[430]#011train's multi_logloss: 0.0384475#011val's multi_logloss: 0.0388722\u001b[0m\n",
      "\u001b[34m[431]#011train's multi_logloss: 0.0384449#011val's multi_logloss: 0.038871\u001b[0m\n",
      "\u001b[34m[432]#011train's multi_logloss: 0.0384429#011val's multi_logloss: 0.0388703\u001b[0m\n",
      "\u001b[34m[433]#011train's multi_logloss: 0.0384402#011val's multi_logloss: 0.0388695\u001b[0m\n",
      "\u001b[34m[434]#011train's multi_logloss: 0.0384386#011val's multi_logloss: 0.0388687\u001b[0m\n",
      "\u001b[34m[435]#011train's multi_logloss: 0.0384363#011val's multi_logloss: 0.0388675\u001b[0m\n",
      "\u001b[34m[436]#011train's multi_logloss: 0.038434#011val's multi_logloss: 0.0388668\u001b[0m\n",
      "\u001b[34m[437]#011train's multi_logloss: 0.0384315#011val's multi_logloss: 0.0388654\u001b[0m\n",
      "\u001b[34m[438]#011train's multi_logloss: 0.0384287#011val's multi_logloss: 0.0388636\u001b[0m\n",
      "\u001b[34m[439]#011train's multi_logloss: 0.0384261#011val's multi_logloss: 0.0388626\u001b[0m\n",
      "\u001b[34m[440]#011train's multi_logloss: 0.0384231#011val's multi_logloss: 0.038861\u001b[0m\n",
      "\u001b[34m[441]#011train's multi_logloss: 0.0384214#011val's multi_logloss: 0.0388603\u001b[0m\n",
      "\u001b[34m[442]#011train's multi_logloss: 0.0384195#011val's multi_logloss: 0.0388591\u001b[0m\n",
      "\u001b[34m[443]#011train's multi_logloss: 0.038418#011val's multi_logloss: 0.0388587\u001b[0m\n",
      "\u001b[34m[444]#011train's multi_logloss: 0.0384165#011val's multi_logloss: 0.0388578\u001b[0m\n",
      "\u001b[34m[445]#011train's multi_logloss: 0.0384139#011val's multi_logloss: 0.0388566\u001b[0m\n",
      "\u001b[34m[446]#011train's multi_logloss: 0.0384118#011val's multi_logloss: 0.0388557\u001b[0m\n",
      "\u001b[34m[447]#011train's multi_logloss: 0.0384093#011val's multi_logloss: 0.0388539\u001b[0m\n",
      "\u001b[34m[448]#011train's multi_logloss: 0.0384076#011val's multi_logloss: 0.0388529\u001b[0m\n",
      "\u001b[34m[449]#011train's multi_logloss: 0.0384058#011val's multi_logloss: 0.0388517\u001b[0m\n",
      "\u001b[34m[450]#011train's multi_logloss: 0.0384039#011val's multi_logloss: 0.0388506\u001b[0m\n",
      "\u001b[34m[451]#011train's multi_logloss: 0.0384002#011val's multi_logloss: 0.0388486\u001b[0m\n",
      "\u001b[34m[452]#011train's multi_logloss: 0.0383975#011val's multi_logloss: 0.0388475\u001b[0m\n",
      "\u001b[34m[453]#011train's multi_logloss: 0.0383951#011val's multi_logloss: 0.0388466\u001b[0m\n",
      "\u001b[34m[454]#011train's multi_logloss: 0.0383926#011val's multi_logloss: 0.0388453\u001b[0m\n",
      "\u001b[34m[455]#011train's multi_logloss: 0.0383909#011val's multi_logloss: 0.0388446\u001b[0m\n",
      "\u001b[34m[456]#011train's multi_logloss: 0.0383885#011val's multi_logloss: 0.0388434\u001b[0m\n",
      "\u001b[34m[457]#011train's multi_logloss: 0.0383858#011val's multi_logloss: 0.0388426\u001b[0m\n",
      "\u001b[34m[458]#011train's multi_logloss: 0.0383839#011val's multi_logloss: 0.0388424\u001b[0m\n",
      "\u001b[34m[459]#011train's multi_logloss: 0.0383817#011val's multi_logloss: 0.0388414\u001b[0m\n",
      "\u001b[34m[460]#011train's multi_logloss: 0.0383785#011val's multi_logloss: 0.03884\u001b[0m\n",
      "\u001b[34m[461]#011train's multi_logloss: 0.0383764#011val's multi_logloss: 0.0388397\u001b[0m\n",
      "\u001b[34m[462]#011train's multi_logloss: 0.0383737#011val's multi_logloss: 0.0388392\u001b[0m\n",
      "\u001b[34m[463]#011train's multi_logloss: 0.0383716#011val's multi_logloss: 0.0388388\u001b[0m\n",
      "\u001b[34m[464]#011train's multi_logloss: 0.0383696#011val's multi_logloss: 0.0388383\u001b[0m\n",
      "\u001b[34m[465]#011train's multi_logloss: 0.0383679#011val's multi_logloss: 0.0388374\u001b[0m\n",
      "\u001b[34m[466]#011train's multi_logloss: 0.038366#011val's multi_logloss: 0.0388368\u001b[0m\n",
      "\u001b[34m[467]#011train's multi_logloss: 0.0383635#011val's multi_logloss: 0.0388361\u001b[0m\n",
      "\u001b[34m[468]#011train's multi_logloss: 0.0383607#011val's multi_logloss: 0.0388351\u001b[0m\n",
      "\u001b[34m[469]#011train's multi_logloss: 0.0383582#011val's multi_logloss: 0.0388343\u001b[0m\n",
      "\u001b[34m[470]#011train's multi_logloss: 0.0383562#011val's multi_logloss: 0.0388334\u001b[0m\n",
      "\u001b[34m[471]#011train's multi_logloss: 0.0383533#011val's multi_logloss: 0.0388331\u001b[0m\n",
      "\u001b[34m[472]#011train's multi_logloss: 0.0383514#011val's multi_logloss: 0.0388327\u001b[0m\n",
      "\u001b[34m[473]#011train's multi_logloss: 0.0383485#011val's multi_logloss: 0.0388325\u001b[0m\n",
      "\u001b[34m[474]#011train's multi_logloss: 0.0383456#011val's multi_logloss: 0.0388315\u001b[0m\n",
      "\u001b[34m[475]#011train's multi_logloss: 0.0383428#011val's multi_logloss: 0.0388297\u001b[0m\n",
      "\u001b[34m[476]#011train's multi_logloss: 0.0383387#011val's multi_logloss: 0.0388288\u001b[0m\n",
      "\u001b[34m[477]#011train's multi_logloss: 0.038336#011val's multi_logloss: 0.0388276\u001b[0m\n",
      "\u001b[34m[478]#011train's multi_logloss: 0.0383338#011val's multi_logloss: 0.0388267\u001b[0m\n",
      "\u001b[34m[479]#011train's multi_logloss: 0.0383315#011val's multi_logloss: 0.0388251\u001b[0m\n",
      "\u001b[34m[480]#011train's multi_logloss: 0.0383299#011val's multi_logloss: 0.0388245\u001b[0m\n",
      "\u001b[34m[481]#011train's multi_logloss: 0.0383276#011val's multi_logloss: 0.0388233\u001b[0m\n",
      "\u001b[34m[482]#011train's multi_logloss: 0.0383254#011val's multi_logloss: 0.0388219\u001b[0m\n",
      "\u001b[34m[483]#011train's multi_logloss: 0.0383231#011val's multi_logloss: 0.0388209\u001b[0m\n",
      "\u001b[34m[484]#011train's multi_logloss: 0.038321#011val's multi_logloss: 0.0388203\u001b[0m\n",
      "\u001b[34m[485]#011train's multi_logloss: 0.0383194#011val's multi_logloss: 0.0388198\u001b[0m\n",
      "\u001b[34m[486]#011train's multi_logloss: 0.0383174#011val's multi_logloss: 0.0388194\u001b[0m\n",
      "\u001b[34m[487]#011train's multi_logloss: 0.0383149#011val's multi_logloss: 0.0388184\u001b[0m\n",
      "\u001b[34m[488]#011train's multi_logloss: 0.038313#011val's multi_logloss: 0.0388175\u001b[0m\n",
      "\u001b[34m[489]#011train's multi_logloss: 0.0383105#011val's multi_logloss: 0.0388163\u001b[0m\n",
      "\u001b[34m[490]#011train's multi_logloss: 0.0383081#011val's multi_logloss: 0.0388151\u001b[0m\n",
      "\u001b[34m[491]#011train's multi_logloss: 0.0383061#011val's multi_logloss: 0.0388138\u001b[0m\n",
      "\u001b[34m[492]#011train's multi_logloss: 0.0383046#011val's multi_logloss: 0.0388132\u001b[0m\n",
      "\u001b[34m[493]#011train's multi_logloss: 0.0383029#011val's multi_logloss: 0.0388124\u001b[0m\n",
      "\u001b[34m[494]#011train's multi_logloss: 0.0383009#011val's multi_logloss: 0.0388115\u001b[0m\n",
      "\u001b[34m[495]#011train's multi_logloss: 0.0382997#011val's multi_logloss: 0.0388109\u001b[0m\n",
      "\u001b[34m[496]#011train's multi_logloss: 0.0382967#011val's multi_logloss: 0.0388091\u001b[0m\n",
      "\u001b[34m[497]#011train's multi_logloss: 0.0382924#011val's multi_logloss: 0.0388083\u001b[0m\n",
      "\u001b[34m[498]#011train's multi_logloss: 0.0382902#011val's multi_logloss: 0.0388076\u001b[0m\n",
      "\u001b[34m[499]#011train's multi_logloss: 0.038288#011val's multi_logloss: 0.0388066\u001b[0m\n",
      "\u001b[34m[500]#011train's multi_logloss: 0.0382862#011val's multi_logloss: 0.0388053\u001b[0m\n",
      "\u001b[34mDid not meet early stopping. Best iteration is:\u001b[0m\n",
      "\u001b[34m[500]#011train's multi_logloss: 0.0382862#011val's multi_logloss: 0.0388053\u001b[0m\n",
      "\n",
      "2024-03-12 17:56:20 Uploading - Uploading generated training model\n",
      "2024-03-12 17:56:20 Completed - Training job completed\n",
      "\u001b[34mINFO:root:Saving model...\u001b[0m\n",
      "\u001b[34mINFO:root:Info file not found at '_input_model_extracted/__models_info__.json'.\u001b[0m\n",
      "\u001b[34m2024-03-12 17:56:07,673 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "Training seconds: 10760\n",
      "Billable seconds: 10760\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "\n",
    "# Specify the location of your input data in S3\n",
    "train_data = training_dataset_s3_path\n",
    "validation_data = validation_dataset_s3_path\n",
    "\n",
    "# Set input data channels\n",
    "train_channel = sagemaker.inputs.TrainingInput(train_data, content_type='application/x-parquet')\n",
    "validation_channel = sagemaker.inputs.TrainingInput(validation_data, content_type='application/x-parquet')\n",
    "\n",
    "data_channels = {'train': train_channel, 'validation': validation_channel}\n",
    "\n",
    "# Launch a SageMaker Training job by passing the S3 path of the training data\n",
    "tabular_estimator.fit(\n",
    "    {\n",
    "        \"train\": train_channel,\n",
    "        \"validation\": validation_channel,\n",
    "    }, logs=True, job_name=training_job_name\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6a3f75-bc67-44e5-929a-526ab29c1ae3",
   "metadata": {},
   "source": [
    "## Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8abc9d-289e-4e92-9364-aa2b41487713",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "s3_url = f\"s3://viamericas-datalake-dev-us-east-1-283731589572-raw/FraudModel/Data4Model/Test/Test.parquet\"\n",
    "\n",
    "dtest = pd.read_parquet(s3_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f261dd9-c4c9-4404-b0d9-1b203bd986ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import joblib \n",
    "import tarfile\n",
    "import boto3\n",
    "\n",
    "# Set up S3 client\n",
    "client = boto3.client('s3')\n",
    "bucket_name = 'viamericas-datalake-dev-us-east-1-283731589572-analytics'\n",
    "path = 'FraudModel/output/built-in-algo-lightgbm-classification-m-2024-03-12-14-56-09-133/output/' # Folder under analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0975cc7e-6270-4c10-a057-dbb0bcbdc912",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tar_file_key = 'FraudModel/output/built-in-algo-lightgbm-classification-m-2024-03-12-14-56-09-133/output/model.tar.gz'\n",
    "\n",
    "responde = client.get_object(Bucket=bucket_name, Key=tar_file_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49b501d1-9a4a-4541-85c0-de42e22408dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tar_bytes = responde['Body'].read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "42d0cd53-613d-4a33-a669-73f289d7b353",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import io\n",
    "\n",
    "fileobj = io.BytesIO(tar_bytes)\n",
    "tarf = tarfile.open(fileobj=fileobj)\n",
    "\n",
    "tarf.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "600b10d6-10bb-4990-91a5-da8874c992b7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lightgbm\n",
      "  Using cached lightgbm-4.3.0-py3-none-manylinux_2_28_x86_64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from lightgbm) (1.26.2)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from lightgbm) (1.11.4)\n",
      "Using cached lightgbm-4.3.0-py3-none-manylinux_2_28_x86_64.whl (3.1 MB)\n",
      "Installing collected packages: lightgbm\n",
      "Successfully installed lightgbm-4.3.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "60237655-3cc7-4ec4-bcf1-9f23357e6aa8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (2.1.3)\n",
      "Collecting pandas\n",
      "  Using cached pandas-2.2.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: dask[complete] in /opt/conda/lib/python3.10/site-packages (2022.7.0)\n",
      "Collecting dask[complete]\n",
      "  Downloading dask-2024.3.0-py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in /opt/conda/lib/python3.10/site-packages (from pandas) (1.26.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: click>=8.1 in /opt/conda/lib/python3.10/site-packages (from dask[complete]) (8.1.7)\n",
      "Requirement already satisfied: cloudpickle>=1.5.0 in /opt/conda/lib/python3.10/site-packages (from dask[complete]) (2.2.1)\n",
      "Requirement already satisfied: fsspec>=2021.09.0 in /opt/conda/lib/python3.10/site-packages (from dask[complete]) (2022.7.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from dask[complete]) (21.3)\n",
      "Requirement already satisfied: partd>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from dask[complete]) (1.2.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /opt/conda/lib/python3.10/site-packages/PyYAML-6.0-py3.10-linux-x86_64.egg (from dask[complete]) (6.0)\n",
      "Requirement already satisfied: toolz>=0.10.0 in /opt/conda/lib/python3.10/site-packages (from dask[complete]) (0.11.2)\n",
      "Collecting importlib-metadata>=4.13.0 (from dask[complete])\n",
      "  Using cached importlib_metadata-7.0.2-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: pyarrow>=7.0 in /opt/conda/lib/python3.10/site-packages (from dask[complete]) (14.0.1)\n",
      "Collecting pyarrow-hotfix (from dask[complete])\n",
      "  Using cached pyarrow_hotfix-0.6-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting lz4>=4.3.2 (from dask[complete])\n",
      "  Using cached lz4-4.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.10/site-packages (from importlib-metadata>=4.13.0->dask[complete]) (3.8.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->dask[complete]) (3.0.9)\n",
      "Requirement already satisfied: locket in /opt/conda/lib/python3.10/site-packages (from partd>=1.2.0->dask[complete]) (1.0.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: bokeh>=2.4.2 in /opt/conda/lib/python3.10/site-packages (from dask[complete]) (3.3.2)\n",
      "Requirement already satisfied: jinja2>=2.10.3 in /opt/conda/lib/python3.10/site-packages (from dask[complete]) (3.1.2)\n",
      "Collecting distributed==2024.3.0 (from dask[complete])\n",
      "  Downloading distributed-2024.3.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting dask-expr<1.1,>=1.0 (from dask[complete])\n",
      "  Downloading dask_expr-1.0.1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: msgpack>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from distributed==2024.3.0->dask[complete]) (1.0.3)\n",
      "Requirement already satisfied: psutil>=5.7.2 in /opt/conda/lib/python3.10/site-packages (from distributed==2024.3.0->dask[complete]) (5.9.0)\n",
      "Requirement already satisfied: sortedcontainers>=2.0.5 in /opt/conda/lib/python3.10/site-packages (from distributed==2024.3.0->dask[complete]) (2.4.0)\n",
      "Requirement already satisfied: tblib>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from distributed==2024.3.0->dask[complete]) (1.7.0)\n",
      "Requirement already satisfied: tornado>=6.0.4 in /opt/conda/lib/python3.10/site-packages (from distributed==2024.3.0->dask[complete]) (6.4)\n",
      "Requirement already satisfied: urllib3>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from distributed==2024.3.0->dask[complete]) (2.1.0)\n",
      "Collecting zict>=3.0.0 (from distributed==2024.3.0->dask[complete])\n",
      "  Using cached zict-3.0.0-py2.py3-none-any.whl.metadata (899 bytes)\n",
      "Requirement already satisfied: contourpy>=1 in /opt/conda/lib/python3.10/site-packages (from bokeh>=2.4.2->dask[complete]) (1.2.0)\n",
      "Requirement already satisfied: pillow>=7.1.0 in /opt/conda/lib/python3.10/site-packages (from bokeh>=2.4.2->dask[complete]) (10.1.0)\n",
      "Requirement already satisfied: xyzservices>=2021.09.1 in /opt/conda/lib/python3.10/site-packages (from bokeh>=2.4.2->dask[complete]) (2023.10.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2>=2.10.3->dask[complete]) (2.1.3)\n",
      "Using cached pandas-2.2.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.0 MB)\n",
      "Using cached importlib_metadata-7.0.2-py3-none-any.whl (24 kB)\n",
      "Using cached lz4-4.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "Downloading dask-2024.3.0-py3-none-any.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading distributed-2024.3.0-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
      "Downloading dask_expr-1.0.1-py3-none-any.whl (178 kB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m178.5/178.5 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached zict-3.0.0-py2.py3-none-any.whl (43 kB)\n",
      "Installing collected packages: zict, pyarrow-hotfix, lz4, importlib-metadata, pandas, dask, distributed, dask-expr\n",
      "  Attempting uninstall: zict\n",
      "    Found existing installation: zict 2.1.0\n",
      "    Uninstalling zict-2.1.0:\n",
      "      Successfully uninstalled zict-2.1.0\n",
      "  Attempting uninstall: lz4\n",
      "    Found existing installation: lz4 3.1.3\n",
      "    Uninstalling lz4-3.1.3:\n",
      "      Successfully uninstalled lz4-3.1.3\n",
      "  Attempting uninstall: importlib-metadata\n",
      "    Found existing installation: importlib-metadata 4.11.3\n",
      "    Uninstalling importlib-metadata-4.11.3:\n",
      "      Successfully uninstalled importlib-metadata-4.11.3\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 2.1.3\n",
      "    Uninstalling pandas-2.1.3:\n",
      "      Successfully uninstalled pandas-2.1.3\n",
      "  Attempting uninstall: dask\n",
      "    Found existing installation: dask 2022.7.0\n",
      "    Uninstalling dask-2022.7.0:\n",
      "      Successfully uninstalled dask-2022.7.0\n",
      "  Attempting uninstall: distributed\n",
      "    Found existing installation: distributed 2022.7.0\n",
      "    Uninstalling distributed-2022.7.0:\n",
      "      Successfully uninstalled distributed-2022.7.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "spyder 5.3.3 requires pyqt5<5.16, which is not installed.\n",
      "spyder 5.3.3 requires pyqtwebengine<5.16, which is not installed.\n",
      "panel 0.13.1 requires bokeh<2.5.0,>=2.4.0, but you have bokeh 3.3.2 which is incompatible.\n",
      "sagemaker 2.199.0 requires importlib-metadata<7.0,>=1.4.0, but you have importlib-metadata 7.0.2 which is incompatible.\n",
      "sagemaker 2.199.0 requires urllib3<1.27, but you have urllib3 2.1.0 which is incompatible.\n",
      "sagemaker-datawrangler 0.4.3 requires sagemaker-data-insights==0.4.0, but you have sagemaker-data-insights 0.3.3 which is incompatible.\n",
      "spyder 5.3.3 requires ipython<8.0.0,>=7.31.1, but you have ipython 8.18.1 which is incompatible.\n",
      "spyder 5.3.3 requires pylint<3.0,>=2.5.0, but you have pylint 3.0.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed dask-2024.3.0 dask-expr-1.0.1 distributed-2024.3.0 importlib-metadata-7.0.2 lz4-4.3.3 pandas-2.2.1 pyarrow-hotfix-0.6 zict-3.0.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade pandas \"dask[complete]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e73eba94-930b-4b51-a6f3-c56bec8235cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed654658-5bf3-4148-b88e-bf3f7974a374",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "#model_url = f\"viamericas-datalake-dev-us-east-1-283731589572-analytics/FraudModel/output/built-in-algo-lightgbm-classification-m-2024-03-12-14-56-09-133/output\"\n",
    "#model_file_path = f\"s3://viamericas-datalake-dev-us-east-1-283731589572-analytics/FraudModel/output/built-in-algo-lightgbm-classification-m-2024-03-12-14-56-09-133/output/model.tar.gz\"\n",
    "\n",
    "\n",
    "#t = tarfile.open(f\"s3://{bucket_name}/{path}/model.tar.gz\", 'r:gz')\n",
    "#t = tarfile.open('model.tar.gz', 'r:gz')\n",
    "#t.extractall()\n",
    "\n",
    "model = joblib.load('model.pkl')\n",
    "\n",
    "# prediction with test data\n",
    "# dtest should be a pandas DataFrame with column names feature_0, feature_1, ..., feature_d\n",
    "pred = model.predict(dtest.loc[:, dtest.columns != 'target_fraudes'],) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed9749e-0cc1-44a6-87b9-5a2998478d47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Retrieve the inference docker container uri\n",
    "deploy_image_uri = image_uris.retrieve(\n",
    "    region=None,\n",
    "    framework=None,\n",
    "    image_scope=\"inference\",\n",
    "    model_id=train_model_id,\n",
    "    model_version=train_model_version,\n",
    "    instance_type=inference_instance_type,\n",
    ")\n",
    "# Retrieve the inference script uri\n",
    "deploy_source_uri = script_uris.retrieve(\n",
    "    model_id=train_model_id, model_version=train_model_version, script_scope=\"inference\"\n",
    ")\n",
    "\n",
    "endpoint_name = name_from_base(f\"jumpstart-example-{train_model_id}-\")\n",
    "\n",
    "# Use the estimator from the previous step to deploy to a SageMaker endpoint\n",
    "predictor = (tuner if use_amt else tabular_estimator).deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=inference_instance_type,\n",
    "    entry_point=\"inference.py\",\n",
    "    image_uri=deploy_image_uri,\n",
    "    source_dir=deploy_source_uri,\n",
    "    endpoint_name=endpoint_name,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.g4dn.xlarge",
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
